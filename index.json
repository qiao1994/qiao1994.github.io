[{"categories":["婚假学习内容"],"content":" 项目 数据库 关键问题 数据分片 Cache 1.概述 2.TinyURL NoSQL Hash方式选择，考虑容量、数量 离线预生产Key 按首字母：数据不均匀 按hash分：ok 淘汰策略：LRU 3.Pastebin MySQL or NoSQ(元信息) 对象存储(数据) 离线预生产Key 同上 同上 4.Instagram 对象存储or HDFS(数据) NoSQL(PhotoID=\u003emetadata) wide-column datastore (relationship[user with phots and user follow]) 推(粉丝多的人)拉(粉丝少的人)结合 UserID：不均匀 PhoteId:ok 可以离线预生成PhotoID CDN LRU 80-20原则 5.Dropbox MySQL(ACID) 数据分片：备份成本与同步速度 保持长连接：long polling 同步数据时需要用消息队列来削峰 数据去重：实时去重 or 异步去重 垂直分区（用户信息与文件信息分开）：一致性、扩展性l 按首字母：数据不均匀 按Hash分：ok Memcached LRU 6.Facebook Messenger HBase：column-oriented key-value NoSQL Pull or Push？Push每个client都需要和server建立长链接（long polling or webscokets） 在线状态可以按需取用，不一定需要实时更新 UserID：ok MessageID：获取一串信息将非常慢 7.Twitter 同Instagram UserID：热门用户导致数据不均匀 TwitterId：查询一个用户的一串信息时，非常慢 按时间：读很友好，但是写基本都是写到最近的服务器，不均匀 按时间+TwitterId：把twitterId设计成时间+序号的方式 8.Youtube or Netflix MySQL：metadata HDFS：video BigTable：trumbnails 读写分离 视频去重可以分块去 UserID：热门用户导致数据不均匀 VideoId：查询视频时需扫描所有服务器，然后做merge；加cache缓解 9.Typeahead Suggestion 10.API Rate Limiter 固定窗口(hash[userid][ip][x秒] =\u003e count) 滑动窗口(hash[userid][ip][1/60单位] =\u003e count) 11.Twitter Search 12.Web Crawler 13.Facebook Newsfeed 14.Yelp or Nearby Friends 15.Uber backend 16.总结 参考资料：https://www.educative.io/courses/grokking-the-system-design-interview ","date":"2022-04-26","objectID":"/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E6%80%BB%E7%BB%93/:0:0","tags":["系统设计"],"title":"系统设计总结","uri":"/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E6%80%BB%E7%BB%93/"},{"categories":["婚假学习内容"],"content":" 优先贪心（一般复杂度比较低） 局部最后可以推出全局最优，且无反例 组合、子集、排列求具体数据用回溯 求最值/可行性/方案数用DP（尤其是数据不可排序、不可交换的情况），求子序列用DP(dp[i][j])，求股票收益用DP(dp[i][j][k])，求加和或能转化成加和用DP(背包) 辅助判断：重叠子问题、无后效性、有最优子结构 ","date":"2022-04-25","objectID":"/%E8%B4%AA%E5%BF%83%E5%9B%9E%E6%BA%AF%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E6%80%BB%E7%BB%93/:0:0","tags":["算法","leetcode","贪心","回溯","动态规划"],"title":"贪心\u0026回溯\u0026动态规划总结","uri":"/%E8%B4%AA%E5%BF%83%E5%9B%9E%E6%BA%AF%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E6%80%BB%E7%BB%93/"},{"categories":["婚假学习内容"],"content":"回溯主要用来解决组合、子集与排列问题，这里给出各类目的典型题与对比表格。 其中path表示递归过程中已走过的路径，即树枝 组合 给定两个整数 n 和 k，返回 1 … n 中所有可能的 k 个数的组合。链接：组合 找出所有相加之和为 n 的 k 个数的组合。组合中只允许含有 1 - 9 的正整数，并且每种组合中不存在重复的数字。链接：组合总和iii 给定一个无重复元素的数组 candidates 和一个目标数 target ，找出 candidates 中所有可以使数字和为 target 的组合。candidates 中的数字可以无限制重复被选取。链接：组合总和 给定一个（可能有重复元素的）数组 candidates 和一个目标数 target ，找出 candidates 中所有可以使数字和为 target 的组合。candidates 中的每个数字在每个组合中只能使用一次。链接：组合总和 题目 1 2 3 4 结果条件 path(递归过程中走过的路径).len == k sum == k sum == target sum == target startIndex i + 1 i + 1 i i + 1 去重 同层去重，树枝不去 子集 给定一组不含重复元素的整数数组 nums，返回该数组所有可能的子集（幂集）。解集不能包含重复的子集。链接：子集 给定一个可能包含重复元素的整数数组 nums，返回该数组所有可能的子集（幂集）。解集不能包含重复的子集。链接：子集ii 给定一个整型数组, 你的任务是找到所有该数组的递增子序列，递增子序列的长度至少是2。链接：递增子序列 题目 1 2 3 结果条件 任意(不return) 任意 path.len \u003e= 2 startIndex i + 1 i + 1 i + 1 去重 同层去重：sort + continue 同层去重：不能sort，用set或hash 排列 给定一个 没有重复 数字的序列，返回其所有可能的全排列。链接：全排列 给定一个可包含重复数字的序列 nums ，按任意顺序 返回所有不重复的全排列。链接：全排列ii 题目 1 2 结果条件 path.len == k path.len == k startIndex 0 0 去重 树枝去重：用used（因为排列无法用startIndex） 树枝去重或同层去重都可以，用used 备注 排序是为了准确判断i与i-1的关系，否则无法判断 序列考虑顺序，所以不同顺序算2个序列，集合不算 元素可重用时，startIndex不+1；元素不可重用时，startIndex要+1 子集终止条件比较宽松，且不return 去重： 同层去重：用sort加for时continnue的方式或者used的方式；不能sort时可用set或者hash 树枝去重：只能用used used去重：used[i - 1] = false 同层用过，used[i - 1] = true 树枝用过 参考资料：https://www.programmercarl.com/ ","date":"2022-04-24","objectID":"/%E5%9B%9E%E6%BA%AF%E6%80%BB%E7%BB%93/:0:0","tags":["算法","leetcode","回溯"],"title":"回溯总结","uri":"/%E5%9B%9E%E6%BA%AF%E6%80%BB%E7%BB%93/"},{"categories":["婚假学习内容"],"content":"疫情导致哪都去不了，所以婚假也只能学学习啦 背包问题 类型 维度 物品/容量遍历顺序(内外) 原因 容量遍历顺序(左右) 原因 01 二维 任意 内层左到右 01 一维 外物品、内容量 由于容量需要从右往左遍历，如果外容量、内物品，会导致每个容量都只看一个物品。*确保容量会考虑不同物品* 右-\u003e左 对于DP中的每个点来说，数据来自于上方和左上方。从右至左遍历能保持左侧数据是上一次迭代完成的，否则会被污染（相当于多次使用物品）。*确保每个物品都只被使用一次* 完全 二维 任意 任意 完全 一维 外物品、内容量是遍历组合外容量、内物品是遍历排列 对于DP中的每个点来说，数据来自于上方和左方。先横后竖意味着左侧数据只考虑了当前物品，未考虑后续物品；先竖后横则意味着左侧数据也已经考虑了后续物品。****主要区别是左侧数据是否考虑了后续物品****举一个外物品、内容量的例子：组合总和计算dp[4]的时候，结果集只有 {1,3} 这样的集合，不会有{3,1}这样的集合，因为nums遍历放在外层，3只能出现在1后面。 左-\u003e右 对于DP中的每个点来说，数据来自于上方和左方，从左往右会确保左侧的数据已经被当前迭代更新过（追求01背包中需要避免的情况）。*确保每个物品在每个容量下都被充分使用* 买卖股票 dp[i][j][k]:截止第i天，持有(j=1)/不持有(j=0)，已卖出k次情况的数据 子序列 dp[i][j]:截止a字符串的第i个字符，b字符串的第j个字符的数据情况 参考资料：https://www.programmercarl.com/ ","date":"2022-04-23","objectID":"/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E6%80%BB%E7%BB%93/:0:0","tags":["算法","leetcode","动态规划"],"title":"动态规划总结","uri":"/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E6%80%BB%E7%BB%93/"},{"categories":["读书笔记"],"content":"第一章：佛系烦恼 —- 反应之前先理解 心烦意乱的真正原因是没有清楚的意识到烦恼的存在，理解烦恼的存在，是解决烦恼的第一步。 ","date":"2019-08-12","objectID":"/%E4%BD%9B%E7%B3%BB%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/:1:0","tags":["读书笔记"],"title":"《佛系：如何成为一个快乐的人》读书笔记","uri":"/%E4%BD%9B%E7%B3%BB%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"categories":["读书笔记"],"content":"烦恼从哪来？ 烦恼的原因是『心灵的反应』，『心灵的反应』的根源在于『索求之心』，它可以分化为『七大欲望』：生存欲、睡眠欲、食欲、性欲、懒惰欲、感乐欲、承认欲。 其中『承认欲』是一种人类特有的欲望，现代社会人类的大多数烦恼都来源于承认欲，但是仔细想想，被别人认可，有啥用呢？ ","date":"2019-08-12","objectID":"/%E4%BD%9B%E7%B3%BB%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/:1:1","tags":["读书笔记"],"title":"《佛系：如何成为一个快乐的人》读书笔记","uri":"/%E4%BD%9B%E7%B3%BB%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"categories":["读书笔记"],"content":"我们可以这样理解我们的人生 我们都有『索求之心』；它会产生『七种欲望』；我们被这些欲望所动摇，产生『心灵的反应』；当这些欲望得到满足时，我们就会感到喜悦；欲望得不到满足，我们就会产生不满情绪；人的一生都是在这几种状态中循环往复。 人心永远在索求，所以永远感到饥渴，如果我们无法理解这一点，对『索求之心』不停做出反应的话，就会被不满锁驱使。 通过索求，我们能找到『前进的可能性』，但是过多的心灵反应往往是适得其反的 ","date":"2019-08-12","objectID":"/%E4%BD%9B%E7%B3%BB%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/:1:2","tags":["读书笔记"],"title":"《佛系：如何成为一个快乐的人》读书笔记","uri":"/%E4%BD%9B%E7%B3%BB%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"categories":["读书笔记"],"content":"如何避免心灵的反应 审视内心的状态，可以避免『心灵的反应』，我们可以通过这几种步骤来理解和避免心灵的反应： 语言确认：『我在焦虑』、『我在紧张』… 意识到身体的感觉：『感受双手』、『深呼吸』 进行分类：『贪欲』、『愤怒』、『妄想』 其中『妄想』是困扰我们很多的一种状态，比如『还有一堆工作需要处理』，『往后可怎么办呢』等等，这种不存在的东西每时每刻都在给我们带来痛苦，要想摆脱痛苦，就需要消除妄想，消除妄想的方法有二：一是通过言语确认或暗示自己正在妄想；二是通过记住『妄想』和『非妄想』(即真实世界)的感受，把我们的思想集中在对真实世界的感受上。 ","date":"2019-08-12","objectID":"/%E4%BD%9B%E7%B3%BB%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/:1:3","tags":["读书笔记"],"title":"《佛系：如何成为一个快乐的人》读书笔记","uri":"/%E4%BD%9B%E7%B3%BB%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"categories":["Redis"],"content":"特点 性能、并发 ","date":"2019-07-23","objectID":"/redis%E6%8A%B1%E4%BD%9B%E8%84%9A/:1:0","tags":["Redis"],"title":"Redis抱佛脚","uri":"/redis%E6%8A%B1%E4%BD%9B%E8%84%9A/"},{"categories":["Redis"],"content":"问题 需要使用物理内存，不支持海量数据 缓存何数据库双写一致性问题 要求强一致性的问题不用缓存 缓存穿透 互斥锁 异步更新 拦截 缓存雪崩 预热 默认值 并发竞争 互斥锁 队列 ","date":"2019-07-23","objectID":"/redis%E6%8A%B1%E4%BD%9B%E8%84%9A/:2:0","tags":["Redis"],"title":"Redis抱佛脚","uri":"/redis%E6%8A%B1%E4%BD%9B%E8%84%9A/"},{"categories":["Redis"],"content":"为啥快？ \u0008\u0008\u0008纯内存 单线程无上下文切换 I/O多路复用 ","date":"2019-07-23","objectID":"/redis%E6%8A%B1%E4%BD%9B%E8%84%9A/:3:0","tags":["Redis"],"title":"Redis抱佛脚","uri":"/redis%E6%8A%B1%E4%BD%9B%E8%84%9A/"},{"categories":["Redis"],"content":"数据类型 String Hash List Set Sorted Set ","date":"2019-07-23","objectID":"/redis%E6%8A%B1%E4%BD%9B%E8%84%9A/:4:0","tags":["Redis"],"title":"Redis抱佛脚","uri":"/redis%E6%8A%B1%E4%BD%9B%E8%84%9A/"},{"categories":["Redis"],"content":"过期策略 定期删除 惰性删除 LRU ","date":"2019-07-23","objectID":"/redis%E6%8A%B1%E4%BD%9B%E8%84%9A/:5:0","tags":["Redis"],"title":"Redis抱佛脚","uri":"/redis%E6%8A%B1%E4%BD%9B%E8%84%9A/"},{"categories":["Redis"],"content":"高并发解决思路 写内存，不写磁盘 异步处理 分布式处理 ","date":"2019-07-23","objectID":"/redis%E6%8A%B1%E4%BD%9B%E8%84%9A/:6:0","tags":["Redis"],"title":"Redis抱佛脚","uri":"/redis%E6%8A%B1%E4%BD%9B%E8%84%9A/"},{"categories":["Redis"],"content":"持久化方式 AOF (追加写日志文件) 内存快照 (全量备份) VM ","date":"2019-07-23","objectID":"/redis%E6%8A%B1%E4%BD%9B%E8%84%9A/:7:0","tags":["Redis"],"title":"Redis抱佛脚","uri":"/redis%E6%8A%B1%E4%BD%9B%E8%84%9A/"},{"categories":["Redis"],"content":"参考资料 https://zhuanlan.zhihu.com/p/59168140 https://zhuanlan.zhihu.com/p/57568995 ","date":"2019-07-23","objectID":"/redis%E6%8A%B1%E4%BD%9B%E8%84%9A/:8:0","tags":["Redis"],"title":"Redis抱佛脚","uri":"/redis%E6%8A%B1%E4%BD%9B%E8%84%9A/"},{"categories":null,"content":"SQL注入 永远不要使用超级用户或所有者帐号去连接数据库，要用权限被严格限制的帐号 检查输入的数据是否具有所期望的数据格式 is_numeric() 、 ctype_digit()等 使用数据库特定的敏感字符转义函数 mysql_escape_string() 、 sql_escape_string()、 addslashes() 、 str_replace() 避免显示出任何有关数据库的信息 白名单列出输入字段 ","date":"2019-07-20","objectID":"/web%E5%AE%89%E5%85%A8%E7%AC%94%E8%AE%B0/:1:0","tags":["Web"],"title":"Web安全备忘","uri":"/web%E5%AE%89%E5%85%A8%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"XSS 跨站脚本攻击 ","date":"2019-07-20","objectID":"/web%E5%AE%89%E5%85%A8%E7%AC%94%E8%AE%B0/:2:0","tags":["Web"],"title":"Web安全备忘","uri":"/web%E5%AE%89%E5%85%A8%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"非持久型(url) Web 页面渲染的所有内容或者渲染的数据都必须来自于服务端 尽量不要从 URL，document.referrer，document.forms 等这种 DOM API 中获取数据直接渲染 尽量不要使用 eval, new Function()，document.write()，document.writeln()，window.setInterval()，window.setTimeout()，innerHTML，document.creteElement() 等可执行字符串的方法 如果做不到以上几点，也必须对涉及 DOM 渲染的方法传入的字符串参数做 escape 转义 前端渲染的时候对任何的字段都需要做 escape 转义编码，escape 转义的目的是将一些构成 HTML 标签的元素转义，比如 \u003c，\u003e，空格 等，转义成 \u003c，\u003e， 等显示转义字符 ","date":"2019-07-20","objectID":"/web%E5%AE%89%E5%85%A8%E7%AC%94%E8%AE%B0/:2:1","tags":["Web"],"title":"Web安全备忘","uri":"/web%E5%AE%89%E5%85%A8%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"持久型(db) 后端在入库前应该选择不相信任何前端数据，将所有的字段统一进行转义处理 后端在输出给前端数据统一进行转义处理 前端在渲染页面 DOM 的时候应该选择不相信任何后端数据，任何字段都需要做转义处理 ","date":"2019-07-20","objectID":"/web%E5%AE%89%E5%85%A8%E7%AC%94%E8%AE%B0/:2:2","tags":["Web"],"title":"Web安全备忘","uri":"/web%E5%AE%89%E5%85%A8%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"CSRF 跨站请求伪造攻击 正确使用 GET，POST 请求和 cookie；在非 GET 请求中增加 token 为每个用户生成一个唯一的 cookie token，所有表单都包含同一个伪随机值，这种方案最简单，因为攻击者不能获得第三方的 cookie(理论上)，所以表单中的数据也就构造失败，但是由于用户的 cookie 很容易由于网站的 XSS 漏洞而被盗取，所以这个方案必须要在没有 XSS 的情况下才安全。 每个 POST 请求使用验证码，这个方案算是比较完美的，但是需要用户多次输入验证码，用户体验比较差，所以不适合在业务中大量运用。 渲染表单的时候，为每一个表单包含一个 csrfToken，提交表单的时候，带上 csrfToken，然后在后端做 csrfToken 验证。 ","date":"2019-07-20","objectID":"/web%E5%AE%89%E5%85%A8%E7%AC%94%E8%AE%B0/:3:0","tags":["Web"],"title":"Web安全备忘","uri":"/web%E5%AE%89%E5%85%A8%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"参考资料 https://baijiahao.baidu.com/s?id=1608462773715109234\u0026wfr=spider\u0026for=pc https://www.php.net/manual/zh/security.database.sql-injection.php ","date":"2019-07-20","objectID":"/web%E5%AE%89%E5%85%A8%E7%AC%94%E8%AE%B0/:4:0","tags":["Web"],"title":"Web安全备忘","uri":"/web%E5%AE%89%E5%85%A8%E7%AC%94%E8%AE%B0/"},{"categories":["计算机网络学习笔记"],"content":"TCP/IP协议族 应用层(HTTP/FTP) 传输层(TCP/UDP) 网络层(IP) 网络接口层(把0、1序列划分为数据帧从一个节点传输到临近的另一个节点) ","date":"2019-07-20","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:1:0","tags":["学习笔记","计算机网络"],"title":"计算机网络学习笔记","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["计算机网络学习笔记"],"content":"HTTP 无状态、无连接 (自HTTP1.1起，可以keep aliva) 请求格式 请求行：请求方法 URL 协议版本 请求头：多个kv对 请求体：请求数据 响应格式 状态行：协议版本 状态码 状态码描述 响应头：多个kv对 响应体：响应数据 常见通用头 Content-Type Accept Content-Length Content-Encoding Accept-Encoding ETag Cache-Control 常见请求头 Authorization User-Agent If-Modified-Since If-Node-Match Cookie Referer Host 常见响应头 Date Last-Modified Transfer-Encoding Set-Cookie Location Server ","date":"2019-07-20","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:2:0","tags":["学习笔记","计算机网络"],"title":"计算机网络学习笔记","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["计算机网络学习笔记"],"content":"HTTPS 对称加密存在被黑客截获消息后伪装的问题 非对称加密存在公钥权威性问题 于是衍生出了CA机构，用于暴保障权威性 ","date":"2019-07-20","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:3:0","tags":["学习笔记","计算机网络"],"title":"计算机网络学习笔记","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["计算机网络学习笔记"],"content":"TCP ","date":"2019-07-20","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:4:0","tags":["学习笔记","计算机网络"],"title":"计算机网络学习笔记","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["计算机网络学习笔记"],"content":"基本性质 面向连接、可靠的字节流服务，使用校验和重传的方式来保证可靠传输 给数据分节进行排序，并使用累计确认来保证数据的顺序不变和非重复 使用滑动窗口机制来实现流量控制 ","date":"2019-07-20","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:4:1","tags":["学习笔记","计算机网络"],"title":"计算机网络学习笔记","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["计算机网络学习笔记"],"content":"三次握手：建立连接 第一次：客户端说：我要和你(服务端)建立连接 第二次：服务端说：好的，可以，你确认要和我建立连接吗 第三次：客户端说：确认 =\u003e 建立连接 三次握手是为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误 如果只需要请求+返回就建立连接，那么在这种情况下如果一个历史的连接建立请求被阻塞在网络中，一段时间后到达服务端的话，服务端会直接返回确认并建立连接，但是客户端已经不需要了，服务端会一直等待这个连接传入数据，造成资源浪费。 ","date":"2019-07-20","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:4:2","tags":["学习笔记","计算机网络"],"title":"计算机网络学习笔记","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["计算机网络学习笔记"],"content":"四次挥手：断开连接 第一次：主机1：我没什么要对你说的了，我想关闭连接可以吗 第二次：主机2：可以 第三次：主机2：我也没什么要对你说的了，我想关闭连接可以吗 第四次：主机1：可以 =\u003e 主机2收到后就关闭连接；主机1发送完成后等待2MSL后关闭连接 TCP是全双工模式，四次挥手是需要双方都确认没有数据要发送后才可以关闭 主机1为啥要等2MSL？ 保证TCP协议的全双工连接能够可靠关闭 如果由于网络延迟等原因，主机2迟迟没有收到主机1的最后确认信息，会一直重复发送FIN信号。 保证这次连接的重复数据段从网络中消失 一种极端情况，两个端口关闭后马上又在相同的端口建立的新的连接，如果原来的数据传输有延迟，那么会被混淆到新的连接里。 ","date":"2019-07-20","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:4:3","tags":["学习笔记","计算机网络"],"title":"计算机网络学习笔记","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["计算机网络学习笔记"],"content":"滑动窗口限流 如果发送方把数据发送得过快，接收方可能会来不及接收，这就会造成数据的丢失。所谓流量控制就是让发送方的发送速率不要太快，要让接收方来得及接收。即接收方通知发送方，我目前能接收多少数据 ","date":"2019-07-20","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:4:4","tags":["学习笔记","计算机网络"],"title":"计算机网络学习笔记","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["计算机网络学习笔记"],"content":"拥塞控制 (逐步试探的过程) 慢开始算法 最开始时发送最小单位，如果网络状况允许，就逐渐翻倍扩大每次发送的数据量。 拥塞避免 当慢开始算法一直翻倍到某个阈值，接下来就是每次把发送的数据量加一个单位，避免一直翻倍造成网络拥塞。 当遇到网络拥塞时，马上把慢开始阈值调成原来的一半，并且把\u0008每次发送的数据量降到1，重新开始执行慢开始算法 快重传 当接收方还没收到3就已经收到456时，对于456的响应都是2，这样发送方就知道缺失了3，马上发送缺失的3 快恢复 当有数据丢失发送后，就想应对网络拥塞一样把慢开始阈值调低一半，但是并不把每次发送的数据量降到1后逐步翻倍，而是降到新阈值的一半后重新开始逐步加1。 ","date":"2019-07-20","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:4:5","tags":["学习笔记","计算机网络"],"title":"计算机网络学习笔记","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["计算机网络学习笔记"],"content":"UDP 不可靠，数据报有长度，无连接，支持多播和广播 ","date":"2019-07-20","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:5:0","tags":["学习笔记","计算机网络"],"title":"计算机网络学习笔记","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["计算机网络学习笔记"],"content":"IP 不可靠 ","date":"2019-07-20","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:6:0","tags":["学习笔记","计算机网络"],"title":"计算机网络学习笔记","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["计算机网络学习笔记"],"content":"参考资料 TCP/IP https://hit-alibaba.github.io/interview/basic/network/ https://zhuanlan.zhihu.com/p/70949908 https://zhuanlan.zhihu.com/p/72587882 https://blog.csdn.net/qzcsu/article/details/72861891 CDN https://zhuanlan.zhihu.com/p/28940451 https://www.jianshu.com/p/1dae6e1680ff ","date":"2019-07-20","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:7:0","tags":["学习笔记","计算机网络"],"title":"计算机网络学习笔记","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"基本组成 nginx由内核和模块组成,模块分为handler、filter、proxy类模块 ","date":"2019-07-20","objectID":"/nginx/:1:0","tags":["Nginx","学习笔记"],"title":"Nginx学习笔记","uri":"/nginx/"},{"categories":null,"content":"进程模型 nginx默认是多进程方式，一个master进程监听socket，并fork多个(worker_process个)worker进程，每个worker进程有个数量为N(worker_connections个)的连接池；这样的一个nginx理论上最大能同时处理worker_process*worker_connections个请求。 ","date":"2019-07-20","objectID":"/nginx/:2:0","tags":["Nginx","学习笔记"],"title":"Nginx学习笔记","uri":"/nginx/"},{"categories":null,"content":"配置文件 nginx的配置文件分为以下几部分 main events HTTP server location upstream ","date":"2019-07-20","objectID":"/nginx/:3:0","tags":["Nginx","学习笔记"],"title":"Nginx学习笔记","uri":"/nginx/"},{"categories":null,"content":"关键参数 worker_process worker进程数 worker_connections 每个worker连接池中连接的数量 use epoll 使用epoll模式 ","date":"2019-07-20","objectID":"/nginx/:3:1","tags":["Nginx","学习笔记"],"title":"Nginx学习笔记","uri":"/nginx/"},{"categories":null,"content":"I/O多路复用 IO模式 阻塞IO：发起请求后等待IO完成才继续执行 非阻塞IO：发起请求后立即拿到结果，但是如果IO没有就绪，还需要不断轮询直到成功 IO多路复用： select：轮询文件描述符，有最大轮询数量限制 poll：轮询文件描述符，无最大轮询数量限制(用了链表) epoll：无需轮询，当有io就绪后通过回调的方式通知内核，内核再调起用户进程 水平触发(LT)：每次都会通知当前已经就绪的文件描述符，直到用户进程处理该描述符 边缘触发(ET)：只在一个描述符由非就绪转为就绪后通知一次，假定用户进程一定会处理 对比：select/poll适合活跃fd比例高的情况(遍历效率高)；epoll适合活跃fd比例低的情况(避免遍历带来的浪费) 异步IO：发起请求后立即拿到结果，当IO就绪后，通知进程 ","date":"2019-07-20","objectID":"/nginx/:4:0","tags":["Nginx","学习笔记"],"title":"Nginx学习笔记","uri":"/nginx/"},{"categories":null,"content":"与PHP交互 ","date":"2019-07-20","objectID":"/nginx/:5:0","tags":["Nginx","学习笔记"],"title":"Nginx学习笔记","uri":"/nginx/"},{"categories":null,"content":"一些定义 CGI：通用网关接口 FastCGI：常驻进程的CGI程序 PHP-FPM：PHP FastCGI Process Manager 主要配置： pm.max_requests 处理N个请求后就重新创建进程 进程启动模式： dynamic pm.max_children 最大wrapper进程数 pm.start_servers 启动时的wrapper进程数 pm.min_spare_servers 保证最小空闲进程数，如果空闲进程小于这个值，就会尝试创建新的进程 pm.max_spare_servers 最大空闲进程数，如果空闲进程大于这个值，就会尝试清理 static pm.max_children 启动N个wrapper进程 对比：动态适合小内存机器，灵活分配进程，省内存。静态适用于大内存机器，动态创建回收进程对服务器资源也是一种消耗。 ","date":"2019-07-20","objectID":"/nginx/:5:1","tags":["Nginx","学习笔记"],"title":"Nginx学习笔记","uri":"/nginx/"},{"categories":null,"content":"关联关系 Nginx拿到php请求后，会转发到指定的socket(同时转发的还有服务器信息和请求信息)，FastCGI的wrapper进程拿到请求后转发给后端的CGI-APP处理(这里即PHP程序)，处理完成后再把结果原路返回给Nginx。 ","date":"2019-07-20","objectID":"/nginx/:5:2","tags":["Nginx","学习笔记"],"title":"Nginx学习笔记","uri":"/nginx/"},{"categories":null,"content":"关联方式 TCP：即ip:port形式，可以跨服务器 UNIX Domain Socket：经过内核，不经过网络 ","date":"2019-07-20","objectID":"/nginx/:5:3","tags":["Nginx","学习笔记"],"title":"Nginx学习笔记","uri":"/nginx/"},{"categories":null,"content":"参考资料 原理：https://zhuanlan.zhihu.com/p/67636582 参数调优 https://www.cnblogs.com/yueminghai/p/8657861.html https://www.cnblogs.com/songgj/p/9113901.html https://blog.csdn.net/fyy1219/article/details/80270845 与php交互 https://blog.csdn.net/wuhuagu_wuhuaguo/article/details/83032578 https://www.jianshu.com/p/eab11cd1bb28 https://www.jianshu.com/p/c892f3f0c9bd I/O多路复用 https://www.jianshu.com/p/dfd940e7fca2 https://segmentfault.com/a/1190000003063859 ","date":"2019-07-20","objectID":"/nginx/:6:0","tags":["Nginx","学习笔记"],"title":"Nginx学习笔记","uri":"/nginx/"},{"categories":null,"content":"join本质上是用驱动表的每个记录去一一匹配被驱动表（会包含重复记录），然后根据条件做优化。 关键点 尽量把条件放到ON后，这里的条件可以用在初次查询中，WHERE中的条件只能用在最后的过滤中 选择数量小的作为驱动表 选择最高效的join算法 算法 Simple Nested-Loop Join：一一遍历，从驱动表中选择一条记录，然后循环匹配表的每一行记录，效率最低。 Index Nested-Loop Join：索引匹配，如果匹配表的条件上有索引，则直接通过索引匹配到对应的记录 Block Nested-Loop Join：Simple Nested-Loop Join的加缓存版，一次读多条记录到缓存内 ","date":"2019-07-14","objectID":"/mysql_join%E5%A4%87%E5%BF%98/:0:0","tags":["MySQL"],"title":"MySQL join操作备忘","uri":"/mysql_join%E5%A4%87%E5%BF%98/"},{"categories":["算法7天练"],"content":"思路 把所有链表的头节点，建立一个最小堆，逐个从堆中拿下最小的节点，并用链表的后续节点补充 分治，分别两两合并 ","date":"2019-07-04","objectID":"/10-merge-k-sorted-lists/:1:0","tags":["算法","leetcode"],"title":"合并多个链表","uri":"/10-merge-k-sorted-lists/"},{"categories":["算法7天练"],"content":"问题 分治和遍历的差别是：每次分治处理之后，样本数量都会降低1/2 分治的边界把握很重要 ","date":"2019-07-04","objectID":"/10-merge-k-sorted-lists/:2:0","tags":["算法","leetcode"],"title":"合并多个链表","uri":"/10-merge-k-sorted-lists/"},{"categories":["算法7天练"],"content":"代码 /** * Definition for singly-linked list. * type ListNode struct { * Val int * Next *ListNode * } */ func mergeKLists(lists []*ListNode) *ListNode { if len(lists) == 0 { return nil } begin, end := 0, len(lists) - 1 for begin \u003c end { mid := (begin + end - 1) / 2 for i:=0; i\u003c=mid; i++ { lists[i] = mergeTwoLists(lists[i], lists[end-i]) } end = (begin + end) / 2 } return lists[0] } //合并两个有序链表 func mergeTwoLists(head1, head2 *ListNode) *ListNode { if head1 == nil { return head2 } if head2 == nil { return head1 } if head1.Val \u003c head2.Val { head1.Next = mergeTwoLists(head1.Next, head2) return head1 } else { head2.Next = mergeTwoLists(head1, head2.Next) return head2 } } ","date":"2019-07-04","objectID":"/10-merge-k-sorted-lists/:3:0","tags":["算法","leetcode"],"title":"合并多个链表","uri":"/10-merge-k-sorted-lists/"},{"categories":["算法7天练"],"content":"思路 使用快慢两个指针，如果两个指针相遇，则链表有环；如果快指针先走到链表尾，则链表无环 ","date":"2019-07-04","objectID":"/9-linked-list-cycle/:1:0","tags":["算法","leetcode"],"title":"判断链表是否有环","uri":"/9-linked-list-cycle/"},{"categories":["算法7天练"],"content":"问题 判等操作应该在指针迁移一次后再做，否则所有都会被判定为true 传入参数可能为空，异常处理需要作为一个下意识；这里把它放到对fast指针的判定一起判断 ","date":"2019-07-04","objectID":"/9-linked-list-cycle/:2:0","tags":["算法","leetcode"],"title":"判断链表是否有环","uri":"/9-linked-list-cycle/"},{"categories":["算法7天练"],"content":"代码 type ListNode struct { Val int Next *ListNode } func hasCycle(head *ListNode) bool { fast, slow := head, head for { if fast != nil \u0026\u0026 fast.Next != nil \u0026\u0026 fast.Next.Next != nil { fast = fast.Next.Next } else { return false } slow = slow.Next if fast == slow { return true } } } ","date":"2019-07-04","objectID":"/9-linked-list-cycle/:3:0","tags":["算法","leetcode"],"title":"判断链表是否有环","uri":"/9-linked-list-cycle/"},{"categories":["算法7天练"],"content":"思路 思路一：排序，然而不能满足空间复杂度的要求 思路二：把每个位置的有效num，与num-1位置的元素交换，然后遍历处理后的数组，第一个元素值不等于索引值+1的位置，即为缺失的第一个正数 ","date":"2019-07-03","objectID":"/8-first-missing-positive/:1:0","tags":["算法","leetcode"],"title":"寻找第一个缺失的正数","uri":"/8-first-missing-positive/"},{"categories":["算法7天练"],"content":"问题 有效：大于0，且num小于等于数组容量的元素是有效元素； 交换时把指针位置交换到了其他位置，需要继续再该位置交换，直到该位置没有可交换的元素才能移动；否则可能会出现被换到这个位置的元素需要被处理，但是没有被处理；case:[3,4,-1,1] ","date":"2019-07-03","objectID":"/8-first-missing-positive/:2:0","tags":["算法","leetcode"],"title":"寻找第一个缺失的正数","uri":"/8-first-missing-positive/"},{"categories":["算法7天练"],"content":"代码 package main import \"fmt\" func main() { nums := []int{3,4,-1,1} r := firstMissingPositive(nums) fmt.Println(r) } func firstMissingPositive(nums []int) int { for i:=0; i\u003clen(nums); { num := nums[i] if num \u003e 0 \u0026\u0026 num \u003c= len(nums) \u0026\u0026 nums[num-1] != num { nums[num-1], nums[i] = nums[i], nums[num-1] } else { i++ } } for i, num := range nums { if num != i+1 { return i+1 } } return len(nums) + 1 } ","date":"2019-07-03","objectID":"/8-first-missing-positive/:3:0","tags":["算法","leetcode"],"title":"寻找第一个缺失的正数","uri":"/8-first-missing-positive/"},{"categories":["算法7天练"],"content":"思路 思路一：使用一个hash表，统计每个元素出现的次数 思路二：用一个变量result暂存当前的数字，遇到一个数字如果是result，就给count+1，否则给count-1；当count = 0时，更换result；这样如果一定有一个大多数，最终的reuslt中存的一定是所求 ","date":"2019-07-03","objectID":"/7-majority-element/:1:0","tags":["算法","leetcode"],"title":"求大多数","uri":"/7-majority-element/"},{"categories":["算法7天练"],"content":"问题 思路很清晰，代码很简单，唯一的问题是这个思路二一般人真的是想不到… ","date":"2019-07-03","objectID":"/7-majority-element/:2:0","tags":["算法","leetcode"],"title":"求大多数","uri":"/7-majority-element/"},{"categories":["算法7天练"],"content":"代码 package main import \"fmt\" func main() { nums := []int{3,2,3} r := majorityElement(nums) fmt.Println(r) } func majorityElement(nums []int) int { result, count := 0, 0 for _, num := range nums { if count == 0 { result = num count++ } else { if num == result { count++ } else { count-- } } } return result } ","date":"2019-07-03","objectID":"/7-majority-element/:3:0","tags":["算法","leetcode"],"title":"求大多数","uri":"/7-majority-element/"},{"categories":["算法7天练"],"content":"思路 ","date":"2019-07-03","objectID":"/6-3-sum/:1:0","tags":["算法","leetcode"],"title":"3 sum","uri":"/6-3-sum/"},{"categories":["算法7天练"],"content":"2 sum的三种解法 暴力两重循环 O(n^2) map+一重循环 O(n) + O(n) 排序+一重循环 O(nlogn) ","date":"2019-07-03","objectID":"/6-3-sum/:1:1","tags":["算法","leetcode"],"title":"3 sum","uri":"/6-3-sum/"},{"categories":["算法7天练"],"content":"3 sum的三种解法 暴力三重循环 O(n^3) map+两重循环 O(n) + O(n^2) 排序+两重循环 O(n^2) ","date":"2019-07-03","objectID":"/6-3-sum/:1:2","tags":["算法","leetcode"],"title":"3 sum","uri":"/6-3-sum/"},{"categories":["算法7天练"],"content":"问题 核心问题是去重 相同的值需要快进，避免重复 遍历的时候需要从最外层指针的右侧开始夹逼，避免重复 先快进，再++ 保证比较过后再快进(如果先++后快进，更容易抵达j\u003e=k导致循环退出，错过结果) ","date":"2019-07-03","objectID":"/6-3-sum/:2:0","tags":["算法","leetcode"],"title":"3 sum","uri":"/6-3-sum/"},{"categories":["算法7天练"],"content":"代码 package main import \"fmt\" func main() { r := threeSum([]int{-2,0,1,1,2}, 0) fmt.Println(r) } /* 核心问题就是去重 1.相同的值需要快进，避免重复 2.遍历的时候需要从最外层指针的右侧开始夹逼，避免重复 3.先快进，再++ 保证比较过后再快进(如果先++后快进,更容易抵达j\u003ck导致循环退出) */ func threeSum(nums []int, target int) [][]int { quickSort(nums, 0, len(nums) - 1) fmt.Println(nums) result := [][]int{} for i:=0; i\u003clen(nums); i++ { j, k := i + 1, len(nums) - 1 fmt.Println(\"i+++\") for j \u003c k { fmt.Printf(\"1:i:%d,j:%d,k:%d;nums[i]:%d,nums[j]:%d,nums[k]:%d\\n\", i, j, k, nums[i], nums[j], nums[k]) if nums[i] + nums[j] + nums[k] == target \u0026\u0026 i != j \u0026\u0026 j != k \u0026\u0026 i != k { result = append(result, []int{nums[i], nums[j], nums[k]}) for j \u003c k \u0026\u0026 nums[j] == nums[j+1] { fmt.Println(\"j++\") j++ } for j \u003c k \u0026\u0026 nums[k] == nums[k-1] { fmt.Println(\"k--\") k-- } for i \u003c len(nums) - 1 \u0026\u0026 nums[i] == nums[i+1] { fmt.Println(\"i++\") i++ } j++ k-- } else if nums[i] + nums[j] + nums[k] \u003c target { fmt.Println(\"j++\") j++ } else { k-- fmt.Println(\"k--\") } fmt.Printf(\"2:i:%d,j:%d,k:%d;nums[i]:%d,nums[j]:%d,nums[k]:%d\\n\", i, j, k, nums[i], nums[j], nums[k]) } } return result } //快速排序 func quickSort(data []int, left, right int) { if left \u003e= right { return ; } flag := data[left]; i, j := left, right; for i \u003c j { //← for i \u003c j \u0026\u0026 data[j] \u003e= flag { j--; } if i \u003c j { data[i] = data[j]; i++; } //→ for i \u003c j \u0026\u0026 data[i] \u003c flag { i++; } if i \u003c j { data[j] = data[i]; j--; } } data[i] = flag; quickSort(data, left, i); quickSort(data, i+1, right); } ","date":"2019-07-03","objectID":"/6-3-sum/:3:0","tags":["算法","leetcode"],"title":"3 sum","uri":"/6-3-sum/"},{"categories":["算法7天练"],"content":"一下能想到的是暴力解法，先遍历链表获取链表节点总数，然后求出中点的索引值，这样的时间复杂度是O(n)； 稍微优化一下的话就是使用经典的快慢节点的方式，每次遍历时快节点前进两位，慢节点前进一位，当快节点走到链表结尾时，慢节点所在的位置就是链表中点，这样的时间复杂度是O(n/2)，量级没有变化，但是会快一些。 package main import \"fmt\" type node struct { val int next *node } func main() { //0-\u003e1...10 head := \u0026node{10, nil} for i:=9; i\u003e=0; i-- { head = \u0026node{i, head} } midpoint := getMidpoint(head) fmt.Println(midpoint) } //获取链表中点 func getMidpoint(head *node) int { slow, fast := head, head slowIndex, fastIndex := 0, 0 for (fast != nil) \u0026\u0026 (fast.next != nil) { slow = slow.next slowIndex++ fast = fast.next.next fastIndex = fastIndex + 2 } return slowIndex } ","date":"2019-06-29","objectID":"/5-%E6%B1%82%E9%93%BE%E8%A1%A8%E7%9A%84%E4%B8%AD%E9%97%B4%E8%8A%82%E7%82%B9/:0:0","tags":["算法","leetcode"],"title":"求链表的中间节点","uri":"/5-%E6%B1%82%E9%93%BE%E8%A1%A8%E7%9A%84%E4%B8%AD%E9%97%B4%E8%8A%82%E7%82%B9/"},{"categories":["算法7天练"],"content":"递归 补：2019-07-04发现了屌炸天的递归算法，补上它 理解这个递归的核心是，该函数每次都会返回剩余元素中最小的一个；或者一个链表已空，则返回剩余的；这一点保证了head1.next = mergeRecursion(head1.next, head2)一定能链接到下一个最小的元素，这里依然利用了递归深入的过程中就能保存顺序这一特性，代码极其简单。 func mergeRecursion(head1, head2 *node) *node { if head1 == nil { return head2 } if head2 == nil { return head1 } if head1.val \u003c head2.val { head1.next = mergeRecursion(head1.next, head2) return head1 } else { head2.next = mergeRecursion(head1, head2.next) return head2 } } ","date":"2019-06-29","objectID":"/4-%E5%90%88%E5%B9%B6%E6%9C%89%E5%BA%8F%E9%93%BE%E8%A1%A8/:1:0","tags":["算法","leetcode"],"title":"合并两个有序链表","uri":"/4-%E5%90%88%E5%B9%B6%E6%9C%89%E5%BA%8F%E9%93%BE%E8%A1%A8/"},{"categories":["算法7天练"],"content":"遍历 遍历算法和合并有序数组思路基本一致 package main import \"fmt\" type node struct { val int next *node } func main() { //0-\u003e2-\u003e4-\u003e6-\u003e8-\u003e10 head1 := \u0026node{10, nil} for i:=8; i\u003e0; i=i-2 { head1 = \u0026node{i, head1} } //1-\u003e3-\u003e5-\u003e7-\u003e9 head2 := \u0026node{9, nil} for i:=7; i\u003e0; i=i-2 { head2 = \u0026node{i, head2} } head := merge(head1, head2) for head != nil { fmt.Println(head.val) head = head.next } } //合并两个有序链表 func merge(head1, head2 *node) *node { if head1 == nil { return head2 } if head2 == nil { return head1 } head := \u0026node{} node := head node1 := head1 node2 := head2 for (node1 != nil) || (node2 != nil) { if node1 == nil { node = appendNode(node, node2) node2 = node2.next continue } if node2 == nil { node = appendNode(node, node1) node1 = node1.next continue } if node1.val \u003c node2.val { node = appendNode(node, node1) node1 = node1.next continue } else { node = appendNode(node, node2) node2 = node2.next continue } } return head } //辅助函数 func appendNode(node, node1 *node) *node { if node == nil { node = node1 } else { node.next = node1 node = node.next } return node } ","date":"2019-06-29","objectID":"/4-%E5%90%88%E5%B9%B6%E6%9C%89%E5%BA%8F%E9%93%BE%E8%A1%A8/:2:0","tags":["算法","leetcode"],"title":"合并两个有序链表","uri":"/4-%E5%90%88%E5%B9%B6%E6%9C%89%E5%BA%8F%E9%93%BE%E8%A1%A8/"},{"categories":["算法7天练"],"content":"递归反转链表的基本思路是先用递归深入到最后一个节点，把最后一个节点传递返回，作为新的头节点；跳出递归的过程中把每个节点的后一个节点指向自身，并把自身的next指向空(为了把原头节点的next清空)。 如果不用递归，从前到后遍历每个节点时，需要关注很多节点，以及很多边界情况；递归的方法比较简洁的原因是递归的深入过程中自然记录了节点顺序，就能够从后向前调整，每次调整都只关注两个节点即可。 package main import \"fmt\" type node struct { val int next *node } func main() { //0-\u003e1...10 head := \u0026node{10, nil} for i:=9; i\u003e=0; i-- { head = \u0026node{i, head} } head = reverse(head); for head != nil { fmt.Println(head.val) head = head.next } } //递归反转链表 func reverse(head *node) *node { if head == nil || head.next == nil { return head; } nHead := reverse(head.next); head.next.next = head; head.next = nil; return nHead; } ","date":"2019-06-29","objectID":"/3-%E5%8D%95%E9%93%BE%E8%A1%A8%E5%8F%8D%E8%BD%AC/:0:0","tags":["算法","leetcode"],"title":"单链表反转","uri":"/3-%E5%8D%95%E9%93%BE%E8%A1%A8%E5%8F%8D%E8%BD%AC/"},{"categories":["算法7天练"],"content":"如果有的选，选一个小的；如果没的选，把另外一个遍历完。 package main import \"fmt\" //合并两个有序数组 func merge(array1, array2 []int) []int { result := []int{} i, j := 0, 0 for (i \u003c= len(array1)-1) || (j \u003c= len(array2)-1) { //两个数组如果其中一个已遍历完成,持续累加另一个 if i \u003e (len(array1)-1) { result = append(result, array2[j]) j++ continue } if j \u003e (len(array2)-1) { result = append(result, array1[i]) i++ continue } //从个数组中选择一个小的 if array1[i] \u003c array2[j] { result = append(result, array1[i]) i++ } else { result = append(result, array2[j]) j++ } } return result } //测试 func main() { result := merge([]int{1, 3, 5, 7, 9}, []int{2, 4, 6, 8, 10}) fmt.Println(result) } ","date":"2019-06-29","objectID":"/2-%E5%90%88%E5%B9%B6%E6%9C%89%E5%BA%8F%E6%95%B0%E7%BB%84/:0:0","tags":["算法","leetcode"],"title":"合并两个有序数组","uri":"/2-%E5%90%88%E5%B9%B6%E6%9C%89%E5%BA%8F%E6%95%B0%E7%BB%84/"},{"categories":["算法7天练"],"content":"这里实现了一个能够动态扩容和缩容的数组，动态数组的核心在于扩容和缩容策略，这里采用的策略如下 扩容：当数组满了以后，把容量扩充为原来的两倍 缩容：当数组使用率低于1/4，把容量缩小为原来的一半 不在低于1/2时就缩容是为了避免在临界点反复增删导致的频繁扩容缩容导致的性能问题 package main import \"fmt\" //数据结构 type array struct { data []interface{} size int capacity int } //数组接口 type arrayInterface interface { add(int, interface{}) remove(int) interface{} set(int, interface{}) get(int) interface{} } //构造函数 func getArray(capacity int) *array { result := \u0026array{} result.data = make([]interface{}, capacity) result.size = 0 result.capacity = capacity return result } //扩容/缩容数组 func (this *array) resize(capacity int) { //创建一个指定大小的新数组 newData := make([]interface{}, capacity) //把this.data中的数据搬到新数组中 for i:=0; i\u003cthis.size; i++ { newData[i] = this.data[i] } //把this.data更新为新数组 this.data = newData //更新容量 this.capacity = capacity } //增 func (this *array) add(index int, element interface{}) { //合法性判断 if (index \u003c 0) || (index \u003e this.capacity) { panic(\"index must \u003e= 0 and \u003c= capacity\") } //判断是否需要扩容 if len(this.data) == this.size { this.resize(this.size * 2) } //插入位置及其之后的位置,需要向后移动 for i:=this.size-1; i\u003e=index; i-- { this.data[i+1] = this.data[i] } //赋值 this.data[index] = element //数组规模增加 this.size++ } //删 func (this *array) remove(index int) interface{} { //合法性判断 if (index \u003c 0) || (index \u003e this.capacity) { panic(\"index must \u003e= 0 and \u003c= capacity\") } //缓存要删除的元素 removeElement := this.data[index] //删除位置及其之后的位置,需要向前移动 for i:=index; i\u003cthis.size-1; i++ { this.data[i] = this.data[i+1] } //数组规则减少 this.size-- //清理最后一个元素 this.data[this.size] = nil //缩容 if (this.size \u003c len(this.data)/4) \u0026\u0026 (len(this.data)/2 != 0) { this.resize(len(this.data)/2) } return removeElement } //改 func (this *array) set(index int, element interface{}) { //合法性判断 if (index \u003c 0) || (index \u003e this.capacity) { panic(\"index must \u003e= 0 and \u003c= capacity\") } //赋值 this.data[index] = element } //查 func (this *array) get(index int) interface{} { //合法性判断 if (index \u003c 0) || (index \u003e this.capacity) { panic(\"index must \u003e= 0 and \u003c= capacity\") } return this.data[index] } //测试代码 func main() { testArr := getArray(10) for i:=0; i\u003c10; i++ { testArr.add(0, i) } for i:=0; i\u003c10; i++ { testArr.remove(0) } testArr.set(0, 1) testArr.set(1, 2) r := testArr.get(1) fmt.Println(r) } 参考：https://segmentfault.com/a/1190000015680429 ","date":"2019-06-29","objectID":"/1-%E5%8A%A8%E6%80%81%E6%95%B0%E7%BB%84/:0:0","tags":["算法","leetcode"],"title":"动态数组","uri":"/1-%E5%8A%A8%E6%80%81%E6%95%B0%E7%BB%84/"},{"categories":["算法7天练"],"content":"Day 1：数组和链表 ","date":"2019-06-28","objectID":"/0-%E7%9B%AE%E5%BD%95/:0:0","tags":["算法","leetcode"],"title":"算法7天练目录","uri":"/0-%E7%9B%AE%E5%BD%95/"},{"categories":["算法7天练"],"content":"数组 实现一个动态扩容的数组：这里 实现一个大小固定的有序数组，支持动态增删改查操作 这个不知道咋下手 实现两个有序数组合并为一个有序数组 这里 ","date":"2019-06-28","objectID":"/0-%E7%9B%AE%E5%BD%95/:1:0","tags":["算法","leetcode"],"title":"算法7天练目录","uri":"/0-%E7%9B%AE%E5%BD%95/"},{"categories":["算法7天练"],"content":"链表 实现单链表、循环链表、双向链表，支持增删操作 这个不知道咋下手 实现单链表反转 这里 实现两个有序链表合并为一个有序链表 这里 实现求链表的中间节点 这里 ","date":"2019-06-28","objectID":"/0-%E7%9B%AE%E5%BD%95/:2:0","tags":["算法","leetcode"],"title":"算法7天练目录","uri":"/0-%E7%9B%AE%E5%BD%95/"},{"categories":["算法7天练"],"content":"LeetCode ","date":"2019-06-28","objectID":"/0-%E7%9B%AE%E5%BD%95/:3:0","tags":["算法","leetcode"],"title":"算法7天练目录","uri":"/0-%E7%9B%AE%E5%BD%95/"},{"categories":["算法7天练"],"content":"数组 https://leetcode.com/problems/3sum/ 这里 https://leetcode.com/problems/majority-element/ 这里 https://leetcode.com/problems/first-missing-positive/ 这里 ","date":"2019-06-28","objectID":"/0-%E7%9B%AE%E5%BD%95/:3:1","tags":["算法","leetcode"],"title":"算法7天练目录","uri":"/0-%E7%9B%AE%E5%BD%95/"},{"categories":["算法7天练"],"content":"链表 https://leetcode.com/problems/linked-list-cycle/ 这里 https://leetcode.com/problems/merge-k-sorted-lists/ 这里 Day 2：栈、队列和递归 ","date":"2019-06-28","objectID":"/0-%E7%9B%AE%E5%BD%95/:3:2","tags":["算法","leetcode"],"title":"算法7天练目录","uri":"/0-%E7%9B%AE%E5%BD%95/"},{"categories":["算法7天练"],"content":"栈 用数组实现一个顺序栈 用链表实现一个链式栈 编程模拟一个浏览器的前进、后退功能 ","date":"2019-06-28","objectID":"/0-%E7%9B%AE%E5%BD%95/:4:0","tags":["算法","leetcode"],"title":"算法7天练目录","uri":"/0-%E7%9B%AE%E5%BD%95/"},{"categories":["算法7天练"],"content":"队列 用数组实现一个顺序队列 用链表实现一个链式队列 实现一个循环队列 ","date":"2019-06-28","objectID":"/0-%E7%9B%AE%E5%BD%95/:5:0","tags":["算法","leetcode"],"title":"算法7天练目录","uri":"/0-%E7%9B%AE%E5%BD%95/"},{"categories":["算法7天练"],"content":"递归 编程实现斐波那契数列 编程求阶乘 编程实现一组数据集合的全排列 ","date":"2019-06-28","objectID":"/0-%E7%9B%AE%E5%BD%95/:6:0","tags":["算法","leetcode"],"title":"算法7天练目录","uri":"/0-%E7%9B%AE%E5%BD%95/"},{"categories":["算法7天练"],"content":"LeetCode ","date":"2019-06-28","objectID":"/0-%E7%9B%AE%E5%BD%95/:7:0","tags":["算法","leetcode"],"title":"算法7天练目录","uri":"/0-%E7%9B%AE%E5%BD%95/"},{"categories":["算法7天练"],"content":"栈 https://leetcode.com/problems/valid-parentheses/ https://leetcode.com/problems/longest-valid-parentheses/ https://leetcode.com/problems/evaluate-reverse-polish-notation/ ","date":"2019-06-28","objectID":"/0-%E7%9B%AE%E5%BD%95/:7:1","tags":["算法","leetcode"],"title":"算法7天练目录","uri":"/0-%E7%9B%AE%E5%BD%95/"},{"categories":["算法7天练"],"content":"队列 https://leetcode.com/problems/design-circular-deque/ https://leetcode.com/problems/sliding-window-maximum/ ","date":"2019-06-28","objectID":"/0-%E7%9B%AE%E5%BD%95/:7:2","tags":["算法","leetcode"],"title":"算法7天练目录","uri":"/0-%E7%9B%AE%E5%BD%95/"},{"categories":["算法7天练"],"content":"递归 https://leetcode.com/problems/climbing-stairs/ Day 3：排序和二分查找 ","date":"2019-06-28","objectID":"/0-%E7%9B%AE%E5%BD%95/:7:3","tags":["算法","leetcode"],"title":"算法7天练目录","uri":"/0-%E7%9B%AE%E5%BD%95/"},{"categories":["算法7天练"],"content":"排序 实现归并排序、快速排序、插入排序、冒泡排序、选择排序 编程实现O(n)复杂度内找到一组数据的第K大元素 ","date":"2019-06-28","objectID":"/0-%E7%9B%AE%E5%BD%95/:8:0","tags":["算法","leetcode"],"title":"算法7天练目录","uri":"/0-%E7%9B%AE%E5%BD%95/"},{"categories":["算法7天练"],"content":"二分查找 实现一个有序数组的二分查找算法 实现模糊二分查找算法(比如大于等于给定值的第一个元素) ","date":"2019-06-28","objectID":"/0-%E7%9B%AE%E5%BD%95/:9:0","tags":["算法","leetcode"],"title":"算法7天练目录","uri":"/0-%E7%9B%AE%E5%BD%95/"},{"categories":["算法7天练"],"content":"LeetCode https://leetcode.com/problems/sqrtx/ Day 4：散列表和字符串 ","date":"2019-06-28","objectID":"/0-%E7%9B%AE%E5%BD%95/:10:0","tags":["算法","leetcode"],"title":"算法7天练目录","uri":"/0-%E7%9B%AE%E5%BD%95/"},{"categories":["算法7天练"],"content":"散列表 实现一个基于链表法解决冲突问题的散列表 实现一个LRU缓存淘汰算法 ","date":"2019-06-28","objectID":"/0-%E7%9B%AE%E5%BD%95/:11:0","tags":["算法","leetcode"],"title":"算法7天练目录","uri":"/0-%E7%9B%AE%E5%BD%95/"},{"categories":["算法7天练"],"content":"字符串 实现一个字符集只包含a~z这26个字母的Trie树 实现朴素的字符串匹配算法 ","date":"2019-06-28","objectID":"/0-%E7%9B%AE%E5%BD%95/:12:0","tags":["算法","leetcode"],"title":"算法7天练目录","uri":"/0-%E7%9B%AE%E5%BD%95/"},{"categories":["算法7天练"],"content":"LeetCode ","date":"2019-06-28","objectID":"/0-%E7%9B%AE%E5%BD%95/:13:0","tags":["算法","leetcode"],"title":"算法7天练目录","uri":"/0-%E7%9B%AE%E5%BD%95/"},{"categories":["算法7天练"],"content":"字符串 https://leetcode.com/problems/reverse-string/ https://leetcode.com/problems/reverse-words-in-a-string/ https://leetcode.com/problems/string-to-integer-atoi/ Day 5：二叉树和堆 ","date":"2019-06-28","objectID":"/0-%E7%9B%AE%E5%BD%95/:13:1","tags":["算法","leetcode"],"title":"算法7天练目录","uri":"/0-%E7%9B%AE%E5%BD%95/"},{"categories":["算法7天练"],"content":"二叉树 实现一个二叉查找树，并且支持插入、删除、查找操作 实现查找二叉查找树中某个节点的后继、前驱节点 实现二叉树前、中、后序以及按层遍历 ","date":"2019-06-28","objectID":"/0-%E7%9B%AE%E5%BD%95/:14:0","tags":["算法","leetcode"],"title":"算法7天练目录","uri":"/0-%E7%9B%AE%E5%BD%95/"},{"categories":["算法7天练"],"content":"堆 实现一个小顶堆、大顶堆、优先级队列 实现堆排序 利用优先级队列合并 K 个有序数组 求一组动态数据集合的最大 Top K ","date":"2019-06-28","objectID":"/0-%E7%9B%AE%E5%BD%95/:15:0","tags":["算法","leetcode"],"title":"算法7天练目录","uri":"/0-%E7%9B%AE%E5%BD%95/"},{"categories":["算法7天练"],"content":"LeetCode https://leetcode.com/problems/invert-binary-tree/ https://leetcode.com/problems/maximum-depth-of-binary-tree/ https://leetcode.com/problems/validate-binary-search-tree/ https://leetcode.com/problems/path-sum/ Day 6：图 实现有向图、无向图、有权图、无权图的邻接矩阵和邻接表表示方法 实现图的深度优先搜索、广度优先搜索 实现 Dijkstra 算法、A* 算法 实现拓扑排序的 Kahn 算法、DFS 算法 ","date":"2019-06-28","objectID":"/0-%E7%9B%AE%E5%BD%95/:16:0","tags":["算法","leetcode"],"title":"算法7天练目录","uri":"/0-%E7%9B%AE%E5%BD%95/"},{"categories":["算法7天练"],"content":"LeetCode https://leetcode.com/problems/number-of-islands/description/ https://leetcode.com/problems/valid-sudoku/ Day 7：贪心、分治、回溯和动态规划 ","date":"2019-06-28","objectID":"/0-%E7%9B%AE%E5%BD%95/:17:0","tags":["算法","leetcode"],"title":"算法7天练目录","uri":"/0-%E7%9B%AE%E5%BD%95/"},{"categories":["算法7天练"],"content":"回溯 利用回溯算法求解八皇后问题 利用回溯算法求解 0-1 背包问题 ","date":"2019-06-28","objectID":"/0-%E7%9B%AE%E5%BD%95/:18:0","tags":["算法","leetcode"],"title":"算法7天练目录","uri":"/0-%E7%9B%AE%E5%BD%95/"},{"categories":["算法7天练"],"content":"分治 利用分治算法求一组数据的逆序对个数 ","date":"2019-06-28","objectID":"/0-%E7%9B%AE%E5%BD%95/:19:0","tags":["算法","leetcode"],"title":"算法7天练目录","uri":"/0-%E7%9B%AE%E5%BD%95/"},{"categories":["算法7天练"],"content":"动态规划 0-1 背包问题 最小路径和 编程实现莱文斯坦最短编辑距离 编程实现查找两个字符串的最长公共子序列 编程实现一个数据序列的最长递增子序列 ","date":"2019-06-28","objectID":"/0-%E7%9B%AE%E5%BD%95/:20:0","tags":["算法","leetcode"],"title":"算法7天练目录","uri":"/0-%E7%9B%AE%E5%BD%95/"},{"categories":["算法7天练"],"content":"LeetCode https://leetcode.com/problems/regular-expression-matching/ https://leetcode.com/problems/minimum-path-sum/ https://leetcode.com/problems/coin-change/ https://leetcode.com/problems/best-time-to-buy-and-sell-stock/ https://leetcode.com/problems/maximum-product-subarray/ https://leetcode.com/problems/triangle/ ","date":"2019-06-28","objectID":"/0-%E7%9B%AE%E5%BD%95/:21:0","tags":["算法","leetcode"],"title":"算法7天练目录","uri":"/0-%E7%9B%AE%E5%BD%95/"},{"categories":["Yii2"],"content":"《深入理解Yii2.0》 今天是周日 花了一个上午+半个下午的时间看完了这本“书”，链接：http://www.digpage.com/index.html 其中【Yii基础】和【Yii模式部分】两部分写得很赞，很有启发，非常感谢作者，这里记录下这两部分的笔记； 但是【Yii与数据库】部分稍感深度不够，只罗列了事件和事件的基本原理，没有给出各个数据库相关的类以及关联关系。 ","date":"2019-06-23","objectID":"/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3yii2.0%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:1:0","tags":["Yii2","学习笔记","PHP"],"title":"《深入理解Yii2.0》学习笔记","uri":"/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3yii2.0%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["Yii2"],"content":"Yii基础 ","date":"2019-06-23","objectID":"/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3yii2.0%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:1:1","tags":["Yii2","学习笔记","PHP"],"title":"《深入理解Yii2.0》学习笔记","uri":"/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3yii2.0%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["Yii2"],"content":"依赖注入 ","date":"2019-06-23","objectID":"/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3yii2.0%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:1:2","tags":["Yii2","学习笔记","PHP"],"title":"《深入理解Yii2.0》学习笔记","uri":"/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3yii2.0%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["Yii2"],"content":"整体 图中的所有绑定、解绑、注册、注入等操作，都是在对应的属性数组中插入或删除元素。 ","date":"2019-06-23","objectID":"/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3yii2.0%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:1:3","tags":["Yii2","学习笔记","PHP"],"title":"《深入理解Yii2.0》学习笔记","uri":"/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3yii2.0%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["Yii2"],"content":"粗读代码 上面的书里给出了Yii的概览情况，我又趁热打铁，花了后面半个下午的事件粗读了几个重要类的代码，这里贴出梗概备忘。 ","date":"2019-06-23","objectID":"/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3yii2.0%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:2:0","tags":["Yii2","学习笔记","PHP"],"title":"《深入理解Yii2.0》学习笔记","uri":"/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3yii2.0%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["Yii2"],"content":"数据模型 ","date":"2019-06-23","objectID":"/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3yii2.0%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:2:1","tags":["Yii2","学习笔记","PHP"],"title":"《深入理解Yii2.0》学习笔记","uri":"/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3yii2.0%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["Yii2"],"content":"控制器 ","date":"2019-06-23","objectID":"/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3yii2.0%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:2:2","tags":["Yii2","学习笔记","PHP"],"title":"《深入理解Yii2.0》学习笔记","uri":"/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3yii2.0%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["Yii2"],"content":"独立动作 How a full day bye. ","date":"2019-06-23","objectID":"/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3yii2.0%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:2:3","tags":["Yii2","学习笔记","PHP"],"title":"《深入理解Yii2.0》学习笔记","uri":"/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3yii2.0%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["Linux性能优化学习笔记"],"content":"网络协议栈 ","date":"2019-06-22","objectID":"/4-%E7%BD%91%E7%BB%9C/:1:0","tags":["Linux","学习笔记"],"title":"4.网络性能分析","uri":"/4-%E7%BD%91%E7%BB%9C/"},{"categories":["Linux性能优化学习笔记"],"content":"性能指标 带宽 吞吐量 延时 PPS 各层性能 转发性能 TCP/UDP性能 HTTP性能 应用负载性能 ","date":"2019-06-22","objectID":"/4-%E7%BD%91%E7%BB%9C/:2:0","tags":["Linux","学习笔记"],"title":"4.网络性能分析","uri":"/4-%E7%BD%91%E7%BB%9C/"},{"categories":["Linux性能优化学习笔记"],"content":"工具字典 ","date":"2019-06-22","objectID":"/4-%E7%BD%91%E7%BB%9C/:3:0","tags":["Linux","学习笔记"],"title":"4.网络性能分析","uri":"/4-%E7%BD%91%E7%BB%9C/"},{"categories":["Linux性能优化学习笔记"],"content":"I/O栈 ","date":"2019-06-22","objectID":"/3-io/:1:0","tags":["Linux","学习笔记"],"title":"3.I/O性能分析","uri":"/3-io/"},{"categories":["Linux性能优化学习笔记"],"content":"性能指标 文件系统I/O性能指标 存储空间使用情况 容量 使用量 剩余量 索引节点使用情况 容量 使用量 剩余量 缓存使用情况 页缓存 目录项缓存 索引节点缓存 各文件系统的缓存 文件I/O IOPS(r/s、w/s) 响应时间(延迟) 吞吐量(B/s) 磁盘系统I/O性能指标 使用率 指磁盘忙处理 I/O 请求的百分比。 IOPS 吞吐量 响应时间 ","date":"2019-06-22","objectID":"/3-io/:2:0","tags":["Linux","学习笔记"],"title":"3.I/O性能分析","uri":"/3-io/"},{"categories":["Linux性能优化学习笔记"],"content":"工具字典 ","date":"2019-06-22","objectID":"/3-io/:3:0","tags":["Linux","学习笔记"],"title":"3.I/O性能分析","uri":"/3-io/"},{"categories":["Linux性能优化学习笔记"],"content":"分析思路 ","date":"2019-06-22","objectID":"/3-io/:4:0","tags":["Linux","学习笔记"],"title":"3.I/O性能分析","uri":"/3-io/"},{"categories":["Linux性能优化学习笔记"],"content":"性能指标 系统内存使用情况 已用内存 共享内存 可用内存 进程内存使用情况 虚拟内存 包括进程代码段、数据段、共享内存、已经申请的堆内存和已经换出的内存等 已经申请的内存，即使还没有分配物理内存，也算作虚拟内存 虚拟内存需要通过MMU映射到物理内存上 常驻内存 是进程实际使用的物理内存 共享内存 既包括与其他进程共同使用的真实的共享内存，还包括了加载的动态链接库以及程序的代码段等 Swap内存 通过 Swap 换出到磁盘的内存 缺页异常 系统调用内存分配请求后，并不会立刻为其分配物理内存，而是在请求首次访问时，通过缺页异常分配。可以直接从物理内存中分配时，被称为次缺页异常；需要磁盘 I/O 介入（比如 Swap）时，被称为主缺页异常。 Swap的使用情况 已用空间 剩余空间 换入速度 换出速度 ","date":"2019-06-22","objectID":"/2-%E5%86%85%E5%AD%98/:1:0","tags":["Linux","学习笔记"],"title":"2.内存性能分析","uri":"/2-%E5%86%85%E5%AD%98/"},{"categories":["Linux性能优化学习笔记"],"content":"工具字典 ","date":"2019-06-22","objectID":"/2-%E5%86%85%E5%AD%98/:2:0","tags":["Linux","学习笔记"],"title":"2.内存性能分析","uri":"/2-%E5%86%85%E5%AD%98/"},{"categories":["Linux性能优化学习笔记"],"content":"分析思路 ","date":"2019-06-22","objectID":"/2-%E5%86%85%E5%AD%98/:3:0","tags":["Linux","学习笔记"],"title":"2.内存性能分析","uri":"/2-%E5%86%85%E5%AD%98/"},{"categories":["Linux性能优化学习笔记"],"content":"性能指标 CPU使用率：非空闲时间占总 CPU 时间的百分比 用户CPU使用率 系统CPU使用率 等待I/O的CPU使用率 软/硬中断CPU使用率 虚拟机CPU使用率 运行客户CPU使用率 平均负载：系统的平均活跃进程数 上下文切换 无法获取资源而导致的自愿上下文切换 被系统强制调度导致的非自愿上下文切换 CPU缓存命中率 ","date":"2019-06-22","objectID":"/1-cpu/:1:0","tags":["Linux","学习笔记"],"title":"1.CPU性能分析","uri":"/1-cpu/"},{"categories":["Linux性能优化学习笔记"],"content":"工具字典 ","date":"2019-06-22","objectID":"/1-cpu/:2:0","tags":["Linux","学习笔记"],"title":"1.CPU性能分析","uri":"/1-cpu/"},{"categories":["Linux性能优化学习笔记"],"content":"分析思路 ","date":"2019-06-22","objectID":"/1-cpu/:3:0","tags":["Linux","学习笔记"],"title":"1.CPU性能分析","uri":"/1-cpu/"},{"categories":["MySQL学习笔记"],"content":"一个字总结：很有收获 两个字总结：通透 把所有内容学习完之后再回过头来把这些内容串起来，形成一个小知识网络，然后用一张图来表达我的思想感情。 I’m on my slow boat. I’m going to speed it up. ","date":"2019-06-14","objectID":"/mysql%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/:0:0","tags":["MySQL","学习笔记"],"title":"MySQL学习总结","uri":"/mysql%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"它们在哪(物理上)，是干嘛的(逻辑上)？ 按速度从快到慢依次列出物理硬件(一级列表)；二级列表为物理硬件上的逻辑分配 cpu cpu缓存 内存 cached 读写文件的页缓存 Slab分配器中的可回收内存 buffers 读写原始磁盘块的缓存 磁盘 swap 当内存条不够时，从磁盘上拿出一块空间放一些接近过期的内存数据 disk 持久化存储数据 ","date":"2019-06-13","objectID":"/cached-buffers-swap/:1:0","tags":["Linux"],"title":"cached、buffers、swap是啥","uri":"/cached-buffers-swap/"},{"categories":null,"content":"如何查看剩余内存 Mem, total ：物理上的内存总量 Mem, used ：系统已经分配给buffers+cached的内存总量，只是已分配的，并不是已经使用了的 Mem, free ：系统没有分配的物理内存，即啥都没在用的，并不是“空闲的” Mem, shared：由多个进程共享的内存 Mem, buffers：系统已经分配，但是没有使用的buffers Mem, cached：系统已分配，但是没有使用的cached buffers/cache, total：系统已分配，并且已使用的buffers+cached，真正的已用内存 buffers/cache, free：系统已分配，但没有使用的buffers+cached，和系统没有分配的物理内容存，真正的空闲内存 Swap, totel：系统分配的swap总量 Swap, used：已用的swap量 Swap, free：空闲的swap量 不小心暴露了我的开发机有188G内存的本质，hhh… ","date":"2019-06-13","objectID":"/cached-buffers-swap/:2:0","tags":["Linux"],"title":"cached、buffers、swap是啥","uri":"/cached-buffers-swap/"},{"categories":["MySQL学习笔记"],"content":"分区表跟用户分表比起来，有两个绕不开的问题：一个是第一次访问的时候需要访问所有分区，另一个是共用MDL锁。 如果要使用分区表，就不要创建太多的分区 ","date":"2019-06-02","objectID":"/43-%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8%E5%88%86%E5%8C%BA%E8%A1%A8/:0:0","tags":["MySQL","学习笔记"],"title":"43.要不要使用分区表","uri":"/43-%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8%E5%88%86%E5%8C%BA%E8%A1%A8/"},{"categories":["MySQL学习笔记"],"content":"grant语句会同时修改数据表和内存，判断权限的时候使用的是内存数据。因此，规范地使用grant和revoke语句，是不需要随后加上flush privileges语句的。 flush privileges语句本身会用数据表的数据重建一份内存权限数据，所以在权限数据可能存在不一致的情况下再使用。而这种不一致往往是由于直接用DML语句操作系统权限表导致的，比如直接修改users表。 ","date":"2019-06-02","objectID":"/42-grant%E4%B9%8B%E5%90%8E%E8%A6%81%E4%B8%8D%E8%A6%81%E6%89%A7%E8%A1%8Cfush-privileges/:0:0","tags":["MySQL","学习笔记"],"title":"42.grant之后要不要执行fush privileges","uri":"/42-grant%E4%B9%8B%E5%90%8E%E8%A6%81%E4%B8%8D%E8%A6%81%E6%89%A7%E8%A1%8Cfush-privileges/"},{"categories":["MySQL学习笔记"],"content":"复制一张表的方式 物理拷贝的方式速度最快，尤其对于大表拷贝来说是最快的方法。如果出现误删表的情况，用备份恢复出误删之前的临时库，然后再把临时库中的表拷贝到生产库上，是恢复数据最快的方法。但是，这种方法的使用也有一定的局限性： 必须是全表拷贝，不能只拷贝部分数据； 需要到服务器上拷贝数据，在用户无法登录数据库主机的场景下无法使用； 由于是通过拷贝物理文件实现的，源表和目标表都是使用InnoDB引擎时才能使用。 用mysqldump生成包含INSERT语句文件的方法，可以在where参数增加过滤条件，来实现只导出部分数据。这个方式的不足之一是，不能使用join这种比较复杂的where条件写法。 用select … into outfile的方法是最灵活的，支持所有的SQL写法。但，这个方法的缺点之一就是，每次只能导出一张表的数据，而且表结构也需要另外的语句单独备份。 后两种方式都是逻辑备份方式，是可以跨引擎使用的。 ","date":"2019-06-02","objectID":"/41-%E5%A6%82%E4%BD%95%E5%BF%AB%E9%80%9F%E7%9A%84%E5%A4%8D%E5%88%B6%E4%B8%80%E5%BC%A0%E8%A1%A8/:1:0","tags":["MySQL","学习笔记"],"title":"41.如何快速的复制一张表","uri":"/41-%E5%A6%82%E4%BD%95%E5%BF%AB%E9%80%9F%E7%9A%84%E5%A4%8D%E5%88%B6%E4%B8%80%E5%BC%A0%E8%A1%A8/"},{"categories":["MySQL学习笔记"],"content":"insert … select 是很常见的在两个表之间拷贝数据的方法。在可重复读隔离级别下，这个语句会给select的表里扫描到的记录和间隙加读锁。 而如果insert和select的对象是同一个表，则有可能会造成循环写入。这种情况下，我们需要引入用户临时表来做优化。 insert 语句如果出现唯一键冲突，会在冲突的唯一值上加共享的next-key lock(S锁)。因此，碰到由于唯一键约束导致报错后，要尽快提交或回滚事务，避免加锁时间过长。 ","date":"2019-06-02","objectID":"/40-insert%E7%9A%84%E9%94%81/:0:0","tags":["MySQL","学习笔记"],"title":"40.insert的锁","uri":"/40-insert%E7%9A%84%E9%94%81/"},{"categories":["MySQL学习笔记"],"content":"内存表 ","date":"2019-06-02","objectID":"/38-%E5%86%85%E5%AD%98%E8%A1%A8/:1:0","tags":["MySQL","学习笔记"],"title":"38.内存表","uri":"/38-%E5%86%85%E5%AD%98%E8%A1%A8/"},{"categories":["MySQL学习笔记"],"content":"不适合用作普通表 重启会丢数据，如果一个备库重启，会导致主备同步线程停止；如果主库跟这个备库是双M架构，还可能导致主库的内存表数据被删掉 内存表由于不支持行锁，更新语句会阻塞查询，性能也未必好 所以生产上不建议使用内存表 ","date":"2019-06-02","objectID":"/38-%E5%86%85%E5%AD%98%E8%A1%A8/:1:1","tags":["MySQL","学习笔记"],"title":"38.内存表","uri":"/38-%E5%86%85%E5%AD%98%E8%A1%A8/"},{"categories":["MySQL学习笔记"],"content":"适合用来做临时表 内存表支持hash索引，这个特性利用起来，对复杂查询的加速效果有帮助 同时临时表因为是只会被当前session使用，也不存在并发问题； 会话结束后就会释放，也不存在丢数据的问题。 ","date":"2019-06-02","objectID":"/38-%E5%86%85%E5%AD%98%E8%A1%A8/:1:2","tags":["MySQL","学习笔记"],"title":"38.内存表","uri":"/38-%E5%86%85%E5%AD%98%E8%A1%A8/"},{"categories":["MySQL学习笔记"],"content":"为什么自增主键不一定是连续的 在MyISAM引擎里面，自增值是被写在数据文件上的 在InnoDB中，自增值是被记录在内存的，所以每次重启后，都会获取当前最大的主键id+1作为新的自增；MySQL8.0开始，把innodb的自增值持久化了 唯一索引冲突和事务回滚后不会让自增值回退，也会造成自增id不连续 ","date":"2019-06-02","objectID":"/39-%E8%87%AA%E5%A2%9E%E4%B8%BB%E9%94%AE%E4%B8%BA%E5%95%A5%E4%B8%8D%E6%98%AF%E8%BF%9E%E7%BB%AD%E7%9A%84/:1:0","tags":["MySQL","学习笔记"],"title":"39.自增主键为啥不是连续的","uri":"/39-%E8%87%AA%E5%A2%9E%E4%B8%BB%E9%94%AE%E4%B8%BA%E5%95%A5%E4%B8%8D%E6%98%AF%E8%BF%9E%E7%BB%AD%E7%9A%84/"},{"categories":["MySQL学习笔记"],"content":"什么时候会使用内部临时表？ ","date":"2019-06-02","objectID":"/37-%E5%95%A5%E6%97%B6%E5%80%99%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8/:1:0","tags":["MySQL","学习笔记"],"title":"37.啥时候使用内部临时表","uri":"/37-%E5%95%A5%E6%97%B6%E5%80%99%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8/"},{"categories":["MySQL学习笔记"],"content":"实例 union 合并后判断唯一；union all则不需要 group by 排序和计数时；如果有索引，则不需要用到临时表 ","date":"2019-06-02","objectID":"/37-%E5%95%A5%E6%97%B6%E5%80%99%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8/:1:1","tags":["MySQL","学习笔记"],"title":"37.啥时候使用内部临时表","uri":"/37-%E5%95%A5%E6%97%B6%E5%80%99%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8/"},{"categories":["MySQL学习笔记"],"content":"理论 如果语句执行过程可以一边读数据，一边直接得到结果，是不需要额外内存的，否则就需要额外的内存，来保存中间结果； join_buffer是无序数组，sort_buffer是有序数组，临时表是二维表结构； 如果执行逻辑需要用到二维表特性，就会优先考虑使用临时表。比如我们的例子中，union需要用到唯一索引约束， group by还需要用到另外一个字段来存累积计数。 ","date":"2019-06-02","objectID":"/37-%E5%95%A5%E6%97%B6%E5%80%99%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8/:1:2","tags":["MySQL","学习笔记"],"title":"37.啥时候使用内部临时表","uri":"/37-%E5%95%A5%E6%97%B6%E5%80%99%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8/"},{"categories":["MySQL学习笔记"],"content":"指导规则 如果对group by语句的结果没有排序要求，要在语句后面加 order by null； 尽量让group by过程用上表的索引，确认方法是explain结果里没有Using temporary 和 Using filesort； 如果group by需要统计的数据量不大，尽量只使用内存临时表；也可以通过适当调大tmp_table_size参数，来避免用到磁盘临时表； 如果数据量实在太大，使用SQL_BIG_RESULT这个提示，来告诉优化器直接使用排序算法得到group by的结果。 ","date":"2019-06-02","objectID":"/37-%E5%95%A5%E6%97%B6%E5%80%99%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8/:2:0","tags":["MySQL","学习笔记"],"title":"37.啥时候使用内部临时表","uri":"/37-%E5%95%A5%E6%97%B6%E5%80%99%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8/"},{"categories":["MySQL学习笔记"],"content":"临时表 创建语句reate temporary table temp_t(id int primary key)engine=innodb; 由session创建，且只能被创建的session访问到，可以和普通表同名（优先访问临时表），当session结束后，就释放掉了。 会创建一个ql{进程id}_{线程id}_序列号的表，专门用于存放临时表 ","date":"2019-06-02","objectID":"/36-%E4%B8%B4%E6%97%B6%E8%A1%A8/:1:0","tags":["MySQL","学习笔记"],"title":"36.临时表","uri":"/36-%E4%B8%B4%E6%97%B6%E8%A1%A8/"},{"categories":["MySQL学习笔记"],"content":"主从复制时对临时表的策略 statement格式下，临时表的操作需要被binlog忠实记录，否则无法正常进行。 row格式下，临时表的操作不需要被记录，因为row格式的binlog会存储具体数据，无临时表也可以。 ","date":"2019-06-02","objectID":"/36-%E4%B8%B4%E6%97%B6%E8%A1%A8/:2:0","tags":["MySQL","学习笔记"],"title":"36.临时表","uri":"/36-%E4%B8%B4%E6%97%B6%E8%A1%A8/"},{"categories":["MySQL学习笔记"],"content":"Multi-Range Read优化 MRR 拿到一批主键后再去查询(回表或者join)，可以利用顺序访问速度较快的特性，提升查询速度。 ","date":"2019-06-01","objectID":"/35-join%E7%9A%84%E4%BC%98%E5%8C%96/:1:0","tags":["MySQL","学习笔记"],"title":"35.join的优化","uri":"/35-join%E7%9A%84%E4%BC%98%E5%8C%96/"},{"categories":["MySQL学习笔记"],"content":"Batched Key Access BKA 这个算法利用MRR，可以对Index Nested-Loop Join做优化 ","date":"2019-06-01","objectID":"/35-join%E7%9A%84%E4%BC%98%E5%8C%96/:2:0","tags":["MySQL","学习笔记"],"title":"35.join的优化","uri":"/35-join%E7%9A%84%E4%BC%98%E5%8C%96/"},{"categories":["MySQL学习笔记"],"content":"BNL的优化 在被驱动表上建立索引，转为INLJ，再利用BKA优化； 如果原被驱动表不能加索引，就建立临时表，在临时表上建立索引，把原表数据插入后再执行join ","date":"2019-06-01","objectID":"/35-join%E7%9A%84%E4%BC%98%E5%8C%96/:3:0","tags":["MySQL","学习笔记"],"title":"35.join的优化","uri":"/35-join%E7%9A%84%E4%BC%98%E5%8C%96/"},{"categories":["MySQL学习笔记"],"content":"Index Nested-Loop Join 如果驱动表和被驱动表都能使用索引，那么会采用这个算法； ","date":"2019-06-01","objectID":"/34-join%E5%88%B0%E5%BA%95%E8%83%BD%E4%B8%8D%E8%83%BD%E7%94%A8/:1:0","tags":["MySQL","学习笔记"],"title":"34.join到底能不能用","uri":"/34-join%E5%88%B0%E5%BA%95%E8%83%BD%E4%B8%8D%E8%83%BD%E7%94%A8/"},{"categories":["MySQL学习笔记"],"content":"Simple Nested-Loop Join 当有表不能使用索引时，MySQL会把两个表都读入内存，然后执行扫描。 ","date":"2019-06-01","objectID":"/34-join%E5%88%B0%E5%BA%95%E8%83%BD%E4%B8%8D%E8%83%BD%E7%94%A8/:2:0","tags":["MySQL","学习笔记"],"title":"34.join到底能不能用","uri":"/34-join%E5%88%B0%E5%BA%95%E8%83%BD%E4%B8%8D%E8%83%BD%E7%94%A8/"},{"categories":["MySQL学习笔记"],"content":"Block Nested-Loop Join 当内存不够用时，会分段把表读入内存，Simple Nested-Loop Join就会退化为这个算法。 ","date":"2019-06-01","objectID":"/34-join%E5%88%B0%E5%BA%95%E8%83%BD%E4%B8%8D%E8%83%BD%E7%94%A8/:3:0","tags":["MySQL","学习笔记"],"title":"34.join到底能不能用","uri":"/34-join%E5%88%B0%E5%BA%95%E8%83%BD%E4%B8%8D%E8%83%BD%E7%94%A8/"},{"categories":["MySQL学习笔记"],"content":"能不能使用join？ 如果能使用Index Nested-Loop Join算法，则可以用；否则尽量不要用 ","date":"2019-06-01","objectID":"/34-join%E5%88%B0%E5%BA%95%E8%83%BD%E4%B8%8D%E8%83%BD%E7%94%A8/:4:0","tags":["MySQL","学习笔记"],"title":"34.join到底能不能用","uri":"/34-join%E5%88%B0%E5%BA%95%E8%83%BD%E4%B8%8D%E8%83%BD%E7%94%A8/"},{"categories":["MySQL学习笔记"],"content":"选择哪个表作为驱动表？ 小表 ","date":"2019-06-01","objectID":"/34-join%E5%88%B0%E5%BA%95%E8%83%BD%E4%B8%8D%E8%83%BD%E7%94%A8/:5:0","tags":["MySQL","学习笔记"],"title":"34.join到底能不能用","uri":"/34-join%E5%88%B0%E5%BA%95%E8%83%BD%E4%B8%8D%E8%83%BD%E7%94%A8/"},{"categories":["MySQL学习笔记"],"content":"全表扫描对server层的影响 MySQL是“边读边发的” ","date":"2019-06-01","objectID":"/33-mysql%E6%9F%A5%E8%AF%A2%E6%97%B6%E5%AF%B9%E5%86%85%E5%AD%98%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E5%BC%8F/:1:0","tags":["MySQL","学习笔记"],"title":"33.MySQL查询时对内存的使用方式","uri":"/33-mysql%E6%9F%A5%E8%AF%A2%E6%97%B6%E5%AF%B9%E5%86%85%E5%AD%98%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E5%BC%8F/"},{"categories":["MySQL学习笔记"],"content":"全表扫描对innodb的影响 innodb的Buffer Pool中是使用改进过的LRU算法进行淘汰的，单次遍历全表不会对内存命中率有很大影响 ","date":"2019-06-01","objectID":"/33-mysql%E6%9F%A5%E8%AF%A2%E6%97%B6%E5%AF%B9%E5%86%85%E5%AD%98%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E5%BC%8F/:2:0","tags":["MySQL","学习笔记"],"title":"33.MySQL查询时对内存的使用方式","uri":"/33-mysql%E6%9F%A5%E8%AF%A2%E6%97%B6%E5%AF%B9%E5%86%85%E5%AD%98%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E5%BC%8F/"},{"categories":["MySQL学习笔记"],"content":"kill 当用户执行kill query thread_id_B时，MySQL里处理kill命令的线程做了两件事： 把session B的运行状态改成THD::KILL_QUERY(将变量killed赋值为THD::KILL_QUERY)； 给session B的执行线程发一个信号。 三层意思： 一个语句执行过程中有多处“埋点”，在这些“埋点”的地方判断线程状态，如果发现线程状态是THD::KILL_QUERY，才开始进入语句终止逻辑； 如果处于等待状态，必须是一个可以被唤醒的等待，否则根本不会执行到“埋点”处； 语句从开始进入终止逻辑，到终止逻辑完全完成，是有一个过程的。 ","date":"2019-06-01","objectID":"/32-%E6%9C%89%E4%BA%9B%E8%BF%9B%E7%A8%8B%E6%9D%80%E4%B8%8D%E6%8E%89/:1:0","tags":["MySQL","学习笔记"],"title":"32.有些进程杀不掉","uri":"/32-%E6%9C%89%E4%BA%9B%E8%BF%9B%E7%A8%8B%E6%9D%80%E4%B8%8D%E6%8E%89/"},{"categories":["MySQL学习笔记"],"content":"kill不掉的情况 线程没有执行到判断线程状态的逻辑 终止逻辑耗时较长 超大事务执行期间被kill。这时候，回滚操作需要对事务执行期间生成的所有新数据版本做回收操作，耗时很长。 大查询回滚。如果查询过程中生成了比较大的临时文件，加上此时文件系统压力大，删除临时文件可能需要等待IO资源，导致耗时较长。 DDL命令执行到最后阶段，如果被kill，需要删除中间过程的临时文件，也可能受IO资源影响耗时较久。 执行Ctrl+C并不能马上终止掉所有进程，也是执行kill流程 ","date":"2019-06-01","objectID":"/32-%E6%9C%89%E4%BA%9B%E8%BF%9B%E7%A8%8B%E6%9D%80%E4%B8%8D%E6%8E%89/:1:1","tags":["MySQL","学习笔记"],"title":"32.有些进程杀不掉","uri":"/32-%E6%9C%89%E4%BA%9B%E8%BF%9B%E7%A8%8B%E6%9D%80%E4%B8%8D%E6%8E%89/"},{"categories":["MySQL学习笔记"],"content":"误删行 Flashback 是修改binlog的内容，拿回原库重放 ","date":"2019-06-01","objectID":"/31-%E5%88%A0%E5%BA%93%E4%B8%8D%E8%B7%91%E8%B7%AF/:1:0","tags":["MySQL","学习笔记"],"title":"31.删库不跑路","uri":"/31-%E5%88%A0%E5%BA%93%E4%B8%8D%E8%B7%91%E8%B7%AF/"},{"categories":["MySQL学习笔记"],"content":"预防方式 把sql_safe_updates参数设置为on。这样一来，如果我们忘记在delete或者update语句中写where条件，或者where条件里面没有包含索引字段的话，这条语句的执行就会报错。 码上线前，必须经过SQL审计 ","date":"2019-06-01","objectID":"/31-%E5%88%A0%E5%BA%93%E4%B8%8D%E8%B7%91%E8%B7%AF/:1:1","tags":["MySQL","学习笔记"],"title":"31.删库不跑路","uri":"/31-%E5%88%A0%E5%BA%93%E4%B8%8D%E8%B7%91%E8%B7%AF/"},{"categories":["MySQL学习笔记"],"content":"误删库/表 ","date":"2019-06-01","objectID":"/31-%E5%88%A0%E5%BA%93%E4%B8%8D%E8%B7%91%E8%B7%AF/:2:0","tags":["MySQL","学习笔记"],"title":"31.删库不跑路","uri":"/31-%E5%88%A0%E5%BA%93%E4%B8%8D%E8%B7%91%E8%B7%AF/"},{"categories":["MySQL学习笔记"],"content":"全量备份 + 实时备份binlog 加速方法 用上主从的并行复制 延迟复制备库 主备间配置较大延迟，这样主库误操作删除，备库还有数据。 ","date":"2019-06-01","objectID":"/31-%E5%88%A0%E5%BA%93%E4%B8%8D%E8%B7%91%E8%B7%AF/:2:1","tags":["MySQL","学习笔记"],"title":"31.删库不跑路","uri":"/31-%E5%88%A0%E5%BA%93%E4%B8%8D%E8%B7%91%E8%B7%AF/"},{"categories":["MySQL学习笔记"],"content":"预防误删库/表的方法 账号分离 制定操作规范 ","date":"2019-06-01","objectID":"/31-%E5%88%A0%E5%BA%93%E4%B8%8D%E8%B7%91%E8%B7%AF/:2:2","tags":["MySQL","学习笔记"],"title":"31.删库不跑路","uri":"/31-%E5%88%A0%E5%BA%93%E4%B8%8D%E8%B7%91%E8%B7%AF/"},{"categories":["MySQL学习笔记"],"content":"rm删除数据 选出新的主库，继续工作 ","date":"2019-06-01","objectID":"/31-%E5%88%A0%E5%BA%93%E4%B8%8D%E8%B7%91%E8%B7%AF/:3:0","tags":["MySQL","学习笔记"],"title":"31.删库不跑路","uri":"/31-%E5%88%A0%E5%BA%93%E4%B8%8D%E8%B7%91%E8%B7%AF/"},{"categories":["MySQL学习笔记"],"content":"select 1判断 执行select 1看能否成功 问题：只能说明这个库的进程还在，并不能说明主库没问题 ","date":"2019-06-01","objectID":"/29-%E5%A6%82%E4%BD%95%E5%88%A4%E6%96%AD%E6%95%B0%E6%8D%AE%E5%BA%93%E6%98%AF%E5%90%A6%E6%AD%A3%E5%B8%B8/:1:0","tags":["MySQL","学习笔记"],"title":"29.如何判断数据库是否正常","uri":"/29-%E5%A6%82%E4%BD%95%E5%88%A4%E6%96%AD%E6%95%B0%E6%8D%AE%E5%BA%93%E6%98%AF%E5%90%A6%E6%AD%A3%E5%B8%B8/"},{"categories":["MySQL学习笔记"],"content":"查表判断 专门建立一个表，执行select语句来进行状态判断。 问题：空间满的情况无法判断到 ","date":"2019-06-01","objectID":"/29-%E5%A6%82%E4%BD%95%E5%88%A4%E6%96%AD%E6%95%B0%E6%8D%AE%E5%BA%93%E6%98%AF%E5%90%A6%E6%AD%A3%E5%B8%B8/:2:0","tags":["MySQL","学习笔记"],"title":"29.如何判断数据库是否正常","uri":"/29-%E5%A6%82%E4%BD%95%E5%88%A4%E6%96%AD%E6%95%B0%E6%8D%AE%E5%BA%93%E6%98%AF%E5%90%A6%E6%AD%A3%E5%B8%B8/"},{"categories":["MySQL学习笔记"],"content":"更新判断 专门建立一个表，执行update语句 注意：如果有主备，则需要给每个server专门分配一个记录用作监控 问题：当io\u0008利用率为100%时，我们检测的命令需要的资源很少，有可能执行成功。 ","date":"2019-06-01","objectID":"/29-%E5%A6%82%E4%BD%95%E5%88%A4%E6%96%AD%E6%95%B0%E6%8D%AE%E5%BA%93%E6%98%AF%E5%90%A6%E6%AD%A3%E5%B8%B8/:3:0","tags":["MySQL","学习笔记"],"title":"29.如何判断数据库是否正常","uri":"/29-%E5%A6%82%E4%BD%95%E5%88%A4%E6%96%AD%E6%95%B0%E6%8D%AE%E5%BA%93%E6%98%AF%E5%90%A6%E6%AD%A3%E5%B8%B8/"},{"categories":["MySQL学习笔记"],"content":"内部统计 MySQL有专门用于统计的表，可以根据统计信息判断 ","date":"2019-06-01","objectID":"/29-%E5%A6%82%E4%BD%95%E5%88%A4%E6%96%AD%E6%95%B0%E6%8D%AE%E5%BA%93%E6%98%AF%E5%90%A6%E6%AD%A3%E5%B8%B8/:4:0","tags":["MySQL","学习笔记"],"title":"29.如何判断数据库是否正常","uri":"/29-%E5%A6%82%E4%BD%95%E5%88%A4%E6%96%AD%E6%95%B0%E6%8D%AE%E5%BA%93%E6%98%AF%E5%90%A6%E6%AD%A3%E5%B8%B8/"},{"categories":["MySQL学习笔记"],"content":"当主库的压力持续较大时，因为主库是多线程执行的，当备库是单线程执行时，主从延迟会越来越大。 在MySQL5.6以前，备库只能串行执行请求，从5.6开始，陆续有了一些并行复制的策略。 ","date":"2019-06-01","objectID":"/26-%E5%A4%87%E5%BA%93%E5%BB%B6%E8%BF%9F%E5%A5%BD%E5%87%A0%E4%B8%AA%E5%B0%8F%E6%97%B6%E5%92%8B%E6%95%B4/:0:0","tags":["MySQL","学习笔记"],"title":"26.备库延迟好几个小时咋整","uri":"/26-%E5%A4%87%E5%BA%93%E5%BB%B6%E8%BF%9F%E5%A5%BD%E5%87%A0%E4%B8%AA%E5%B0%8F%E6%97%B6%E5%92%8B%E6%95%B4/"},{"categories":["MySQL学习笔记"],"content":"MySQL备库的并行复制策略 ","date":"2019-06-01","objectID":"/26-%E5%A4%87%E5%BA%93%E5%BB%B6%E8%BF%9F%E5%A5%BD%E5%87%A0%E4%B8%AA%E5%B0%8F%E6%97%B6%E5%92%8B%E6%95%B4/:1:0","tags":["MySQL","学习笔记"],"title":"26.备库延迟好几个小时咋整","uri":"/26-%E5%A4%87%E5%BA%93%E5%BB%B6%E8%BF%9F%E5%A5%BD%E5%87%A0%E4%B8%AA%E5%B0%8F%E6%97%B6%E5%92%8B%E6%95%B4/"},{"categories":["MySQL学习笔记"],"content":"按库分发 把请求按照不同的数据库分发给不同的worker执行 ","date":"2019-06-01","objectID":"/26-%E5%A4%87%E5%BA%93%E5%BB%B6%E8%BF%9F%E5%A5%BD%E5%87%A0%E4%B8%AA%E5%B0%8F%E6%97%B6%E5%92%8B%E6%95%B4/:1:1","tags":["MySQL","学习笔记"],"title":"26.备库延迟好几个小时咋整","uri":"/26-%E5%A4%87%E5%BA%93%E5%BB%B6%E8%BF%9F%E5%A5%BD%E5%87%A0%E4%B8%AA%E5%B0%8F%E6%97%B6%E5%92%8B%E6%95%B4/"},{"categories":["MySQL学习笔记"],"content":"按表分发 把请求按照不同的表分发给不同的worker执行 ","date":"2019-06-01","objectID":"/26-%E5%A4%87%E5%BA%93%E5%BB%B6%E8%BF%9F%E5%A5%BD%E5%87%A0%E4%B8%AA%E5%B0%8F%E6%97%B6%E5%92%8B%E6%95%B4/:1:2","tags":["MySQL","学习笔记"],"title":"26.备库延迟好几个小时咋整","uri":"/26-%E5%A4%87%E5%BA%93%E5%BB%B6%E8%BF%9F%E5%A5%BD%E5%87%A0%E4%B8%AA%E5%B0%8F%E6%97%B6%E5%92%8B%E6%95%B4/"},{"categories":["MySQL学习笔记"],"content":"按行分发 把请求按照不同的行(主键+唯一索引)分发给不同的worker执行 ","date":"2019-06-01","objectID":"/26-%E5%A4%87%E5%BA%93%E5%BB%B6%E8%BF%9F%E5%A5%BD%E5%87%A0%E4%B8%AA%E5%B0%8F%E6%97%B6%E5%92%8B%E6%95%B4/:1:3","tags":["MySQL","学习笔记"],"title":"26.备库延迟好几个小时咋整","uri":"/26-%E5%A4%87%E5%BA%93%E5%BB%B6%E8%BF%9F%E5%A5%BD%E5%87%A0%E4%B8%AA%E5%B0%8F%E6%97%B6%E5%92%8B%E6%95%B4/"},{"categories":["MySQL学习笔记"],"content":"按事务id分发 在一组里面一起提交的事务，有一个相同的commit_id，下一组就是commit_id+1； commit_id直接写到binlog里面； 传到备库应用的时候，相同commit_id的事务分发到多个worker执行； 这一组全部执行完成后，coordinator再去取下一批。 ","date":"2019-06-01","objectID":"/26-%E5%A4%87%E5%BA%93%E5%BB%B6%E8%BF%9F%E5%A5%BD%E5%87%A0%E4%B8%AA%E5%B0%8F%E6%97%B6%E5%92%8B%E6%95%B4/:1:4","tags":["MySQL","学习笔记"],"title":"26.备库延迟好几个小时咋整","uri":"/26-%E5%A4%87%E5%BA%93%E5%BB%B6%E8%BF%9F%E5%A5%BD%E5%87%A0%E4%B8%AA%E5%B0%8F%E6%97%B6%E5%92%8B%E6%95%B4/"},{"categories":["MySQL学习笔记"],"content":"主备延迟 主库A执行完成一个事务，写入binlog，我们把这个时刻记为T1; 之后传给备库B，我们把备库B接收完这个binlog的时刻记为T2; 备库B执行完成这个事务，我们把这个时刻记为T3。 T3-T1即为主备延迟 ","date":"2019-06-01","objectID":"/25-mysql%E6%98%AF%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E9%AB%98%E5%8F%AF%E7%94%A8%E7%9A%84/:1:0","tags":["MySQL","学习笔记"],"title":"25.MySQL是怎么保证高可用的","uri":"/25-mysql%E6%98%AF%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E9%AB%98%E5%8F%AF%E7%94%A8%E7%9A%84/"},{"categories":["MySQL学习笔记"],"content":"主备延迟的来源 备库所在机器性能差 备库用得比较随意 大事务 大表DDL ","date":"2019-06-01","objectID":"/25-mysql%E6%98%AF%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E9%AB%98%E5%8F%AF%E7%94%A8%E7%9A%84/:2:0","tags":["MySQL","学习笔记"],"title":"25.MySQL是怎么保证高可用的","uri":"/25-mysql%E6%98%AF%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E9%AB%98%E5%8F%AF%E7%94%A8%E7%9A%84/"},{"categories":["MySQL学习笔记"],"content":"主备切换策略 ","date":"2019-06-01","objectID":"/25-mysql%E6%98%AF%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E9%AB%98%E5%8F%AF%E7%94%A8%E7%9A%84/:3:0","tags":["MySQL","学习笔记"],"title":"25.MySQL是怎么保证高可用的","uri":"/25-mysql%E6%98%AF%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E9%AB%98%E5%8F%AF%E7%94%A8%E7%9A%84/"},{"categories":["MySQL学习笔记"],"content":"可靠性优先 判断备库B现在的seconds_behind_master，如果小于某个值（比如5秒）继续下一步，否则持续重试这一步； 把主库A改成只读状态，即把readonly设置为true； 判断备库B的seconds_behind_master的值，直到这个值变成0为止； 把备库B改成可读写状态，也就是把readonly 设置为false； 把业务请求切到备库B。 问题是会有一段时间服务不可用。 ","date":"2019-06-01","objectID":"/25-mysql%E6%98%AF%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E9%AB%98%E5%8F%AF%E7%94%A8%E7%9A%84/:3:1","tags":["MySQL","学习笔记"],"title":"25.MySQL是怎么保证高可用的","uri":"/25-mysql%E6%98%AF%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E9%AB%98%E5%8F%AF%E7%94%A8%E7%9A%84/"},{"categories":["MySQL学习笔记"],"content":"可用性优先 强行把步骤4、5调整到最开始执行，也就是说不等主备数据同步，直接把连接切到备库B，并且让备库B可以读写，那么系统几乎就没有不可用时间了。 问题是可能会出现数据不一致等问题。 ","date":"2019-06-01","objectID":"/25-mysql%E6%98%AF%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E9%AB%98%E5%8F%AF%E7%94%A8%E7%9A%84/:3:2","tags":["MySQL","学习笔记"],"title":"25.MySQL是怎么保证高可用的","uri":"/25-mysql%E6%98%AF%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E9%AB%98%E5%8F%AF%E7%94%A8%E7%9A%84/"},{"categories":["MySQL学习笔记"],"content":"在从库上会读到系统的一个过期状态，称为过期读。 ","date":"2019-06-01","objectID":"/28-%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E7%9A%84%E5%9D%91/:0:0","tags":["MySQL","学习笔记"],"title":"28.读写分离的坑","uri":"/28-%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E7%9A%84%E5%9D%91/"},{"categories":["MySQL学习笔记"],"content":"过期读的解决方案 ","date":"2019-06-01","objectID":"/28-%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E7%9A%84%E5%9D%91/:1:0","tags":["MySQL","学习笔记"],"title":"28.读写分离的坑","uri":"/28-%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E7%9A%84%E5%9D%91/"},{"categories":["MySQL学习笔记"],"content":"强制走主库方案 必须拿到最新结果的方案，强制请求主库；非必须最新结果的方案，请求从库。 ","date":"2019-06-01","objectID":"/28-%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E7%9A%84%E5%9D%91/:1:1","tags":["MySQL","学习笔记"],"title":"28.读写分离的坑","uri":"/28-%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E7%9A%84%E5%9D%91/"},{"categories":["MySQL学习笔记"],"content":"sleep方案 主库更新后，从库查询之前，先sleep一下。 不靠谱 ","date":"2019-06-01","objectID":"/28-%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E7%9A%84%E5%9D%91/:1:2","tags":["MySQL","学习笔记"],"title":"28.读写分离的坑","uri":"/28-%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E7%9A%84%E5%9D%91/"},{"categories":["MySQL学习笔记"],"content":"判断主备无延迟方案 查询前先判断主从延迟是否为0，如果不是，一直等。 对比位点确保主备无延迟 对比GTID确保主备无延迟 ","date":"2019-06-01","objectID":"/28-%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E7%9A%84%E5%9D%91/:1:3","tags":["MySQL","学习笔记"],"title":"28.读写分离的坑","uri":"/28-%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E7%9A%84%E5%9D%91/"},{"categories":["MySQL学习笔记"],"content":"配合semi-sync方案 引入半同步复制 事务提交的时候，主库把binlog发给从库； 从库收到binlog以后，发回给主库一个ack，表示收到了； 主库收到这个ack以后，才能给客户端返回“事务完成”的确认。 问题 一主多从的时候，在某些从库执行查询请求会存在过期读的现象； 在持续延迟的情况下，可能出现过度等待的问题。 ","date":"2019-06-01","objectID":"/28-%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E7%9A%84%E5%9D%91/:1:4","tags":["MySQL","学习笔记"],"title":"28.读写分离的坑","uri":"/28-%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E7%9A%84%E5%9D%91/"},{"categories":["MySQL学习笔记"],"content":"等主库位点方案 master_pos_wait 等待，直到实例中的binlog位点执行到了指定位置。 ","date":"2019-06-01","objectID":"/28-%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E7%9A%84%E5%9D%91/:1:5","tags":["MySQL","学习笔记"],"title":"28.读写分离的坑","uri":"/28-%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E7%9A%84%E5%9D%91/"},{"categories":["MySQL学习笔记"],"content":"等GTID方案 wait_for_executed_gtid_set 等待，直到实例中执行了指定GTID。 ","date":"2019-06-01","objectID":"/28-%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E7%9A%84%E5%9D%91/:1:6","tags":["MySQL","学习笔记"],"title":"28.读写分离的坑","uri":"/28-%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E7%9A%84%E5%9D%91/"},{"categories":["MySQL学习笔记"],"content":"基于位点的主备切换 A是主库，A’是备库；B、C、D是从库；当主库要从A切换为A’时，BCD需要知道应该继续从A’的binlog的哪个位点开始执行。 但是无法获取到精准的位点，只能记录下A宕机的时刻T，再从A’的T时刻开始执行，这里的位点是偏前的，因此可能会出现主键冲突等问题，因此需要临时关闭主键冲突、删除行不存在等错误的报警，待同步平稳后再打开。 ","date":"2019-06-01","objectID":"/27-%E4%B8%BB%E5%BA%93%E6%8C%82%E4%BA%86%E4%BB%8E%E5%BA%93%E5%92%8B%E5%8A%9E/:1:0","tags":["MySQL","学习笔记"],"title":"27.主库挂了从库咋办","uri":"/27-%E4%B8%BB%E5%BA%93%E6%8C%82%E4%BA%86%E4%BB%8E%E5%BA%93%E5%92%8B%E5%8A%9E/"},{"categories":["MySQL学习笔记"],"content":"GTID GTID全称是Global Transaction Identifier，也就是全局事务ID，是一个事务在提交的时候生成的，是这个事务的唯一标识。 通过GTID来给每个事务做标记，每个实例都用GTID来记录自己执行了哪些事务，这样当出现主备切换时，只需要判断自己是否执行过GTID来判断是否要跳过某些事务。 ","date":"2019-06-01","objectID":"/27-%E4%B8%BB%E5%BA%93%E6%8C%82%E4%BA%86%E4%BB%8E%E5%BA%93%E5%92%8B%E5%8A%9E/:2:0","tags":["MySQL","学习笔记"],"title":"27.主库挂了从库咋办","uri":"/27-%E4%B8%BB%E5%BA%93%E6%8C%82%E4%BA%86%E4%BB%8E%E5%BA%93%E5%92%8B%E5%8A%9E/"},{"categories":["MySQL学习笔记"],"content":"MySQL主备架构 在备库B上通过change master命令，设置主库A的IP、端口、用户名、密码，以及要从哪个位置开始请求binlog，这个位置包含文件名和日志偏移量。 在备库B上执行start slave命令，这时候备库会启动两个线程，就是图中的io_thread和sql_thread。其中io_thread负责与主库建立连接。 主库A校验完用户名、密码后，开始按照备库B传过来的位置，从本地读取binlog，发给B。 备库B拿到binlog后，写到本地文件，称为中转日志（relay log）。 sql_thread读取中转日志，解析出日志里的命令，并执行。 ","date":"2019-06-01","objectID":"/24-mysql%E6%98%AF%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E4%B8%BB%E5%A4%87%E4%B8%80%E8%87%B4%E7%9A%84/:1:0","tags":["MySQL","学习笔记"],"title":"24.MySQL是怎么保证主备一致的","uri":"/24-mysql%E6%98%AF%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E4%B8%BB%E5%A4%87%E4%B8%80%E8%87%B4%E7%9A%84/"},{"categories":["MySQL学习笔记"],"content":"binlog的格式 ","date":"2019-06-01","objectID":"/24-mysql%E6%98%AF%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E4%B8%BB%E5%A4%87%E4%B8%80%E8%87%B4%E7%9A%84/:2:0","tags":["MySQL","学习笔记"],"title":"24.MySQL是怎么保证主备一致的","uri":"/24-mysql%E6%98%AF%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E4%B8%BB%E5%A4%87%E4%B8%80%E8%87%B4%E7%9A%84/"},{"categories":["MySQL学习笔记"],"content":"statement 只记录sql日志原文 某些情况下有主备不一致风险，如delete from xx where a=1 and b=1 limit 1，由于主备可能使用不同的索引，所以加上limit后，有可能删除不同的行。 ","date":"2019-06-01","objectID":"/24-mysql%E6%98%AF%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E4%B8%BB%E5%A4%87%E4%B8%80%E8%87%B4%E7%9A%84/:2:1","tags":["MySQL","学习笔记"],"title":"24.MySQL是怎么保证主备一致的","uri":"/24-mysql%E6%98%AF%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E4%B8%BB%E5%A4%87%E4%B8%80%E8%87%B4%E7%9A%84/"},{"categories":["MySQL学习笔记"],"content":"row 忠实记录每次操作前后的所有数据 问题是太过臃肿，如删除十万行数据，statement格式只需要一行语句，而row格式需要记录十万行数据。 优势是不会有主备不一致风险，且恢复数据时更容易。 ","date":"2019-06-01","objectID":"/24-mysql%E6%98%AF%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E4%B8%BB%E5%A4%87%E4%B8%80%E8%87%B4%E7%9A%84/:2:2","tags":["MySQL","学习笔记"],"title":"24.MySQL是怎么保证主备一致的","uri":"/24-mysql%E6%98%AF%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E4%B8%BB%E5%A4%87%E4%B8%80%E8%87%B4%E7%9A%84/"},{"categories":["MySQL学习笔记"],"content":"mixed 在没有主备不一致风险时，使用statement格式；有风险时，使用row格式；结合了两者的优势。 ","date":"2019-06-01","objectID":"/24-mysql%E6%98%AF%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E4%B8%BB%E5%A4%87%E4%B8%80%E8%87%B4%E7%9A%84/:2:3","tags":["MySQL","学习笔记"],"title":"24.MySQL是怎么保证主备一致的","uri":"/24-mysql%E6%98%AF%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E4%B8%BB%E5%A4%87%E4%B8%80%E8%87%B4%E7%9A%84/"},{"categories":["MySQL学习笔记"],"content":"binlog的附加内容 binlog会带上时间戳，来保证备库使用binlog复制数据时能顺序执行； binlog会带上server_id，来避免双主时的循环复制问题 ","date":"2019-06-01","objectID":"/24-mysql%E6%98%AF%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E4%B8%BB%E5%A4%87%E4%B8%80%E8%87%B4%E7%9A%84/:3:0","tags":["MySQL","学习笔记"],"title":"24.MySQL是怎么保证主备一致的","uri":"/24-mysql%E6%98%AF%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E4%B8%BB%E5%A4%87%E4%B8%80%E8%87%B4%E7%9A%84/"},{"categories":["MySQL学习笔记"],"content":"时序上redo log先prepare， 再写binlog，最后再把redo log commit ","date":"2019-06-01","objectID":"/23-mysql%E6%98%AF%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E6%95%B0%E6%8D%AE%E4%B8%8D%E4%B8%A2%E5%A4%B1%E7%9A%84/:0:0","tags":["MySQL","学习笔记"],"title":"23.MySQL是怎么保证数据不丢失的","uri":"/23-mysql%E6%98%AF%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E6%95%B0%E6%8D%AE%E4%B8%8D%E4%B8%A2%E5%A4%B1%E7%9A%84/"},{"categories":["MySQL学习笔记"],"content":"binlog的写入机制 事务执行过程中，先把日志写到binlog cache，事务提交的时候，再把binlog cache写到binlog文件中，一个事务的binlog是不能被拆开的，因此不论这个事务多大，也要确保一次性写入。 系统给binlog cache分配了一片内存，每个线程一个，参数 binlog_cache_size用于控制单个线程内binlog cache所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。 图中的write，指的就是指把日志写入到文件系统的page cache，并没有把数据持久化到磁盘，所以速度比较快。 图中的fsync，才是将数据持久化到磁盘的操作。一般情况下，我们认为fsync才占磁盘的IOPS。 sync_binlog可以控制fsync的时机，可选的情况有：每次事务都fsync，每次事务都不fsync，N个事务执行一次fsync。 ","date":"2019-06-01","objectID":"/23-mysql%E6%98%AF%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E6%95%B0%E6%8D%AE%E4%B8%8D%E4%B8%A2%E5%A4%B1%E7%9A%84/:1:0","tags":["MySQL","学习笔记"],"title":"23.MySQL是怎么保证数据不丢失的","uri":"/23-mysql%E6%98%AF%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E6%95%B0%E6%8D%AE%E4%B8%8D%E4%B8%A2%E5%A4%B1%E7%9A%84/"},{"categories":["MySQL学习笔记"],"content":"redo log的写入机制 redo log的写入机制和binlog的写入机制类似，都是buffer-\u003ewrite-\u003efsync，区别是redo log的buffer阶段是所有线程共享一段内存(因为redo log不需要保证时序) innodb后台有一个专门负责写入的线程，定时把执行buffer-\u003ewrite-\u003efsync。 ","date":"2019-06-01","objectID":"/23-mysql%E6%98%AF%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E6%95%B0%E6%8D%AE%E4%B8%8D%E4%B8%A2%E5%A4%B1%E7%9A%84/:2:0","tags":["MySQL","学习笔记"],"title":"23.MySQL是怎么保证数据不丢失的","uri":"/23-mysql%E6%98%AF%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E6%95%B0%E6%8D%AE%E4%B8%8D%E4%B8%A2%E5%A4%B1%E7%9A%84/"},{"categories":["MySQL学习笔记"],"content":"io瓶颈的解决方案 设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count参数，减少binlog的写盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢失数据的风险。 将sync_binlog 设置为大于1的值（比较常见是100~1000）。这样做的风险是，主机掉电时会丢binlog日志。 将innodb_flush_log_at_trx_commit设置为2。这样做的风险是，主机掉电的时候会丢数据。 ","date":"2019-06-01","objectID":"/23-mysql%E6%98%AF%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E6%95%B0%E6%8D%AE%E4%B8%8D%E4%B8%A2%E5%A4%B1%E7%9A%84/:3:0","tags":["MySQL","学习笔记"],"title":"23.MySQL是怎么保证数据不丢失的","uri":"/23-mysql%E6%98%AF%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E6%95%B0%E6%8D%AE%E4%B8%8D%E4%B8%A2%E5%A4%B1%E7%9A%84/"},{"categories":["MySQL学习笔记"],"content":"短连接风暴 短连接是指连接到数据库后，执行很少的SQL语句就断开的连接 ","date":"2019-06-01","objectID":"/22-%E9%A5%AE%E9%B8%A9%E6%AD%A2%E6%B8%B4%E7%9A%84%E6%8F%90%E9%80%9F%E6%96%B9%E6%B3%95/:1:0","tags":["MySQL","学习笔记"],"title":"22.饮鸩止渴的提速方法","uri":"/22-%E9%A5%AE%E9%B8%A9%E6%AD%A2%E6%B8%B4%E7%9A%84%E6%8F%90%E9%80%9F%E6%96%B9%E6%B3%95/"},{"categories":["MySQL学习笔记"],"content":"方法一：处理掉那些占着连接但是不工作的线程 有损，优先断开事务外空闲太久的连接，如果这样还不够，再考虑断开事务内空闲太久的连接。 ","date":"2019-06-01","objectID":"/22-%E9%A5%AE%E9%B8%A9%E6%AD%A2%E6%B8%B4%E7%9A%84%E6%8F%90%E9%80%9F%E6%96%B9%E6%B3%95/:1:1","tags":["MySQL","学习笔记"],"title":"22.饮鸩止渴的提速方法","uri":"/22-%E9%A5%AE%E9%B8%A9%E6%AD%A2%E6%B8%B4%E7%9A%84%E6%8F%90%E9%80%9F%E6%96%B9%E6%B3%95/"},{"categories":["MySQL学习笔记"],"content":"方法二：减少连接过程的消耗 使用–skip-grant-tables启动MySQL，让每次连接都跳过权限验证 ","date":"2019-06-01","objectID":"/22-%E9%A5%AE%E9%B8%A9%E6%AD%A2%E6%B8%B4%E7%9A%84%E6%8F%90%E9%80%9F%E6%96%B9%E6%B3%95/:1:2","tags":["MySQL","学习笔记"],"title":"22.饮鸩止渴的提速方法","uri":"/22-%E9%A5%AE%E9%B8%A9%E6%AD%A2%E6%B8%B4%E7%9A%84%E6%8F%90%E9%80%9F%E6%96%B9%E6%B3%95/"},{"categories":["MySQL学习笔记"],"content":"慢查询问题 慢查询出现的主要原因有如下三个，在线下提前做好所有sql语句的测试、扫描行数和慢查询分析，可以有效避免。 ","date":"2019-06-01","objectID":"/22-%E9%A5%AE%E9%B8%A9%E6%AD%A2%E6%B8%B4%E7%9A%84%E6%8F%90%E9%80%9F%E6%96%B9%E6%B3%95/:2:0","tags":["MySQL","学习笔记"],"title":"22.饮鸩止渴的提速方法","uri":"/22-%E9%A5%AE%E9%B8%A9%E6%AD%A2%E6%B8%B4%E7%9A%84%E6%8F%90%E9%80%9F%E6%96%B9%E6%B3%95/"},{"categories":["MySQL学习笔记"],"content":"索引没有设计好 紧急创建索引，先关闭备库的binlog，在备库增加索引，然后执行主备切换。 ","date":"2019-06-01","objectID":"/22-%E9%A5%AE%E9%B8%A9%E6%AD%A2%E6%B8%B4%E7%9A%84%E6%8F%90%E9%80%9F%E6%96%B9%E6%B3%95/:2:1","tags":["MySQL","学习笔记"],"title":"22.饮鸩止渴的提速方法","uri":"/22-%E9%A5%AE%E9%B8%A9%E6%AD%A2%E6%B8%B4%E7%9A%84%E6%8F%90%E9%80%9F%E6%96%B9%E6%B3%95/"},{"categories":["MySQL学习笔记"],"content":"语句没写好 可以使用query_rewrite功能，改写一些常见的问题形式 ","date":"2019-06-01","objectID":"/22-%E9%A5%AE%E9%B8%A9%E6%AD%A2%E6%B8%B4%E7%9A%84%E6%8F%90%E9%80%9F%E6%96%B9%E6%B3%95/:2:2","tags":["MySQL","学习笔记"],"title":"22.饮鸩止渴的提速方法","uri":"/22-%E9%A5%AE%E9%B8%A9%E6%AD%A2%E6%B8%B4%E7%9A%84%E6%8F%90%E9%80%9F%E6%96%B9%E6%B3%95/"},{"categories":["MySQL学习笔记"],"content":"MySQL选错索引 加上force index ","date":"2019-06-01","objectID":"/22-%E9%A5%AE%E9%B8%A9%E6%AD%A2%E6%B8%B4%E7%9A%84%E6%8F%90%E9%80%9F%E6%96%B9%E6%B3%95/:2:3","tags":["MySQL","学习笔记"],"title":"22.饮鸩止渴的提速方法","uri":"/22-%E9%A5%AE%E9%B8%A9%E6%AD%A2%E6%B8%B4%E7%9A%84%E6%8F%90%E9%80%9F%E6%96%B9%E6%B3%95/"},{"categories":["MySQL学习笔记"],"content":"QPS突增 QPS突增一般是因为业务突增，或者程序bug导致 如果是由全新业务导致的问题，并且db运维规范的话，可以直接关闭新业务的用户 使用查询重写功能把相关请求改写成select 1 ","date":"2019-06-01","objectID":"/22-%E9%A5%AE%E9%B8%A9%E6%AD%A2%E6%B8%B4%E7%9A%84%E6%8F%90%E9%80%9F%E6%96%B9%E6%B3%95/:3:0","tags":["MySQL","学习笔记"],"title":"22.饮鸩止渴的提速方法","uri":"/22-%E9%A5%AE%E9%B8%A9%E6%AD%A2%E6%B8%B4%E7%9A%84%E6%8F%90%E9%80%9F%E6%96%B9%E6%B3%95/"},{"categories":["MySQL学习笔记"],"content":"加锁规则 两个“原则”、两个“优化”和一个“bug” 原则1：加锁的基本单位是next-key lock，next-key lock是前开后闭区间。 原则2：查找过程中访问到的对象才会加锁。 优化1：索引上的等值查询，给唯一索引加锁的时候，next-key lock退化为行锁。 优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock退化为间隙锁，即前开后开区间。 一个bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。 ","date":"2019-06-01","objectID":"/21-%E5%8A%A0%E9%94%81%E8%A7%84%E5%88%99/:0:0","tags":["MySQL","学习笔记"],"title":"21.加锁规则","uri":"/21-%E5%8A%A0%E9%94%81%E8%A7%84%E5%88%99/"},{"categories":["MySQL学习笔记"],"content":"第一类：查询长时间不返回 select * from t where id=1; ","date":"2019-06-01","objectID":"/19-%E4%B8%80%E8%A1%8C%E6%9F%A5%E8%AF%A2%E4%B9%9F%E5%BE%88%E6%85%A2%E7%9A%84%E5%8F%AF%E8%83%BD%E5%8E%9F%E5%9B%A0/:1:0","tags":["MySQL","学习笔记"],"title":"19.一行查询也很慢的可能原因","uri":"/19-%E4%B8%80%E8%A1%8C%E6%9F%A5%E8%AF%A2%E4%B9%9F%E5%BE%88%E6%85%A2%E7%9A%84%E5%8F%AF%E8%83%BD%E5%8E%9F%E5%9B%A0/"},{"categories":["MySQL学习笔记"],"content":"等MDL锁 有一个线程正在表t上请求或者持有MDL写锁，把select语句堵住了 ","date":"2019-06-01","objectID":"/19-%E4%B8%80%E8%A1%8C%E6%9F%A5%E8%AF%A2%E4%B9%9F%E5%BE%88%E6%85%A2%E7%9A%84%E5%8F%AF%E8%83%BD%E5%8E%9F%E5%9B%A0/:1:1","tags":["MySQL","学习笔记"],"title":"19.一行查询也很慢的可能原因","uri":"/19-%E4%B8%80%E8%A1%8C%E6%9F%A5%E8%AF%A2%E4%B9%9F%E5%BE%88%E6%85%A2%E7%9A%84%E5%8F%AF%E8%83%BD%E5%8E%9F%E5%9B%A0/"},{"categories":["MySQL学习笔记"],"content":"等flush 有一个线程正要对表t做flush操作，把select语句堵住了 ","date":"2019-06-01","objectID":"/19-%E4%B8%80%E8%A1%8C%E6%9F%A5%E8%AF%A2%E4%B9%9F%E5%BE%88%E6%85%A2%E7%9A%84%E5%8F%AF%E8%83%BD%E5%8E%9F%E5%9B%A0/:1:2","tags":["MySQL","学习笔记"],"title":"19.一行查询也很慢的可能原因","uri":"/19-%E4%B8%80%E8%A1%8C%E6%9F%A5%E8%AF%A2%E4%B9%9F%E5%BE%88%E6%85%A2%E7%9A%84%E5%8F%AF%E8%83%BD%E5%8E%9F%E5%9B%A0/"},{"categories":["MySQL学习笔记"],"content":"等行锁 select * from t where id=1 lock in share mode; 由于访问id=1这个记录时要加读锁，如果这时候已经有一个事务在这行记录上持有一个写锁，我们的select语句就会被堵住。 ","date":"2019-06-01","objectID":"/19-%E4%B8%80%E8%A1%8C%E6%9F%A5%E8%AF%A2%E4%B9%9F%E5%BE%88%E6%85%A2%E7%9A%84%E5%8F%AF%E8%83%BD%E5%8E%9F%E5%9B%A0/:1:3","tags":["MySQL","学习笔记"],"title":"19.一行查询也很慢的可能原因","uri":"/19-%E4%B8%80%E8%A1%8C%E6%9F%A5%E8%AF%A2%E4%B9%9F%E5%BE%88%E6%85%A2%E7%9A%84%E5%8F%AF%E8%83%BD%E5%8E%9F%E5%9B%A0/"},{"categories":["MySQL学习笔记"],"content":"第二类：查询慢 下图这种情况，会导致select * from t where id=1;执行慢，因为MySQL需要执行undo log，恢复到原始的版本。 ","date":"2019-06-01","objectID":"/19-%E4%B8%80%E8%A1%8C%E6%9F%A5%E8%AF%A2%E4%B9%9F%E5%BE%88%E6%85%A2%E7%9A%84%E5%8F%AF%E8%83%BD%E5%8E%9F%E5%9B%A0/:2:0","tags":["MySQL","学习笔记"],"title":"19.一行查询也很慢的可能原因","uri":"/19-%E4%B8%80%E8%A1%8C%E6%9F%A5%E8%AF%A2%E4%B9%9F%E5%BE%88%E6%85%A2%E7%9A%84%E5%8F%AF%E8%83%BD%E5%8E%9F%E5%9B%A0/"},{"categories":["MySQL学习笔记"],"content":"当MySQL认为需要对索引字段做一点事后才能匹配时，索引会不幸的失去排序能力。 ","date":"2019-06-01","objectID":"/18-%E5%AF%B9%E7%B4%A2%E5%BC%95%E5%AD%97%E6%AE%B5%E5%81%9A%E5%87%BD%E6%95%B0%E6%93%8D%E4%BD%9C%E7%9A%84%E5%9D%91/:0:0","tags":["MySQL","学习笔记"],"title":"18.对索引字段做函数操作的坑","uri":"/18-%E5%AF%B9%E7%B4%A2%E5%BC%95%E5%AD%97%E6%AE%B5%E5%81%9A%E5%87%BD%E6%95%B0%E6%93%8D%E4%BD%9C%E7%9A%84%E5%9D%91/"},{"categories":["MySQL学习笔记"],"content":"案例一：条件字段函数操作 select count(*) from tradelog where month(t_modified)=7; 这条sql语句会扫描全索引，因为对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。 where id+1=1000 会有这个问题，但是where id=1000-1不会有这个问题 ","date":"2019-06-01","objectID":"/18-%E5%AF%B9%E7%B4%A2%E5%BC%95%E5%AD%97%E6%AE%B5%E5%81%9A%E5%87%BD%E6%95%B0%E6%93%8D%E4%BD%9C%E7%9A%84%E5%9D%91/:1:0","tags":["MySQL","学习笔记"],"title":"18.对索引字段做函数操作的坑","uri":"/18-%E5%AF%B9%E7%B4%A2%E5%BC%95%E5%AD%97%E6%AE%B5%E5%81%9A%E5%87%BD%E6%95%B0%E6%93%8D%E4%BD%9C%E7%9A%84%E5%9D%91/"},{"categories":["MySQL学习笔记"],"content":"案例二：隐式类型转换 select * from tradelog where tradeid=110717; (tradeid是varchar(32)) 这样即使tradeid有索引，也需要走全表扫描；因为tradeid会被转化为int，这行sql会被转化为select * from tradelog where CAST(tradid AS signed int) = 110717;，同样是对索引字段做函数操作的原因。 ","date":"2019-06-01","objectID":"/18-%E5%AF%B9%E7%B4%A2%E5%BC%95%E5%AD%97%E6%AE%B5%E5%81%9A%E5%87%BD%E6%95%B0%E6%93%8D%E4%BD%9C%E7%9A%84%E5%9D%91/:2:0","tags":["MySQL","学习笔记"],"title":"18.对索引字段做函数操作的坑","uri":"/18-%E5%AF%B9%E7%B4%A2%E5%BC%95%E5%AD%97%E6%AE%B5%E5%81%9A%E5%87%BD%E6%95%B0%E6%93%8D%E4%BD%9C%E7%9A%84%E5%9D%91/"},{"categories":["MySQL学习笔记"],"content":"案例三：隐式字符编码转换 当两个表的字符集不一致时，如utf8和utf8mb4，跨表查询时会把utf8转为utf8mb4(小范围的转为大范围的)；这是如果条件是a[utf-8]=b[utf8mb4]，则同样会有\"对索引字段做函数操作\"的问题；但是如果是a[utf8mb4]=b[utf8]，就不会有这个问题(因为没有随索引字段做函数操作，而是对值做的操作) ","date":"2019-06-01","objectID":"/18-%E5%AF%B9%E7%B4%A2%E5%BC%95%E5%AD%97%E6%AE%B5%E5%81%9A%E5%87%BD%E6%95%B0%E6%93%8D%E4%BD%9C%E7%9A%84%E5%9D%91/:3:0","tags":["MySQL","学习笔记"],"title":"18.对索引字段做函数操作的坑","uri":"/18-%E5%AF%B9%E7%B4%A2%E5%BC%95%E5%AD%97%E6%AE%B5%E5%81%9A%E5%87%BD%E6%95%B0%E6%93%8D%E4%BD%9C%E7%9A%84%E5%9D%91/"},{"categories":["MySQL学习笔记"],"content":"幻读是什么？ 幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。 在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，幻读在“当前读”下才会出现。 ","date":"2019-05-31","objectID":"/20-%E5%B9%BB%E8%AF%BB/:1:0","tags":["MySQL","学习笔记"],"title":"20.幻读","uri":"/20-%E5%B9%BB%E8%AF%BB/"},{"categories":["MySQL学习笔记"],"content":"幻读有什么问题？ ","date":"2019-05-31","objectID":"/20-%E5%B9%BB%E8%AF%BB/:2:0","tags":["MySQL","学习笔记"],"title":"20.幻读","uri":"/20-%E5%B9%BB%E8%AF%BB/"},{"categories":["MySQL学习笔记"],"content":"语义上 读到异常数据的会话，它的加锁目的没有实现，中途被其他会话插入了数据。 ","date":"2019-05-31","objectID":"/20-%E5%B9%BB%E8%AF%BB/:2:1","tags":["MySQL","学习笔记"],"title":"20.幻读","uri":"/20-%E5%B9%BB%E8%AF%BB/"},{"categories":["MySQL学习笔记"],"content":"数据一致性 binlog是在事务提交的时候写入的，当多个事务会话同时执行时，某种场景下会出现数据和binlog不一致的问题。 ","date":"2019-05-31","objectID":"/20-%E5%B9%BB%E8%AF%BB/:2:2","tags":["MySQL","学习笔记"],"title":"20.幻读","uri":"/20-%E5%B9%BB%E8%AF%BB/"},{"categories":["MySQL学习笔记"],"content":"如何解决幻读？ 使用间隙锁能解决幻读的问题 但是这样做会影响并发度，如果业务允许，可以降低隔离级别为读提交，但是会引入数据和binlog不一致的问题，需要把binlog设置为row。 ","date":"2019-05-31","objectID":"/20-%E5%B9%BB%E8%AF%BB/:3:0","tags":["MySQL","学习笔记"],"title":"20.幻读","uri":"/20-%E5%B9%BB%E8%AF%BB/"},{"categories":["MySQL学习笔记"],"content":"内存临时表 这一行sql语句的执行逻辑 select word from words order by rand() limit 3; 假定表内现在有10000行数据 创建一个临时表。这个临时表使用的是memory引擎，表里有两个字段，第一个字段是double类型，为了后面描述方便，记为字段R，第二个字段是varchar(64)类型，记为字段W。并且，这个表没有建索引。 从words表中，按主键顺序取出所有的word值。对于每一个word值，调用rand()函数生成一个大于0小于1的随机小数，并把这个随机小数和word分别存入临时表的R和W字段中，到此，扫描行数是10000。 现在临时表有10000行数据了，接下来你要在这个没有索引的内存临时表上，按照字段R排序。 初始化 sort_buffer。sort_buffer中有两个字段，一个是double类型，另一个是整型。 从内存临时表中一行一行地取出R值和位置信息，分别存入sort_buffer中的两个字段里。这个过程要对内存临时表做全表扫描，此时扫描行数增加10000，变成了20000。 在sort_buffer中根据R的值进行排序。注意，这个过程没有涉及到表操作，所以不会增加扫描行数。 排序完成后，取出前三个结果的位置信息，依次到内存临时表中取出word值，返回给客户端。这个过程中，访问了表的三行数据，总扫描行数变成了20003。 简单说就是先把所有记录生成一个随机数值放到内存中，再把这些记录按照随机值排序，最后取前三条记录。 ","date":"2019-05-31","objectID":"/17-%E9%9A%8F%E6%9C%BA%E8%8E%B7%E5%8F%96%E8%AE%B0%E5%BD%95%E7%9A%84%E6%AD%A3%E7%A1%AE%E5%A7%BF%E5%8A%BF/:1:0","tags":["MySQL","学习笔记"],"title":"17.随机获取记录的正确姿势","uri":"/17-%E9%9A%8F%E6%9C%BA%E8%8E%B7%E5%8F%96%E8%AE%B0%E5%BD%95%E7%9A%84%E6%AD%A3%E7%A1%AE%E5%A7%BF%E5%8A%BF/"},{"categories":["MySQL学习笔记"],"content":"磁盘临时表 当需要占用的内存过大，就会使用磁盘临时表，同时使用优先队列排序法，只得到三行（如果是要获取很多行，会使用外部排序，即归并排序），不会把所有记录都排序。执行流程如下： 对于这10000个准备排序的(R,rowid)，先取前三行，构造成一个堆； 取下一个行(R’,rowid’)，跟当前堆里面最大的R比较，如果R’小于R，把这个(R,rowid)从堆中去掉，换成(R’,rowid’)； 重复第2步，直到第10000个(R’,rowid’)完成比较。 ","date":"2019-05-31","objectID":"/17-%E9%9A%8F%E6%9C%BA%E8%8E%B7%E5%8F%96%E8%AE%B0%E5%BD%95%E7%9A%84%E6%AD%A3%E7%A1%AE%E5%A7%BF%E5%8A%BF/:2:0","tags":["MySQL","学习笔记"],"title":"17.随机获取记录的正确姿势","uri":"/17-%E9%9A%8F%E6%9C%BA%E8%8E%B7%E5%8F%96%E8%AE%B0%E5%BD%95%E7%9A%84%E6%AD%A3%E7%A1%AE%E5%A7%BF%E5%8A%BF/"},{"categories":["MySQL学习笔记"],"content":"随机排序方法 ","date":"2019-05-31","objectID":"/17-%E9%9A%8F%E6%9C%BA%E8%8E%B7%E5%8F%96%E8%AE%B0%E5%BD%95%E7%9A%84%E6%AD%A3%E7%A1%AE%E5%A7%BF%E5%8A%BF/:3:0","tags":["MySQL","学习笔记"],"title":"17.随机获取记录的正确姿势","uri":"/17-%E9%9A%8F%E6%9C%BA%E8%8E%B7%E5%8F%96%E8%AE%B0%E5%BD%95%E7%9A%84%E6%AD%A3%E7%A1%AE%E5%A7%BF%E5%8A%BF/"},{"categories":["MySQL学习笔记"],"content":"方法1 取得这个表的主键id的最大值M和最小值N; 用随机函数生成一个最大值到最小值之间的数 X = (M-N)*rand() + N; 取不小于X的第一个ID的行。 这种方法得到的结果并不是真正的随机结果，因为主键id可能有空洞。 ","date":"2019-05-31","objectID":"/17-%E9%9A%8F%E6%9C%BA%E8%8E%B7%E5%8F%96%E8%AE%B0%E5%BD%95%E7%9A%84%E6%AD%A3%E7%A1%AE%E5%A7%BF%E5%8A%BF/:3:1","tags":["MySQL","学习笔记"],"title":"17.随机获取记录的正确姿势","uri":"/17-%E9%9A%8F%E6%9C%BA%E8%8E%B7%E5%8F%96%E8%AE%B0%E5%BD%95%E7%9A%84%E6%AD%A3%E7%A1%AE%E5%A7%BF%E5%8A%BF/"},{"categories":["MySQL学习笔记"],"content":"方法2 取得整个表的行数，并记为C。 取得 Y = floor(C * rand())。 floor函数在这里的作用，就是取整数部分。 再用limit Y,1 取得一行。 获取三个随机值 取得整个表的行数，记为C； 根据相同的随机方法得到Y1、Y2、Y3； 再执行三个limit Y, 1语句得到三行数据。 ","date":"2019-05-31","objectID":"/17-%E9%9A%8F%E6%9C%BA%E8%8E%B7%E5%8F%96%E8%AE%B0%E5%BD%95%E7%9A%84%E6%AD%A3%E7%A1%AE%E5%A7%BF%E5%8A%BF/:3:2","tags":["MySQL","学习笔记"],"title":"17.随机获取记录的正确姿势","uri":"/17-%E9%9A%8F%E6%9C%BA%E8%8E%B7%E5%8F%96%E8%AE%B0%E5%BD%95%E7%9A%84%E6%AD%A3%E7%A1%AE%E5%A7%BF%E5%8A%BF/"},{"categories":["MySQL学习笔记"],"content":"全字段排序 分析这个sql语句的执行逻辑 select city,name,age from t where city='杭州' order by name limit 1000; 初始化sort_buffer(一段专门用于排序的内存)，确定放入name、city、age这三个字段； 从索引city找到第一个满足city=‘杭州’条件的主键id，也就是图中的ID_X； 到主键id索引取出整行，取name、city、age三个字段的值，存入sort_buffer中； 从索引city取下一个记录的主键id； 重复步骤3、4直到city的值不满足查询条件为止，对应的主键id也就是图中的ID_Y； 对sort_buffer中的数据按照字段name做快速排序(如果内存满足要求，则在内存中完成，否则使用外部排序[多个文件做归并])； 按照排序结果取前1000行返回给客户端。 ","date":"2019-05-31","objectID":"/15-order-by%E7%9A%84%E6%89%A7%E8%A1%8C%E9%80%BB%E8%BE%91/:1:0","tags":["MySQL","学习笔记"],"title":"15.order by的执行逻辑","uri":"/15-order-by%E7%9A%84%E6%89%A7%E8%A1%8C%E9%80%BB%E8%BE%91/"},{"categories":["MySQL学习笔记"],"content":"rowid排序 如果MySQL任务要排序的行太长(超过配置max_length_for_sort_data的长度)，就会采用rowid排序 初始化sort_buffer，确定放入两个字段，即name和id； 从索引city找到第一个满足city=‘杭州’条件的主键id，也就是图中的ID_X； 到主键id索引取出整行，取name、id这两个字段，存入sort_buffer中； 从索引city取下一个记录的主键id； 重复步骤3、4直到不满足city=‘杭州’条件为止，也就是图中的ID_Y； 对sort_buffer中的数据按照字段name进行排序； 遍历排序结果，取前1000行，并按照id的值回到原表中取出city、name和age三个字段返回给客户端。 ","date":"2019-05-31","objectID":"/15-order-by%E7%9A%84%E6%89%A7%E8%A1%8C%E9%80%BB%E8%BE%91/:2:0","tags":["MySQL","学习笔记"],"title":"15.order by的执行逻辑","uri":"/15-order-by%E7%9A%84%E6%89%A7%E8%A1%8C%E9%80%BB%E8%BE%91/"},{"categories":["MySQL学习笔记"],"content":"两者差异 rowid排序是在内存实在不够的情况下才会选择的算法，因为它需要回表去取数据，增加扫描行数。 ","date":"2019-05-31","objectID":"/15-order-by%E7%9A%84%E6%89%A7%E8%A1%8C%E9%80%BB%E8%BE%91/:3:0","tags":["MySQL","学习笔记"],"title":"15.order by的执行逻辑","uri":"/15-order-by%E7%9A%84%E6%89%A7%E8%A1%8C%E9%80%BB%E8%BE%91/"},{"categories":["MySQL学习笔记"],"content":"如何才能不需要排序？ 给要where和order by的字段增加索引，如本语句中，增加city,name索引，则执行流程会简化为 从索引(city,name)找到第一个满足city=‘杭州’条件的主键id； 到主键id索引取出整行，取name、city、age三个字段的值，作为结果集的一部分直接返回； 从索引(city,name)取下一个记录主键id；索引是有序的，所以不需要排序，依次取满足条件的行即可 重复步骤2、3，直到查到第1000条记录，或者是不满足city=‘杭州’条件时循环结束。 ","date":"2019-05-31","objectID":"/15-order-by%E7%9A%84%E6%89%A7%E8%A1%8C%E9%80%BB%E8%BE%91/:4:0","tags":["MySQL","学习笔记"],"title":"15.order by的执行逻辑","uri":"/15-order-by%E7%9A%84%E6%89%A7%E8%A1%8C%E9%80%BB%E8%BE%91/"},{"categories":["MySQL学习笔记"],"content":"如何能既不排序，又不回表？ 利用索引覆盖，增加city,name,age索引 从索引(city,name,age)找到第一个满足city=‘杭州’条件的记录，取出其中的city、name和age这三个字段的值，作为结果集的一部分直接返回； 从索引(city,name,age)取下一个记录，同样取出这三个字段的值，作为结果集的一部分直接返回； 重复执行步骤2，直到查到第1000条记录，或者是不满足city=‘杭州’条件时循环结束。 ","date":"2019-05-31","objectID":"/15-order-by%E7%9A%84%E6%89%A7%E8%A1%8C%E9%80%BB%E8%BE%91/:5:0","tags":["MySQL","学习笔记"],"title":"15.order by的执行逻辑","uri":"/15-order-by%E7%9A%84%E6%89%A7%E8%A1%8C%E9%80%BB%E8%BE%91/"},{"categories":["MySQL学习笔记"],"content":"count(*)的实现方式 MyISAM引擎把一个表的总行数存在了磁盘上，因此执行count(*)的时候会直接返回这个数，效率很高； 而InnoDB引擎就麻烦了，它执行count(*)的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。 ","date":"2019-05-30","objectID":"/14-count%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84/:1:0","tags":["MySQL","学习笔记"],"title":"14.count是如何执行的","uri":"/14-count%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84/"},{"categories":["MySQL学习笔记"],"content":"为什么InnoDB不跟MyISAM一样，也把数字存起来呢 由于多版本并发控制（MVCC）的原因，InnoDB表“应该返回多少行”也是不确定的 在执行count(*)操作的时候，innodb会扫描普通索引，因为普通索引的叶节点是主键id，比较小 ","date":"2019-05-30","objectID":"/14-count%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84/:2:0","tags":["MySQL","学习笔记"],"title":"14.count是如何执行的","uri":"/14-count%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84/"},{"categories":["MySQL学习笔记"],"content":"用缓存系统保存计数 第一个问题：缓存系统可能会计数不准确(宕机时丢失数据)，可以通过每次启动时统一次来做修复。 第二个问题：插入数据和给缓存系统加一是分开的，这中间的gap可能有逻辑不一致的问题。 解决办法：单独用一个表来计数，通过事务来解决gap的问题。 ","date":"2019-05-30","objectID":"/14-count%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84/:3:0","tags":["MySQL","学习笔记"],"title":"14.count是如何执行的","uri":"/14-count%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84/"},{"categories":["MySQL学习笔记"],"content":"不同count的处理逻辑 count(*)、count(主键id)和count(1) 都表示返回满足条件的结果集的总行数；而count(字段），则表示返回满足条件的数据行里面，参数“字段”不为NULL的总个数。 效率排序：count(字段)\u003ccount(主键id)\u003ccount(1)≈count(*) ","date":"2019-05-30","objectID":"/14-count%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84/:4:0","tags":["MySQL","学习笔记"],"title":"14.count是如何执行的","uri":"/14-count%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84/"},{"categories":["MySQL学习笔记"],"content":"参数innodb_file_per_table OFF：表的数据放在系统共享表空间，也就是跟数据字典放在一起 ON：每个InnoDB表数据存储在一个以 .ibd为后缀的文件中 ON是推荐做法 ","date":"2019-05-30","objectID":"/13-%E5%A6%82%E4%BD%95%E5%87%8F%E5%B0%91%E6%95%B0%E6%8D%AE%E8%A1%A8%E7%9A%84%E7%A3%81%E7%9B%98%E5%8D%A0%E7%94%A8/:1:0","tags":["MySQL","学习笔记"],"title":"13.如何减少MySQL表的磁盘占用","uri":"/13-%E5%A6%82%E4%BD%95%E5%87%8F%E5%B0%91%E6%95%B0%E6%8D%AE%E8%A1%A8%E7%9A%84%E7%A3%81%E7%9B%98%E5%8D%A0%E7%94%A8/"},{"categories":["MySQL学习笔记"],"content":"数据删除流程 删除一行数据时，innodb只会把数据在索引树中的位置标记为删除；如果之后再插入新的数据，且符合该位置的索引顺序关系，即可直接复用这个位置。 如果一个数据页上的所有数据都删除了，那么整个数据页就都可以复用了；但是整页复用不需要符合索引范围，可以复用到任何位置 如果相邻的两个数据页的利用率都很低，系统就会合并他们 如果整个表的数据都被删除，那就是所有的数据页都可以复用了，磁盘文件不会变小。 删除数据不会减小磁盘占用，只会产生数据空洞 插入、修改表数据都会造成空洞 ","date":"2019-05-30","objectID":"/13-%E5%A6%82%E4%BD%95%E5%87%8F%E5%B0%91%E6%95%B0%E6%8D%AE%E8%A1%A8%E7%9A%84%E7%A3%81%E7%9B%98%E5%8D%A0%E7%94%A8/:2:0","tags":["MySQL","学习笔记"],"title":"13.如何减少MySQL表的磁盘占用","uri":"/13-%E5%A6%82%E4%BD%95%E5%87%8F%E5%B0%91%E6%95%B0%E6%8D%AE%E8%A1%A8%E7%9A%84%E7%A3%81%E7%9B%98%E5%8D%A0%E7%94%A8/"},{"categories":["MySQL学习笔记"],"content":"重建表才能删除空洞 原表A，创建一个临时表B，把A中的数据迁移到临时表B，用临时表B替换A 命令alter table A engine=InnoDB可以重建表 Online DDL 重建表的过程中，不能接受有新数据插入表A 一个可选的解决方案是在迁移过程中，对A的操作都记录下，迁移完成后再运行给临时表B；这样就做到了对表A无影响。 Online和inplace online是指对业务无影响 inplace是指在innodb层完成，对server层透明 ","date":"2019-05-30","objectID":"/13-%E5%A6%82%E4%BD%95%E5%87%8F%E5%B0%91%E6%95%B0%E6%8D%AE%E8%A1%A8%E7%9A%84%E7%A3%81%E7%9B%98%E5%8D%A0%E7%94%A8/:3:0","tags":["MySQL","学习笔记"],"title":"13.如何减少MySQL表的磁盘占用","uri":"/13-%E5%A6%82%E4%BD%95%E5%87%8F%E5%B0%91%E6%95%B0%E6%8D%AE%E8%A1%A8%E7%9A%84%E7%A3%81%E7%9B%98%E5%8D%A0%E7%94%A8/"},{"categories":["MySQL学习笔记"],"content":"刷脏页 和磁盘不一致的内存页成为脏页，大多数更新操作MySQL都是修改内存和写入redo log，但是在某些情况下，需要把脏页写入磁盘，称之为\"刷脏页\" ","date":"2019-05-26","objectID":"/12-mysql%E6%8A%96%E5%8A%A8/:1:0","tags":["MySQL","学习笔记"],"title":"12.MySQL抖动","uri":"/12-mysql%E6%8A%96%E5%8A%A8/"},{"categories":["MySQL学习笔记"],"content":"啥时候需要\"刷脏页'' redo log 满了，需要把redo log写入磁盘 整个系统就不能再接受更新了，所有的更新都必须阻塞 系统内存不足，需要淘汰一些数据页，空出内存给别的数据页使用【常态】；这种情况下旧内存有三种情况 还没有使用的：直接释放即可 使用了并且是干净页：直接释放即可 使用了并且是脏页 【常态】；这种情况需要把脏页刷入磁盘，再继续操作，如果出现下面两种情况，会明显影响性能 一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长； 日志写满，更新全部堵住，写性能跌为0(同情况1) MySQL认为系统空闲，刷脏页 不影响性能 MySQL正常关闭 不影响性能 ","date":"2019-05-26","objectID":"/12-mysql%E6%8A%96%E5%8A%A8/:2:0","tags":["MySQL","学习笔记"],"title":"12.MySQL抖动","uri":"/12-mysql%E6%8A%96%E5%8A%A8/"},{"categories":["MySQL学习笔记"],"content":"innodb刷脏页的控制策略 InnoDB的刷盘速度就是要参考这两个因素：一个是脏页比例innodb_io_capacity，一个是redo log写盘速度。 ","date":"2019-05-26","objectID":"/12-mysql%E6%8A%96%E5%8A%A8/:3:0","tags":["MySQL","学习笔记"],"title":"12.MySQL抖动","uri":"/12-mysql%E6%8A%96%E5%8A%A8/"},{"categories":["MySQL学习笔记"],"content":"carry 邻居策略 在准备刷一个脏页的时候，如果这个数据页旁边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉；而且这个把“邻居”拖下水的逻辑还可以继续蔓延，也就是对于每个邻居数据页，如果跟它相邻的数据页也还是脏页的话，也会被放到一起刷。 这个策略在机械硬盘时代，是很有意义的，可以减少很多随机IO，但是SSD下就意义不大了，可以通过innodb_flush_neighbors关闭它。 ","date":"2019-05-26","objectID":"/12-mysql%E6%8A%96%E5%8A%A8/:3:1","tags":["MySQL","学习笔记"],"title":"12.MySQL抖动","uri":"/12-mysql%E6%8A%96%E5%8A%A8/"},{"categories":["MySQL学习笔记"],"content":" 直接创建完整索引，这样可能比较占用空间； 创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引； 前缀索引会损失区分度，所以需要确定好能容忍的损失，根据统计结果选择合适的前缀长度 mysql\u003e select count(distinct left(email,4)）as L4, count(distinct left(email,5)）as L5, count(distinct left(email,6)）as L6, count(distinct left(email,7)）as L7, from SUser; 倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题； 创建hash字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。 ","date":"2019-05-26","objectID":"/11-%E6%80%8E%E4%B9%88%E7%BB%99%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%AD%97%E6%AE%B5%E5%8A%A0%E7%B4%A2%E5%BC%95/:0:0","tags":["MySQL","学习笔记"],"title":"11.怎么给字符串加索引","uri":"/11-%E6%80%8E%E4%B9%88%E7%BB%99%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%AD%97%E6%AE%B5%E5%8A%A0%E7%B4%A2%E5%BC%95/"},{"categories":["MySQL学习笔记"],"content":"MySQL是如何选择索引的 根据扫描行数、是否使用临时表、是否排序等因素综合判断 ","date":"2019-05-25","objectID":"/10-%E4%B8%BA%E4%BB%80%E4%B9%88mysql%E4%BC%9A%E9%80%89%E9%94%99%E7%B4%A2%E5%BC%95/:1:0","tags":["MySQL","学习笔记"],"title":"10.为什么MySQL会选错索引","uri":"/10-%E4%B8%BA%E4%BB%80%E4%B9%88mysql%E4%BC%9A%E9%80%89%E9%94%99%E7%B4%A2%E5%BC%95/"},{"categories":["MySQL学习笔记"],"content":"如何得到扫描行数 MySQL在真正开始执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息来估算记录数。 这个统计信息就是索引的“区分度”。显然，一个索引上不同的值越多，这个索引的区分度就越好。而一个索引上不同的值的个数，我们称之为“基数”（cardinality）。也就是说，这个基数越大，索引的区分度越好。 ","date":"2019-05-25","objectID":"/10-%E4%B8%BA%E4%BB%80%E4%B9%88mysql%E4%BC%9A%E9%80%89%E9%94%99%E7%B4%A2%E5%BC%95/:2:0","tags":["MySQL","学习笔记"],"title":"10.为什么MySQL会选错索引","uri":"/10-%E4%B8%BA%E4%BB%80%E4%B9%88mysql%E4%BC%9A%E9%80%89%E9%94%99%E7%B4%A2%E5%BC%95/"},{"categories":["MySQL学习笔记"],"content":"MySQL是怎样得到索引的基数的呢？ 采样统计 MySQL的bug会导致扫描行数统计不准确 ","date":"2019-05-25","objectID":"/10-%E4%B8%BA%E4%BB%80%E4%B9%88mysql%E4%BC%9A%E9%80%89%E9%94%99%E7%B4%A2%E5%BC%95/:2:1","tags":["MySQL","学习笔记"],"title":"10.为什么MySQL会选错索引","uri":"/10-%E4%B8%BA%E4%BB%80%E4%B9%88mysql%E4%BC%9A%E9%80%89%E9%94%99%E7%B4%A2%E5%BC%95/"},{"categories":["MySQL学习笔记"],"content":"异常处理方式 使用force index 修改sql语句，引导MySQL使用我们期望的索引，比如增加order by中的列 新建一个更合适的索引，或者删掉无用的索引 ","date":"2019-05-25","objectID":"/10-%E4%B8%BA%E4%BB%80%E4%B9%88mysql%E4%BC%9A%E9%80%89%E9%94%99%E7%B4%A2%E5%BC%95/:3:0","tags":["MySQL","学习笔记"],"title":"10.为什么MySQL会选错索引","uri":"/10-%E4%B8%BA%E4%BB%80%E4%B9%88mysql%E4%BC%9A%E9%80%89%E9%94%99%E7%B4%A2%E5%BC%95/"},{"categories":["MySQL学习笔记"],"content":"查询过程 对于普通索引来说，查找到满足条件的第一个记录(5,500)后，需要查找下一个记录，直到碰到第一个不满足k=5条件的记录。 对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。 差异很小 ","date":"2019-05-25","objectID":"/9-%E6%99%AE%E9%80%9A%E7%B4%A2%E5%BC%95%E5%92%8C%E5%94%AF%E4%B8%80%E7%B4%A2%E5%BC%95%E7%9A%84%E5%8C%BA%E5%88%AB/:0:1","tags":["MySQL","学习笔记"],"title":"9.普通索引和唯一索引的区别","uri":"/9-%E6%99%AE%E9%80%9A%E7%B4%A2%E5%BC%95%E5%92%8C%E5%94%AF%E4%B8%80%E7%B4%A2%E5%BC%95%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["MySQL学习笔记"],"content":"change buffer 当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB会将这些更新操作缓存在change buffer中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行change buffer中与这个页有关的操作。 ","date":"2019-05-25","objectID":"/9-%E6%99%AE%E9%80%9A%E7%B4%A2%E5%BC%95%E5%92%8C%E5%94%AF%E4%B8%80%E7%B4%A2%E5%BC%95%E7%9A%84%E5%8C%BA%E5%88%AB/:0:2","tags":["MySQL","学习笔记"],"title":"9.普通索引和唯一索引的区别","uri":"/9-%E6%99%AE%E9%80%9A%E7%B4%A2%E5%BC%95%E5%92%8C%E5%94%AF%E4%B8%80%E7%B4%A2%E5%BC%95%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["MySQL学习笔记"],"content":"啥索引能用change buffer？ 对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。而这必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用change buffer了。 只有普通索引能使用change buffer ","date":"2019-05-25","objectID":"/9-%E6%99%AE%E9%80%9A%E7%B4%A2%E5%BC%95%E5%92%8C%E5%94%AF%E4%B8%80%E7%B4%A2%E5%BC%95%E7%9A%84%E5%8C%BA%E5%88%AB/:0:3","tags":["MySQL","学习笔记"],"title":"9.普通索引和唯一索引的区别","uri":"/9-%E6%99%AE%E9%80%9A%E7%B4%A2%E5%BC%95%E5%92%8C%E5%94%AF%E4%B8%80%E7%B4%A2%E5%BC%95%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["MySQL学习笔记"],"content":"插入一条新记录的流程 这个记录要更新的目标页在内存中 对于唯一索引来说，找到3和5之间的位置，判断到没有冲突，插入这个值，语句执行结束； 对于普通索引来说，找到3和5之间的位置，插入这个值，语句执行结束。 这个记录要更新的目标页不在内存中 对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束； 对于普通索引来说，则是将更新记录在change buffer，语句执行就结束了。 将数据从磁盘读入内存涉及随机IO的访问，是数据库里面成本最高的操作之一。change buffer因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。 ","date":"2019-05-25","objectID":"/9-%E6%99%AE%E9%80%9A%E7%B4%A2%E5%BC%95%E5%92%8C%E5%94%AF%E4%B8%80%E7%B4%A2%E5%BC%95%E7%9A%84%E5%8C%BA%E5%88%AB/:0:4","tags":["MySQL","学习笔记"],"title":"9.普通索引和唯一索引的区别","uri":"/9-%E6%99%AE%E9%80%9A%E7%B4%A2%E5%BC%95%E5%92%8C%E5%94%AF%E4%B8%80%E7%B4%A2%E5%BC%95%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["MySQL学习笔记"],"content":"change buffer的使用场景 写多读少，change buffer收效更高 会积攒很多修改到change buffer里，再统一merge 写少读多，不适合用change buffer 刚写入一条修改到change buffer里，就执行读请求，马上需要执行merge，无收益且需要维护change buffer ","date":"2019-05-25","objectID":"/9-%E6%99%AE%E9%80%9A%E7%B4%A2%E5%BC%95%E5%92%8C%E5%94%AF%E4%B8%80%E7%B4%A2%E5%BC%95%E7%9A%84%E5%8C%BA%E5%88%AB/:0:5","tags":["MySQL","学习笔记"],"title":"9.普通索引和唯一索引的区别","uri":"/9-%E6%99%AE%E9%80%9A%E7%B4%A2%E5%BC%95%E5%92%8C%E5%94%AF%E4%B8%80%E7%B4%A2%E5%BC%95%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["MySQL学习笔记"],"content":"change buffer 和 redo log redo log 主要节省的是随机写磁盘的IO消耗（转成顺序写），而change buffer主要节省的则是随机读磁盘的IO消耗。 ","date":"2019-05-25","objectID":"/9-%E6%99%AE%E9%80%9A%E7%B4%A2%E5%BC%95%E5%92%8C%E5%94%AF%E4%B8%80%E7%B4%A2%E5%BC%95%E7%9A%84%E5%8C%BA%E5%88%AB/:0:6","tags":["MySQL","学习笔记"],"title":"9.普通索引和唯一索引的区别","uri":"/9-%E6%99%AE%E9%80%9A%E7%B4%A2%E5%BC%95%E5%92%8C%E5%94%AF%E4%B8%80%E7%B4%A2%E5%BC%95%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["MySQL学习笔记"],"content":"两种\"视图\" view 用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果create view ... InnoDB在实现MVCC时用到的一致性读视图，即consistent read view，用于支持RC（Read Committed，读提交）和RR（Repeatable Read，可重复读）隔离级别的实现。 ","date":"2019-05-25","objectID":"/8-%E4%BA%8B%E5%8A%A1%E5%88%B0%E5%BA%95%E6%98%AF%E4%B8%8D%E6%98%AF%E9%9A%94%E7%A6%BB%E7%9A%84/:1:0","tags":["MySQL","学习笔记"],"title":"8.事务到底是不是隔离的","uri":"/8-%E4%BA%8B%E5%8A%A1%E5%88%B0%E5%BA%95%E6%98%AF%E4%B8%8D%E6%98%AF%E9%9A%94%E7%A6%BB%E7%9A%84/"},{"categories":["MySQL学习笔记"],"content":"“快照”在MVCC里是怎么工作的? 每个事务都有一个唯一的trx_id，由innodb引擎分配，递增 数据表中的一行记录，可能有多个版本(row)，每个版本有自己的row trx_id 快照通过当前数据+undolog来恢复到事务启动时的状态来获取的 这就是一致性读 ","date":"2019-05-25","objectID":"/8-%E4%BA%8B%E5%8A%A1%E5%88%B0%E5%BA%95%E6%98%AF%E4%B8%8D%E6%98%AF%E9%9A%94%E7%A6%BB%E7%9A%84/:2:0","tags":["MySQL","学习笔记"],"title":"8.事务到底是不是隔离的","uri":"/8-%E4%BA%8B%E5%8A%A1%E5%88%B0%E5%BA%95%E6%98%AF%E4%B8%8D%E6%98%AF%E9%9A%94%E7%A6%BB%E7%9A%84/"},{"categories":["MySQL学习笔记"],"content":"更新逻辑 更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”，否则就可能会丢失其他事务的修改 ","date":"2019-05-25","objectID":"/8-%E4%BA%8B%E5%8A%A1%E5%88%B0%E5%BA%95%E6%98%AF%E4%B8%8D%E6%98%AF%E9%9A%94%E7%A6%BB%E7%9A%84/:3:0","tags":["MySQL","学习笔记"],"title":"8.事务到底是不是隔离的","uri":"/8-%E4%BA%8B%E5%8A%A1%E5%88%B0%E5%BA%95%E6%98%AF%E4%B8%8D%E6%98%AF%E9%9A%94%E7%A6%BB%E7%9A%84/"},{"categories":["MySQL学习笔记"],"content":"读提交和可重复读的区别 在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图，查询只承认在事务启动前就已经提交完成的数据； 在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图，查询只承认在语句启动前就已经提交完成的数据。 而当前读，总是读取已经提交完成的最新版本 ","date":"2019-05-25","objectID":"/8-%E4%BA%8B%E5%8A%A1%E5%88%B0%E5%BA%95%E6%98%AF%E4%B8%8D%E6%98%AF%E9%9A%94%E7%A6%BB%E7%9A%84/:4:0","tags":["MySQL","学习笔记"],"title":"8.事务到底是不是隔离的","uri":"/8-%E4%BA%8B%E5%8A%A1%E5%88%B0%E5%BA%95%E6%98%AF%E4%B8%8D%E6%98%AF%E9%9A%94%E7%A6%BB%E7%9A%84/"},{"categories":["MySQL学习笔记"],"content":"全局锁 ","date":"2019-05-25","objectID":"/6-7-%E5%85%A8%E5%B1%80%E9%94%81-%E8%A1%A8%E9%94%81-%E8%A1%8C%E9%94%81/:1:0","tags":["MySQL","学习笔记"],"title":"6\u00267.全局锁、表锁、行锁","uri":"/6-7-%E5%85%A8%E5%B1%80%E9%94%81-%E8%A1%A8%E9%94%81-%E8%A1%8C%E9%94%81/"},{"categories":["MySQL学习笔记"],"content":"命令 Flush tables with read lock ","date":"2019-05-25","objectID":"/6-7-%E5%85%A8%E5%B1%80%E9%94%81-%E8%A1%A8%E9%94%81-%E8%A1%8C%E9%94%81/:1:1","tags":["MySQL","学习笔记"],"title":"6\u00267.全局锁、表锁、行锁","uri":"/6-7-%E5%85%A8%E5%B1%80%E9%94%81-%E8%A1%A8%E9%94%81-%E8%A1%8C%E9%94%81/"},{"categories":["MySQL学习笔记"],"content":"阻塞语句 数据更新语句（数据的增删改） 数据定义语句（包括建表、修改表结构等） 更新类事务的提交语句 ","date":"2019-05-25","objectID":"/6-7-%E5%85%A8%E5%B1%80%E9%94%81-%E8%A1%A8%E9%94%81-%E8%A1%8C%E9%94%81/:1:2","tags":["MySQL","学习笔记"],"title":"6\u00267.全局锁、表锁、行锁","uri":"/6-7-%E5%85%A8%E5%B1%80%E9%94%81-%E8%A1%A8%E9%94%81-%E8%A1%8C%E9%94%81/"},{"categories":["MySQL学习笔记"],"content":"使用场景 做全库逻辑备份 ","date":"2019-05-25","objectID":"/6-7-%E5%85%A8%E5%B1%80%E9%94%81-%E8%A1%A8%E9%94%81-%E8%A1%8C%E9%94%81/:1:3","tags":["MySQL","学习笔记"],"title":"6\u00267.全局锁、表锁、行锁","uri":"/6-7-%E5%85%A8%E5%B1%80%E9%94%81-%E8%A1%A8%E9%94%81-%E8%A1%8C%E9%94%81/"},{"categories":["MySQL学习笔记"],"content":"不加锁会有什么问题 不加锁的话，备份系统备份的得到的库不是一个逻辑时间点，这个视图是逻辑不一致的。 ","date":"2019-05-25","objectID":"/6-7-%E5%85%A8%E5%B1%80%E9%94%81-%E8%A1%A8%E9%94%81-%E8%A1%8C%E9%94%81/:1:4","tags":["MySQL","学习笔记"],"title":"6\u00267.全局锁、表锁、行锁","uri":"/6-7-%E5%85%A8%E5%B1%80%E9%94%81-%E8%A1%A8%E9%94%81-%E8%A1%8C%E9%94%81/"},{"categories":["MySQL学习笔记"],"content":"mysqldump –single-transaction 当mysqldump使用参数–single-transaction的时候，导数据之前就会启动一个事务，来确保拿到一致性视图 使用这个需要引擎支持事务才可以。 ","date":"2019-05-25","objectID":"/6-7-%E5%85%A8%E5%B1%80%E9%94%81-%E8%A1%A8%E9%94%81-%E8%A1%8C%E9%94%81/:1:5","tags":["MySQL","学习笔记"],"title":"6\u00267.全局锁、表锁、行锁","uri":"/6-7-%E5%85%A8%E5%B1%80%E9%94%81-%E8%A1%A8%E9%94%81-%E8%A1%8C%E9%94%81/"},{"categories":["MySQL学习笔记"],"content":"表锁 ","date":"2019-05-25","objectID":"/6-7-%E5%85%A8%E5%B1%80%E9%94%81-%E8%A1%A8%E9%94%81-%E8%A1%8C%E9%94%81/:2:0","tags":["MySQL","学习笔记"],"title":"6\u00267.全局锁、表锁、行锁","uri":"/6-7-%E5%85%A8%E5%B1%80%E9%94%81-%E8%A1%A8%E9%94%81-%E8%A1%8C%E9%94%81/"},{"categories":["MySQL学习笔记"],"content":"命令 lock tables … read/write unlock tables ","date":"2019-05-25","objectID":"/6-7-%E5%85%A8%E5%B1%80%E9%94%81-%E8%A1%A8%E9%94%81-%E8%A1%8C%E9%94%81/:2:1","tags":["MySQL","学习笔记"],"title":"6\u00267.全局锁、表锁、行锁","uri":"/6-7-%E5%85%A8%E5%B1%80%E9%94%81-%E8%A1%A8%E9%94%81-%E8%A1%8C%E9%94%81/"},{"categories":["MySQL学习笔记"],"content":"MDL metadata lock 在MySQL 5.5版本中引入了MDL，当对一个表做增删改查操作的时候，加MDL读锁；当要对表做结构变更操作的时候，加MDL写锁。 MDL的坑 修改表结构时，会扫描全表数据，所以我们不会贸然修改服务中的大表的结构；但是修改高频查询的小表的结构也要小心，如下图所示，sessionD以后到达的查询请求都会被阻塞。 ","date":"2019-05-25","objectID":"/6-7-%E5%85%A8%E5%B1%80%E9%94%81-%E8%A1%A8%E9%94%81-%E8%A1%8C%E9%94%81/:2:2","tags":["MySQL","学习笔记"],"title":"6\u00267.全局锁、表锁、行锁","uri":"/6-7-%E5%85%A8%E5%B1%80%E9%94%81-%E8%A1%A8%E9%94%81-%E8%A1%8C%E9%94%81/"},{"categories":["MySQL学习笔记"],"content":"行锁 在InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放，这个就是两阶段锁协议。 启示：如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放 ","date":"2019-05-25","objectID":"/6-7-%E5%85%A8%E5%B1%80%E9%94%81-%E8%A1%A8%E9%94%81-%E8%A1%8C%E9%94%81/:3:0","tags":["MySQL","学习笔记"],"title":"6\u00267.全局锁、表锁、行锁","uri":"/6-7-%E5%85%A8%E5%B1%80%E9%94%81-%E8%A1%A8%E9%94%81-%E8%A1%8C%E9%94%81/"},{"categories":["MySQL学习笔记"],"content":"死锁和死锁检测 当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁 策略 直接进入等待，直到超时。这个超时时间可以通过参数innodb_lock_wait_timeout来设置。 发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数innodb_deadlock_detect设置为on，表示开启这个逻辑。 死锁检测会带来额外的负担，即每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是O(n)的操作，其中n是要更新这一行的并发度。这个问题有如下解决方案： \u0008业务逻辑保证一定不会出现死锁，关闭死锁检测 控制并发度 在客户端控制 不行，因为客户端很多，单个数量可控，但是依然无法控制总数量。 在数据库服务端控制，中间件、或者直接修改MySQL源码 一行改成逻辑上的多行来减少锁冲突 以影院账户为例，可以考虑放在多条记录上，比如10个记录，影院的账户总额等于这10个记录的值的总和。这样每次要给影院账户加金额的时候，随机选其中一条记录来加。这样每次冲突概率变成原来的1/10，可以减少锁等待个数，也就减少了死锁检测的CPU消耗。 ","date":"2019-05-25","objectID":"/6-7-%E5%85%A8%E5%B1%80%E9%94%81-%E8%A1%A8%E9%94%81-%E8%A1%8C%E9%94%81/:3:1","tags":["MySQL","学习笔记"],"title":"6\u00267.全局锁、表锁、行锁","uri":"/6-7-%E5%85%A8%E5%B1%80%E9%94%81-%E8%A1%A8%E9%94%81-%E8%A1%8C%E9%94%81/"},{"categories":["MySQL学习笔记"],"content":"常见索引模型 ","date":"2019-05-25","objectID":"/4-5-%E7%B4%A2%E5%BC%95/:1:0","tags":["MySQL","学习笔记"],"title":"4\u00265.索引","uri":"/4-5-%E7%B4%A2%E5%BC%95/"},{"categories":["MySQL学习笔记"],"content":"哈希表 插入很快，只需要在对应位置插入值即可 O(1) 等值查询也很快O(1) 区间查询只能全表扫描 O(N) ， 因为索引是无序的 哈希表适合无需区间查询的场景。 ","date":"2019-05-25","objectID":"/4-5-%E7%B4%A2%E5%BC%95/:1:1","tags":["MySQL","学习笔记"],"title":"4\u00265.索引","uri":"/4-5-%E7%B4%A2%E5%BC%95/"},{"categories":["MySQL学习笔记"],"content":"有序数组 等值查询和范围查询都很快 插入操作需要后移所有元素，消耗很大 有序数组索引适合静态存储引擎，如2017年某个城市的人口数据这类不会改动的数据。 ","date":"2019-05-25","objectID":"/4-5-%E7%B4%A2%E5%BC%95/:1:2","tags":["MySQL","学习笔记"],"title":"4\u00265.索引","uri":"/4-5-%E7%B4%A2%E5%BC%95/"},{"categories":["MySQL学习笔记"],"content":"排序树 crud都有O(logN)的速度 为了尽量减少随机访问，增加数的叉数，降低树的高度；所以可以有二叉排序树，也可以有多叉排序树 ","date":"2019-05-25","objectID":"/4-5-%E7%B4%A2%E5%BC%95/:1:3","tags":["MySQL","学习笔记"],"title":"4\u00265.索引","uri":"/4-5-%E7%B4%A2%E5%BC%95/"},{"categories":["MySQL学习笔记"],"content":"InnoDB的索引模型 InnoDB使用了B+树索引模型 ","date":"2019-05-25","objectID":"/4-5-%E7%B4%A2%E5%BC%95/:2:0","tags":["MySQL","学习笔记"],"title":"4\u00265.索引","uri":"/4-5-%E7%B4%A2%E5%BC%95/"},{"categories":["MySQL学习笔记"],"content":"主键索引和非主键索引 主键索引的叶子节点存的是整行数据 非主键索引的叶子节点内容是主键的值 普通索引查询方式，则需要先搜索非主键索引树，得到主键的值，再到主键索引树搜索一次，这个过程称为回表。也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。 ","date":"2019-05-25","objectID":"/4-5-%E7%B4%A2%E5%BC%95/:2:1","tags":["MySQL","学习笔记"],"title":"4\u00265.索引","uri":"/4-5-%E7%B4%A2%E5%BC%95/"},{"categories":["MySQL学习笔记"],"content":"索引维护 三种情况 索引树叶子节点右侧追加，直接插入即可 插入叶子节点间，需逻辑上挪动后面的数据 数据页已满，需要申请新的数据页，然后挪部分数据过去，这个过程成为页分裂；这种情况下不仅影响性能，还会降低数据页的利用率 问题1：自增主键的意义？ 尽量保证每次操作都是第一种情况，即有序插入，追加节点 问题2：如果有身份证号这种业务上能保证一致的列，能否直接设置为主键？ 如果这个表中除了主键还有其他索引，那么不建议，因为这会导致其他非主键索引中存储的值会变长。 如果只有一个唯一索引，那就可以放心大胆的设置它为主键了，这样可以避免非主键索引的回表操作；这里描述的场景就是典型的kv场景。 ","date":"2019-05-25","objectID":"/4-5-%E7%B4%A2%E5%BC%95/:2:2","tags":["MySQL","学习笔记"],"title":"4\u00265.索引","uri":"/4-5-%E7%B4%A2%E5%BC%95/"},{"categories":["MySQL学习笔记"],"content":"覆盖索引 表T的结构如下 id(主键) k(索引) s 100 1 aa 200 2 bb 300 3 cc 500 5 ee 600 6 ff 700 7 gg 当我们执行select * from T where k between 3 and 5时，它的执行流程如下： 在k索引树上找到k=3的记录，取得 ID = 300； 再到ID索引树查到ID=300对应的R3； 在k索引树取下一个值k=5，取得ID=500； 再回到ID索引树查到ID=500对应的R4； 在k索引树取下一个值k=6，不满足条件，循环结束。 在这个过程中，回到主键索引树搜索的过程，我们称为回表。可以看到，这个查询过程读了k索引树的3条记录（步骤1、3和5），回表了两次（步骤2和4）。 问题：如何避免回表过程？ 执行语句select ID from T where k between 3 and 5，因为要查询的ID的值已经在k的索引树上了，所以不再需要回表。 在这个查询里面，索引k已经“覆盖了”我们的查询需求，我们称为覆盖索引 Tips：利用覆盖索引优化性能 市民信息表中，有身份证号和姓名两个字段，如果有高频需求是根据身份证号查询姓名，那我们可以考虑给身份证号和姓名建立联合索引，以便利用覆盖索引提高查询性能。 ","date":"2019-05-25","objectID":"/4-5-%E7%B4%A2%E5%BC%95/:2:3","tags":["MySQL","学习笔记"],"title":"4\u00265.索引","uri":"/4-5-%E7%B4%A2%E5%BC%95/"},{"categories":["MySQL学习笔记"],"content":"最左前缀 基本概念 当已经有了(a,b)这个联合索引后，一般就不需要单独在a上建立索引了 如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的 考虑空间 如果既有联合查询，又有基于a、b各自的查询呢？查询条件里面只有b的语句，是无法使用(a,b)这个联合索引的，这时候你不得不维护另外一个索引，也就是说你需要同时维护(a,b)、(b) 这两个索引。 这时候，我们要考虑的原则就是空间了。比如上面这个市民表的情况，name字段是比age字段大的 ，那我就建议你创建一个（name,age)的联合索引和一个(age)的单字段索引。 ","date":"2019-05-25","objectID":"/4-5-%E7%B4%A2%E5%BC%95/:2:4","tags":["MySQL","学习笔记"],"title":"4\u00265.索引","uri":"/4-5-%E7%B4%A2%E5%BC%95/"},{"categories":["MySQL学习笔记"],"content":"索引下推 在MySQL5.6中引入了索引下推优化，可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。 举个栗子 假设现在有联合索引（name, age），执行select * from tuser where name like '张%' and age=10 and ismale=1; ","date":"2019-05-25","objectID":"/4-5-%E7%B4%A2%E5%BC%95/:2:5","tags":["MySQL","学习笔记"],"title":"4\u00265.索引","uri":"/4-5-%E7%B4%A2%E5%BC%95/"},{"categories":["MySQL学习笔记"],"content":"事务隔离级别 读未提交：一个事务还没提交时，它做的变更就能被别的事务看到 读提交：一个事务提交之后，它做的变更才会被其他事务看到 可重复读：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的 串行化 ","date":"2019-05-22","objectID":"/3-%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB/:1:0","tags":["MySQL","学习笔记"],"title":"3.事务隔离","uri":"/3-%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB/"},{"categories":["MySQL学习笔记"],"content":"事务隔离的实现 在MySQL中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。 假设一个值从1被按顺序改成了2、3、4，在回滚日志里面就会有类似下面的记录。每次有事务需要获取历史值时，根据事务的视图，通过回滚日志即可得到历史数据。 这里带来的一个问题就是回滚日志啥时候删除，答案是在没有事务依赖的时候删除。所以长事务是很不推荐的使用。 ","date":"2019-05-22","objectID":"/3-%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB/:2:0","tags":["MySQL","学习笔记"],"title":"3.事务隔离","uri":"/3-%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB/"},{"categories":["MySQL学习笔记"],"content":"事务的启动方式 begin/start transaction commit/rollback set autocommit=0，这个命令会将这个线程的自动提交关掉 ","date":"2019-05-22","objectID":"/3-%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB/:3:0","tags":["MySQL","学习笔记"],"title":"3.事务隔离","uri":"/3-%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB/"},{"categories":["MySQL学习笔记"],"content":"redo log innodb的“语音便签” 我早上上班路上一边开车一边听专栏，听到需要记录的东西会在等红灯的时候用语音便签记录下，晚上睡觉前才会整理成博客。这个过程中，边开车边整理博客我是做不到的，所以我先用语音便签做了一个简单记录，等我空闲的时候才会把语音便签整理到博客上。 MySQL也一样，如果每次更新、删除操作都去直接更新磁盘文件，那能容忍的并发恐怕极其有限了。在innodb中采用了redo log的方式先把操作记录下来，等空闲的时候再把redo log批量更新到磁盘中。 redo log的文件数量和大小可以配置，当达到配置的值时，会触发批量写入磁盘操作，清空redo log。 ","date":"2019-05-22","objectID":"/2-%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/:1:0","tags":["MySQL","学习笔记"],"title":"2.日志系统","uri":"/2-%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"},{"categories":["MySQL学习笔记"],"content":"名词 WAL技术 Write-Ahead Logging 先写日志，再写磁盘 crash-safe 有了redo log，可以保证即使服务突然异常，也不会丢失数据 ","date":"2019-05-22","objectID":"/2-%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/:1:1","tags":["MySQL","学习笔记"],"title":"2.日志系统","uri":"/2-%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"},{"categories":["MySQL学习笔记"],"content":"binlog Server层的“语音便签” 上面的redo log是引擎层的日志，server层也有自己的日志，称为binlog（归档日志） ","date":"2019-05-22","objectID":"/2-%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/:2:0","tags":["MySQL","学习笔记"],"title":"2.日志系统","uri":"/2-%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"},{"categories":["MySQL学习笔记"],"content":"问题 为什么有两份日志？ binlog只有归档能力，没有crash-safe能力；innodb为了crash-safe能力引入了redo log binlog和redo log有啥不同？ redo log是innodb特有的，binlog是MySQL的server层的日志，所有引擎都可以使用 redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ” redo log是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。 ","date":"2019-05-22","objectID":"/2-%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/:2:1","tags":["MySQL","学习笔记"],"title":"2.日志系统","uri":"/2-%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"},{"categories":["MySQL学习笔记"],"content":"两阶段提交 ","date":"2019-05-22","objectID":"/2-%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/:3:0","tags":["MySQL","学习笔记"],"title":"2.日志系统","uri":"/2-%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"},{"categories":["MySQL学习笔记"],"content":"一次更新操作的流程 执行器找引擎取到要修改的记录 引擎查看记录是否在内存中，如果在内存中，直接返回给执行器；否则需要从磁盘读入内存，然后再返回 执行器拿到数据后计算新的数值，再调用引擎写入这行新数据 引擎将这行数据更新到内存中，同时写入redo log(prepare状态)；然后告知执行器执行完了，随时可以提交事务 执行器把这个操作的binlog写入磁盘中 执行器通知引擎，引擎把刚刚写入的redo log状态更新为commit ","date":"2019-05-22","objectID":"/2-%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/:3:1","tags":["MySQL","学习笔记"],"title":"2.日志系统","uri":"/2-%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"},{"categories":["MySQL学习笔记"],"content":"为什么需要两阶段提交？ 如果MySQL服务异常宕机，我们需要使用定时镜像+binlog来恢复数据。 如果没有两阶段提交，要么先写binlog，要么先写redo log，考虑只写了一个日志的情况，即写完一个日志就宕机的情况。 先写redo log后写binlog redo log恢复后的数据是更新后的 binlog恢复的数据是更新前的 先写binlog后写redo log binlog恢复的数据是更新后的 redo log恢复的数据是更新前的 如果没有两阶段提交，上述情况下就出现了引擎状态(库的实际状态)和用binlog恢复出来的库状态不一致的问题；不只有数据库，两阶段提交也是跨系统维持数据逻辑一致性时常用的一个方案。 ","date":"2019-05-22","objectID":"/2-%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/:3:2","tags":["MySQL","学习笔记"],"title":"2.日志系统","uri":"/2-%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"},{"categories":["Golang学习笔记"],"content":"接口的基本性质 package main import \"fmt\" //定义一个接口Pet，接口里的内容是接口方法的定义，只要一个数据类型的方法集合中有这3个方法，那么它就一定是Pet接口的实现类型 type Pet interface { SetName(name string) Name() string Category() string } //结构体Dog相关定义 type Dog struct { name string } func (dog *Dog) SetName(name string) { dog.name = name } func (dog Dog) Name() string { return dog.name } func (dog Dog) Category() string { return \"dog\" } //经过上述定义，得到一个Dog类型的结构体，实现了Name()、Category()方法；一个Dog的指针类型*Dog，实现了SetName()方法 func main() { // 示例1。 dog := Dog{\"little pig\"} _, ok := interface{}(dog).(Pet) fmt.Printf(\"Dog implements interface Pet: %v\\n\", ok) //false，因为Dog没有实现setName()方法 _, ok = interface{}(\u0026dog).(Pet) fmt.Printf(\"*Dog implements interface Pet: %v\\n\", ok) //true,因为*Dog实现了setName()方法 fmt.Println() // 示例2。 var pet Pet = \u0026dog //此时pet的动态类型是*Dog；动态值是\u0026dog fmt.Printf(\"This pet is a %s, the name is %q.\\n\", pet.Category(), pet.Name()) } 当我们为一个接口变量赋值时会发生什么 package main import \"fmt\" type Pet interface { Name() string Category() string } type Dog struct { name string } func (dog *Dog) SetName(name string) { dog.name = name } func (dog Dog) Name() string { return dog.name } func (dog Dog) Category() string { return \"dog\" } func main() { // 示例1。 dog := Dog{\"little pig\"} //初始化一个Dog fmt.Printf(\"The dog's name is %q.\\n\", dog.Name()) var pet Pet = dog //赋值给pet接口 dog.SetName(\"monster\") //调用dog的指针的方法，设置name的值；这个操作完成后dog的Name已经变化了，但是pet的Name没有变化(因为pet拿到的是dog的副本，不是原值，所以dog原值的指针只能修改dog原值的内容) fmt.Printf(\"The dog's name is %q.\\n\", dog.Name()) //monster fmt.Printf(\"This pet is a %s, the name is %q.\\n\", pet.Category(), pet.Name()) //原来的值 fmt.Println() //事实上，pet包含了dog的副本，但是不只是dog的副本；它是一种叫iface的实例，它有两个指针，一个指向类型信息，一个指向动态值。 // 示例2。 dog1 := Dog{\"little pig\"} fmt.Printf(\"The name of first dog is %q.\\n\", dog1.Name()) //pig dog2 := dog1 fmt.Printf(\"The name of second dog is %q.\\n\", dog2.Name()) //pig dog1.name = \"monster\" //只修改了dog1的name，dog2不变 fmt.Printf(\"The name of first dog is %q.\\n\", dog1.Name()) //monster fmt.Printf(\"The name of second dog is %q.\\n\", dog2.Name()) //pig fmt.Println() // 示例3。 dog = Dog{\"little pig\"} fmt.Printf(\"The dog's name is %q.\\n\", dog.Name()) //pig pet = \u0026dog //pet的动态类型是*Dog dog.SetName(\"monster\") //dog的值发生了变化，因为pet的值是dog指针的副本，所以pet的值也发生了变化 fmt.Printf(\"The dog's name is %q.\\n\", dog.Name()) fmt.Printf(\"This pet is a %s, the name is %q.\\n\", pet.Category(), pet.Name()) //monster } 接口变量的值在什么情况下才真正为nil？ 只有声明但不初始化，或者显示的赋值为nil时候，接口变量的值才真正为nil； 如果把一个值为nil的结构体变量赋值给接口变量，这个接口变量的值并不是真正的nil；因为它的另外一个指针保存了这个结构体变量的类型。 接口的组合 因为接口只有方法定义，无法覆盖，直接嵌套即可 go语言团队推荐开发者使用小接口的方式，便于接口的自由组合 type Animal interface { ScientificName() string Category() string } type Pet interface { Animal Name() string } ","date":"2019-05-07","objectID":"/7-%E6%8E%A5%E5%8F%A3/:0:0","tags":["Golang","学习笔记"],"title":"7.接口","uri":"/7-%E6%8E%A5%E5%8F%A3/"},{"categories":["Golang学习笔记"],"content":"goroutine goroutine是用户级线程，它的优势在于开销低、灵活(因为完全由用户自己控制，不需要等待系统调度)；劣势在于复杂，因为整个过程需要用户自己管理。但是go语言提供了一套强大的调度器，用于调度goroutine、对接系统级的线程。 goroutine调度器 调度器包含三个主要元素G（goroutine的缩写）、P（processor的缩写）和M（machine的缩写） G就是指goroutine M指系统级线程 P指可以承载若干个G，且能够使这些G适时地与M进行对接，并得到真正运行的中介 收回G资源：当一个正在与某个M对接并运行着的G，需要因某个事件（比如等待I/O或锁的解除）而暂停运行的时候，调度器总会及时地发现，并把这个G与那个M分离开，以释放计算资源供那些等待运行的G使用。 分配G资源：当一个G需要恢复运行的时候，调度器又会尽快地为它寻找空闲的计算资源（包括M）并安排运行。 创建新的系统线程：M不够用时，调度器会帮我们向操作系统申请新的系统级线程，而当某个M已无用时，调度器又会负责把它及时地销毁掉 主goroutine和其他goroutine有何不同 主goroutine和其他goroutine是什么？ 主goroutine执行的就是main函数对应的内容 其他goroutine是由主goroutine调用go语句显示的创建出来的 go函数的执行时间明显之后与go语句的执行时间，因为go语句做的事情就是把这个G放入待执行的队列，至于这个G什么时间被执行，以什么样的顺序执行不做保证。 所以主goroutine默认并不会保证其他goroutine是否能执行、是否按顺序执行，主goroutnie默认也不会等待其他goroutine结束再结束。 所以下面代码可能的执行结果有 按随机顺序输出0~n(n≤9) 部分子goroutine运行后，主goroutine才结束 完全不输出 当子goroutine还没来的及运行时，主goroutine就结束了，这种情况的可能性较大 func main() { for i := 0; i \u003c 10; i++ { go func() { fmt.Println(i) }() } } 怎样才能让主goroutine等待其他goroutine 让主goroutine sleep一段时间，这种方式的优势是简单粗暴；劣势是时间无法把握，所以一般不会采用这种方式。 通过通道进行主goroutine和子goroutine间的通信，当子goroutine都执行完成后，主goroutine再结束 这种情况下通道只需要传输信号，可以使用空结构体值字面量 struct{}；这东西在go语言中只有一份，且所有程序都会用这一份变量。 func main() { num := 10 sign := make(chan struct{}, num) for i := 0; i \u003c num; i++ { go func() { fmt.Println(i) sign \u003c- struct{}{} }() } // 办法1。 //time.Sleep(time.Millisecond * 500) // 办法2。 for j := 0; j \u003c num; j++ { \u003c-sign } } ","date":"2019-05-07","objectID":"/8-goroutine/:0:0","tags":["Golang","学习笔记"],"title":"8.goroutine","uri":"/8-goroutine/"},{"categories":["Golang学习笔记"],"content":"结构体用”组合“的方式实现了类似其他语言中的”继承“ 这里和其他语言的继承很相似，所以不再记录 值方法和指针方法 ","date":"2019-05-07","objectID":"/6-%E7%BB%93%E6%9E%84%E4%BD%93/:0:0","tags":["Golang","学习笔记"],"title":"6.结构体","uri":"/6-%E7%BB%93%E6%9E%84%E4%BD%93/"},{"categories":["Golang学习笔记"],"content":"不同点 传入内容 值方法的接收者是该方法所属的那个类型值的一个副本。我们在该方法内对该副本的修改一般都不会体现在原值上，除非这个类型本身是某个引用类型（比如切片或字典）的别名类型。 而指针方法的接收者，是该方法所属的那个基本类型值的指针值的一个副本。我们在这样的方法内对该副本指向的值进行修改，就一定会体现在原值上。 方法集合 一个自定义数据类型的方法集合中仅会包含它的所有值方法，而该类型的指针类型的方法集合却囊括了前者的所有方法，包括所有值方法和所有指针方法。 严格来讲，我们在这样的基本类型的值上只能调用到它的值方法。但是，Go语言会适时地为我们进行自动地转译，使得我们在这样的值上也能调用到它的指针方法。 比如，在Cat类型的变量cat之上，之所以我们可以通过cat.SetName(\"monster\")修改猫的名字，是因为Go语言把它自动转译为了(\u0026cat).SetName(\"monster\")，即：先取cat的指针值，然后在该指针值上调用SetName方法。 和接口的关系 一个类型的方法集合中有哪些方法与它能实现哪些接口类型是息息相关的。如果一个基本类型和它的指针类型的方法集合是不同的，那么它们具体实现的接口类型的数量就也会有差异，除非这两个数量都是零。 比如，一个指针类型实现了某某接口类型，但它的基本类型却不一定能够作为该接口的实现类型。 ","date":"2019-05-07","objectID":"/6-%E7%BB%93%E6%9E%84%E4%BD%93/:1:0","tags":["Golang","学习笔记"],"title":"6.结构体","uri":"/6-%E7%BB%93%E6%9E%84%E4%BD%93/"},{"categories":["Golang学习笔记"],"content":"举个栗子 package main import \"fmt\" type Cat struct { name string // 名字。 scientificName string // 学名。 category string // 动物学基本分类。 } //返回一个Cat结构体的名字叫New的函数 func New(name, scientificName, category string) Cat { return Cat{ name: name, scientificName: scientificName, category: category, } } //Cat指针类型的一个SetName方法，给指针的副本做修改 func (cat *Cat) SetName(name string) { cat.name = name //cat是指针类型 } //Cat类型的一个SetNameOfCopy方法，给值的副本做修改 func (cat Cat) SetNameOfCopy(name string) { cat.name = name //cat是值类型 } //Cat类型的一个get方法，获取对应字段的值 func (cat Cat) Name() string { return cat.name } func (cat Cat) ScientificName() string { return cat.scientificName } func (cat Cat) Category() string { return cat.category } //Cat类型的string方法 func (cat Cat) String() string { return fmt.Sprintf(\"%s (category: %s, name: %q)\", cat.scientificName, cat.category, cat.name) } func main() { cat := New(\"little pig\", \"American Shorthair\", \"cat\") cat.SetName(\"monster\") // (\u0026cat).SetName(\"monster\") 这里go语言做了自动转译，把基本类型转为了指针类型，修改有效 fmt.Printf(\"The cat: %s\\n\", cat) cat.SetNameOfCopy(\"little pig\") //对值的副本做修改，无效 fmt.Printf(\"The cat: %s\\n\", cat) type Pet interface { SetName(name string) Name() string Category() string ScientificName() string } _, ok := interface{}(cat).(Pet) fmt.Printf(\"Cat implements interface Pet: %v\\n\", ok) //false cat的基本类型没有实现SetName _, ok = interface{}(\u0026cat).(Pet) fmt.Printf(\"*Cat implements interface Pet: %v\\n\", ok)//true cat的指针类型实现了SetName } ","date":"2019-05-07","objectID":"/6-%E7%BB%93%E6%9E%84%E4%BD%93/:2:0","tags":["Golang","学习笔记"],"title":"6.结构体","uri":"/6-%E7%BB%93%E6%9E%84%E4%BD%93/"},{"categories":["Golang学习笔记"],"content":"函数是“一等公民” 函数不但可以用于封装代码、分割功能、解耦逻辑，还可以化身为普通的值，在其他函数间传递、赋予变量、做类型判断和转换等等，就像切片和字典的值那样 函数类型属于引用类型，它的值可以为nil，这种类型的零值也是nil。 type Printer func(contents string) (n int, err error) //声明函数类型 //函数printToStd的签名与Printer的是一致的,printToStd是Printer的一个实现 func printToStd(contents string) (bytesNum int, err error) { return fmt.Println(contents) } func main() { var p Printer //声明了一个Printer类型的变量p p = printToStd //把函数printToStd复制给变量p p(\"something\") //执行p } 高阶函数 ","date":"2019-04-23","objectID":"/5-%E5%87%BD%E6%95%B0/:0:0","tags":["Golang","学习笔记"],"title":"5.函数","uri":"/5-%E5%87%BD%E6%95%B0/"},{"categories":["Golang学习笔记"],"content":"高阶函数的特点 接受其他的函数作为参数传入 把其他的函数作为结果返回 type operate func(x, y int) int //声明一个函数类型 //calculate会根据传入的两个数字和对应的操作函数执行相应的操作 func calculate(x int, y int, op operate) (int, error) { if op == nil { return 0, errors.New(\"invalid operation\") } return op(x, y), nil } //创建一个operate类型的匿名函数 op := func(x, y int) int { return x + y } calculate(1, 2, op) //调用 ","date":"2019-04-23","objectID":"/5-%E5%87%BD%E6%95%B0/:1:0","tags":["Golang","学习笔记"],"title":"5.函数","uri":"/5-%E5%87%BD%E6%95%B0/"},{"categories":["Golang学习笔记"],"content":"高阶函数可以用来实现闭包 func genCalculator(op operate) calculateFunc { return func(x int, y int) (int, error) { if op == nil { return 0, errors.New(\"invalid operation\") } return op(x, y), nil } } 传入函数的参数 所有传给函数的参数值都会被复制，函数在其内部使用的并不是参数值的原值，而是它的副本 一言不合就是副本 对于引用类型，比如：切片、字典、通道，像上面那样复制它们的值，只会拷贝它们本身而已，并不会拷贝它们引用的底层数据 以切片值为例，如此复制的时候，只是拷贝了它指向底层数组中某一个元素的指针，以及它的长度值和容量值，而它的底层数组并不会被拷贝。 ","date":"2019-04-23","objectID":"/5-%E5%87%BD%E6%95%B0/:2:0","tags":["Golang","学习笔记"],"title":"5.函数","uri":"/5-%E5%87%BD%E6%95%B0/"},{"categories":["Golang学习笔记"],"content":"链表container/list 实体：List（双向链表）、Element(链表中元素的结构) 方法们 func (l *List) MoveBefore(e, mark *Element) func (l *List) MoveAfter(e, mark *Element) func (l *List) MoveToFront(e *Element) func (l *List) MoveToBack(e *Element) func (l *List) Front() *Element func (l *List) Back() *Element func (l *List) InsertBefore(v interface{}, mark *Element) *Element func (l *List) InsertAfter(v interface{}, mark *Element) *Element func (l *List) PushFront(v interface{}) *Element func (l *List) PushBack(v interface{}) *Element 为什么链表可以做到开箱即用？ 延迟初始化；同样的，切片也起到了延迟初始化底层数组的作用 优点：把计算压力从变量声明时延迟到真正使用变量时 缺点：每次使用变量之前都需要判断该变量是否已经被初始化了，拖慢性能 但是链表的PushFront方法、PushBack方法、PushBackList方法以及PushFrontList方法，本来就需要先判断链表的状态，并且一个新链表使用之前一定会调用这些方法的其中一个，巧妙的平衡了延迟初始化的缺点。 ","date":"2019-04-23","objectID":"/4-%E9%93%BE%E8%A1%A8/:0:0","tags":["Golang","学习笔记"],"title":"4.链表","uri":"/4-%E9%93%BE%E8%A1%A8/"},{"categories":["Golang学习笔记"],"content":" Don’t communicate by sharing memory; share memory by communicating. （不要通过共享内存来通信，而应该通过通信来共享内存。） 通道是Go语言中唯一一个可以满足并发安全的类型 通道的容量如果大于0，则为有缓冲区通道；否则为无缓冲区通道 基本特性 发送和接收操作都是互斥的 发送和接收操作都是原子的 发送操作和接收操作都是会阻塞的 发送操作时进入通道的并不是在接收操作符右边的那个元素值，而是它的副本 panic的来源 对关闭了的通道进行发送操作 试图关闭一个已经关闭了的通道；so：尽量让发送方来关闭通道 ch1 := make(chan int, 3) ch1 \u003c- 2 ch1 \u003c- 1 ch1 \u003c- 3 elem1 := \u003c-ch1 单向通道的应用场景 约束函数行为，下面的例子说明了我们实现SendInt方法时，只能从通道里读内容 type Notifier interface { SendInt(ch chan\u003c- int) } 在函数声明的结果列表中使用单向通道，下面的例子说明了，得到该通道的程序，只能从通道中接收元素值 func getIntChan() \u003c-chan int { num := 5 ch := make(chan int, num) for i := 0; i \u003c num; i++ { ch \u003c- i } close(ch) return ch } 我们在调用SendInt函数的时候，只需要把一个元素类型匹配的双向通道传给它就行了，没必要用发送通道，因为Go语言在这种情况下会自动地把双向通道转换为函数所需的单向通道。 ","date":"2019-04-23","objectID":"/3-%E9%80%9A%E9%81%93/:0:0","tags":["Golang","学习笔记"],"title":"3.通道","uri":"/3-%E9%80%9A%E9%81%93/"},{"categories":["Golang学习笔记"],"content":" map是一个哈希表的特定实现，是引用类型 map的键的类型是收到约束的，一定要是可判等的 因为map会先求键的哈希，哈希可能存在冲突，对比完哈希值后还要对比一下原值，所以需要是可判等的 所以map的键值类型不能是函数类型、字典类型和切片类型 最合适的键值类型是宽度低的类型，因为哈希计算快 panic的来源 给一个仅声明但是未初始化的词典(nil)增加键-值对 ","date":"2019-04-23","objectID":"/2-%E5%AD%97%E5%85%B8/:0:0","tags":["Golang","学习笔记"],"title":"2.字典","uri":"/2-%E5%AD%97%E5%85%B8/"},{"categories":["Golang学习笔记"],"content":" 切片是变长的，数组是定长的 切片是引用类型，数组是值类型 每个切片都有一个底层数组 切片可以认为是一个变长的窗口，可以透过这个窗口访问底层数组的内容 数组和切片有长度和容量的概念，可以通过函数len和cap获取；数组的长度和容量一直相等；切片的长度可变，容量就是它的底层数组的长度。 切片的底层数组不会改变，当切片长度超过容量需要扩容时，会创建一个新的切片和一个新的底层数组(长度为原来的2倍或者1.25倍) s1 := make([]int, 5) //长度为5，容量为8(底层数组长度为5)的切片 s2 := make([]int, 5, 8) //长度为5，容量为8(底层数组长度为8)的切片 s3 := []int{1, 2, 3, 4, 5, 6, 7, 8} // s4 := s3[3:6] //长度为3，容量为5(8-3)，该切片最多能访问s3中的3-\u003e8 数组和切片的比较 切片本身有着占用内存少和创建便捷等特点，但它的本质上还是数组 切片的一大好处是可以让我们通过窗口快速地定位并获取，或者修改底层数组中的元素。 切片删除元素比较麻烦，需要元素复制，还需要注意清空空闲槽位 切片的频繁扩容也是个严重的问题，因为扩容伴随着新的底层数组的不断产生，尤其是没有有效的缩容策略时 ","date":"2019-04-23","objectID":"/1-%E6%95%B0%E7%BB%84%E5%92%8C%E5%88%87%E7%89%87/:0:0","tags":["Golang","学习笔记"],"title":"1.数组和切片","uri":"/1-%E6%95%B0%E7%BB%84%E5%92%8C%E5%88%87%E7%89%87/"},{"categories":null,"content":"mysql系统 定位慢查询 慢查询日志 show variables like '%slow%'; 可查看log_slow_queries和slow_launch_time show global status like 'slow%'; 可查看 slow_launch_threads和slow_queries 最大连接数 show variables like 'max_connections'; 最大连接数配置 show global status like 'max_used_connections'; 最好max_used_connections/max_connections≈85% 使用explain查看执行计划 type all/range/const key 用到的索引，如果为null，可使用强制索引 force index key_len 索引长度 rows 预估扫描长度 extra 不友好情况 Using filesort, Using temporary 引擎选择：https://www.qiaomaoshuang.com/2019/04/18/MySQL%E7%9A%84%E5%BC%95%E6%93%8E%E3%80%81%E4%BA%8B%E5%8A%A1%E5%92%8C%E9%94%81/ 锁的选择：https://www.qiaomaoshuang.com/2019/04/18/MySQL%E7%9A%84%E5%BC%95%E6%93%8E%E3%80%81%E4%BA%8B%E5%8A%A1%E5%92%8C%E9%94%81/ 建表 符合3NF 1NF：表的列具有原子性，即列的信息不能分解 2NF：表中的记录是唯一的，通常通过主键来实现 3NF：无冗余信息 选择最合适的字段属性，尽量用小类型 varchar/char 变长/定长 not null 避免比较null enum会被当作整型处理，推荐 图片等大内容不要用db存储 SQL语句 大sql尽量拆分，利于多核cpu并发执行，容易命中缓存，不容易长时间锁表 事务尽量小 SELECT 不建议使用select * ，要指定列名 WHERE 避免在where中进行null值判断，因为这样会放弃索引进行全表扫描 不建议使用%模糊查询，这样会导致索引失效，进行全表扫描；如果必须，就建立全文索引 建议在相同类型的字段上进行比较，避免隐式类型转换 避免在where中对字段进行表达式操作 =\u003e 避免整个sql中出现运算，让db功能单一化 LIMIT 当只需要一条数据的时候，使用limit 1；这样explain的type会达到const级别 分页的limit可以用上一页的最大id替代 查询大量数据时，可以使用程序进行分段查询 UNION 如果两个结果没有重复数据，尽量用union all，因为union之后会做一次唯一性过滤操作 使用union来代替手动创建临时表 IN/EXISTS 关于IN 尽量用between替换 in和join相比，join更有优势一些，因为in需要创建临时表，但是要注意使用小表驱动大表 in和exists，遵循小表驱动的原则选择使用 in：子查询是驱动表 exists：外层表是驱动表 少使用not in；not exists可以用join代替 group by 默认分组后会排序，增加order by null即可避免排序 锁定表代替事务，事务的独占性会锁住表 TODO 索引 不建在建有索引的字段使用函数操作 如果要排序字段没有索引，建议减少对该字段的排序 or两侧的字段都有索引，才会走索引；可以用union来替代or 对于联合索引来说，要遵守最左前缀法则；同时如果存在范围查询(between/\u003e/\u003c)等条件时，会造成后面的索引失效 在大量用于join、where和order by的字段建立索引 不要在enum等大量重复内容的字段上建立索引，会拖慢速度（估计是因为字典树退化成链表导致的） ","date":"2019-04-18","objectID":"/mysql%E4%BC%98%E5%8C%96/:0:0","tags":["MySQL"],"title":"MySQL优化","uri":"/mysql%E4%BC%98%E5%8C%96/"},{"categories":null,"content":"存储引擎对比 项 MyISAM innodb 事务支持 否 是 全文索引 是 否（可以通过sphinx实现） 锁 表级，优先处理写入 行级（只在where是主键查询时可以实现） 出现死锁 否 是（解决方式是将持有最少行级排它锁的事务回滚） 外键 否 是 优势操作 count、大量instert操作 根据主键查询、高并发写入 存储结构 堆表、三个文件 索引组织表、一个文件 存储空间 可压缩 较大 可移植性 文件形式 数据文件/binlog/mysqldump 事务 ","date":"2019-04-18","objectID":"/mysql%E7%9A%84%E5%BC%95%E6%93%8E%E4%BA%8B%E5%8A%A1%E5%92%8C%E9%94%81/:0:0","tags":["MySQL"],"title":"MySQL的引擎、事务和锁","uri":"/mysql%E7%9A%84%E5%BC%95%E6%93%8E%E4%BA%8B%E5%8A%A1%E5%92%8C%E9%94%81/"},{"categories":null,"content":"性质 ACID（原子性、一致性、隔离性、持久性） ","date":"2019-04-18","objectID":"/mysql%E7%9A%84%E5%BC%95%E6%93%8E%E4%BA%8B%E5%8A%A1%E5%92%8C%E9%94%81/:1:0","tags":["MySQL"],"title":"MySQL的引擎、事务和锁","uri":"/mysql%E7%9A%84%E5%BC%95%E6%93%8E%E4%BA%8B%E5%8A%A1%E5%92%8C%E9%94%81/"},{"categories":null,"content":"并发问题 并发问题，这里假设A和B都是事务 脏读：A读到了B更新的数据，然后B回滚，A脏读了 不可重复读（侧重修改）：A多次读取同一记录，B在A读取的过程中，对数据做了更新并提交，导致A多次读取不一致 幻读（侧重新增/删除）：A修改了每一行的内容，B新增了一条数据，A幻读 不同隔离级别的事务可以规避不同数量的并发问题。 ","date":"2019-04-18","objectID":"/mysql%E7%9A%84%E5%BC%95%E6%93%8E%E4%BA%8B%E5%8A%A1%E5%92%8C%E9%94%81/:2:0","tags":["MySQL"],"title":"MySQL的引擎、事务和锁","uri":"/mysql%E7%9A%84%E5%BC%95%E6%93%8E%E4%BA%8B%E5%8A%A1%E5%92%8C%E9%94%81/"},{"categories":null,"content":"实现方式 通过记录binlog 锁 ","date":"2019-04-18","objectID":"/mysql%E7%9A%84%E5%BC%95%E6%93%8E%E4%BA%8B%E5%8A%A1%E5%92%8C%E9%94%81/:3:0","tags":["MySQL"],"title":"MySQL的引擎、事务和锁","uri":"/mysql%E7%9A%84%E5%BC%95%E6%93%8E%E4%BA%8B%E5%8A%A1%E5%92%8C%E9%94%81/"},{"categories":null,"content":"数据库锁 参考：https://www.cnblogs.com/xzwblog/p/6956817.html ","date":"2019-04-18","objectID":"/mysql%E7%9A%84%E5%BC%95%E6%93%8E%E4%BA%8B%E5%8A%A1%E5%92%8C%E9%94%81/:4:0","tags":["MySQL"],"title":"MySQL的引擎、事务和锁","uri":"/mysql%E7%9A%84%E5%BC%95%E6%93%8E%E4%BA%8B%E5%8A%A1%E5%92%8C%E9%94%81/"},{"categories":null,"content":"乐观锁和悲观锁 ","date":"2019-04-18","objectID":"/mysql%E7%9A%84%E5%BC%95%E6%93%8E%E4%BA%8B%E5%8A%A1%E5%92%8C%E9%94%81/:5:0","tags":["MySQL"],"title":"MySQL的引擎、事务和锁","uri":"/mysql%E7%9A%84%E5%BC%95%E6%93%8E%E4%BA%8B%E5%8A%A1%E5%92%8C%E9%94%81/"},{"categories":null,"content":"乐观锁 version实现 在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功。 ####cas实现 即compare and swap 或者 compare and set，涉及到三个操作数，数据所在的内存值，预期值，新值。当需要更新时，判断当前内存值与之前取到的值是否相等，若相等，则用新值更新，若失败则重试，一般情况下是一个自旋操作，即不断的重试。 ","date":"2019-04-18","objectID":"/mysql%E7%9A%84%E5%BC%95%E6%93%8E%E4%BA%8B%E5%8A%A1%E5%92%8C%E9%94%81/:5:1","tags":["MySQL"],"title":"MySQL的引擎、事务和锁","uri":"/mysql%E7%9A%84%E5%BC%95%E6%93%8E%E4%BA%8B%E5%8A%A1%E5%92%8C%E9%94%81/"},{"categories":null,"content":"悲观锁 总是假设最坏的情况，每次取数据时都认为其他线程会修改，所以都会加锁（读锁、写锁、行锁等），当其他线程想要访问数据时，都需要阻塞挂起。可以依靠数据库实现，如行锁、读锁和写锁等，都是在操作之前加锁。 ","date":"2019-04-18","objectID":"/mysql%E7%9A%84%E5%BC%95%E6%93%8E%E4%BA%8B%E5%8A%A1%E5%92%8C%E9%94%81/:5:2","tags":["MySQL"],"title":"MySQL的引擎、事务和锁","uri":"/mysql%E7%9A%84%E5%BC%95%E6%93%8E%E4%BA%8B%E5%8A%A1%E5%92%8C%E9%94%81/"},{"categories":["2019春节大礼包"],"content":"本文为2019春节期间用golang刷LeetCode时遇到的基础使用方式，备注一下，后续可直接复制取用。 ","date":"2019-03-21","objectID":"/go%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/:0:0","tags":["golang"],"title":"go语言基本用法","uri":"/go%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/"},{"categories":["2019春节大礼包"],"content":"array package main import \"fmt\" func main() { //dealare way1 var arr1 [5]int //可以认为[5]int是一种类型 fmt.Println(arr1) //dealare way2 arr2 := [...]int{1,2,3,4,5} fmt.Println(arr2) //dealare way3 arr3 := new([5]int) //得到指向数组的指针 fmt.Println(arr3) //traversing way1 for j := 0; j \u003c len(arr2); j++ { fmt.Println(arr2[j]) } //traversing way2 for i,_ := range arr3 { fmt.Println(arr3[i]) } } ","date":"2019-03-21","objectID":"/go%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/:1:0","tags":["golang"],"title":"go语言基本用法","uri":"/go%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/"},{"categories":["2019春节大礼包"],"content":"heap package main import \"fmt\" import \"container/heap\" type IntHeap []int func (h IntHeap) Len() int { return len(h) } func (h IntHeap) Less(i, j int) bool { return h[i] \u003c h[j] } func (h IntHeap) Swap(i, j int) { h[i], h[j] = h[j], h[i] } func (h *IntHeap) Push(x interface{}) { *h = append(*h, x.(int)) } func (h *IntHeap) Pop() interface{} { old := *h n := len(old) x := old[n-1] *h = old[0 : n-1] return x } func main() { h := \u0026IntHeap{2, 1, 5} heap.Init(h) heap.Push(h, 0) heap.Push(h, 6) fmt.Println(h) fmt.Println(h) fmt.Println(h) heap.Push(h, 1) fmt.Println(h) fmt.Println(h) } ","date":"2019-03-21","objectID":"/go%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/:2:0","tags":["golang"],"title":"go语言基本用法","uri":"/go%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/"},{"categories":["2019春节大礼包"],"content":"make package main import \"fmt\" func main() { //array 两种声明方式一样,都会开辟内存空间 var a1 [5]int a2 := [5]int{} a1[0] = 1 a2[0] = 1 fmt.Println(a1) fmt.Println(a2) //slice var不会开辟内存空间;:=如果传入值就会开辟，否则不开辟;make会开辟指定大小的内存空间;只有make的能直接赋值 var s1 []int s2 := []int{} s3 := make([]int, 5) fmt.Println(s1) fmt.Println(s2) fmt.Println(s3) //map 同slice;var 不能直接赋值;:=的可以直接赋值 var m1 map[int]int m2 := map[int]int{} m2[1]=3 m3 := make(map[int]int, 5) m3[1]=2 fmt.Println(m1) fmt.Println(m2) fmt.Println(m3) } ","date":"2019-03-21","objectID":"/go%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/:3:0","tags":["golang"],"title":"go语言基本用法","uri":"/go%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/"},{"categories":["2019春节大礼包"],"content":"map package main import \"fmt\" func main() { //map 同slice;var 不能直接赋值;:=的可以直接赋值 var m1 map[int]int m2 := map[int]int{} m2[1]=3 m3 := make(map[int]int, 5) m3[1]=2 fmt.Println(m1) fmt.Println(m2) fmt.Println(m3) //判断map中某个元素是否存在 if _, ok := map[key]; ok { //存在 } } ","date":"2019-03-21","objectID":"/go%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/:4:0","tags":["golang"],"title":"go语言基本用法","uri":"/go%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/"},{"categories":["2019春节大礼包"],"content":"queue package main import \"fmt\" //实现一个队列 type queue struct { val []int } func (this *queue) push(val int) { this.val = append(this.val, val) } func (this *queue) pop() int { result := this.val[0] this.val = this.val[1:] return result } func (this *queue) peek() int { return this.val[0] } func (this *queue) size() int { return len(this.val) } func (this *queue) empty() bool { if (0 == len(this.val)) { return true } return false } //实现队列结束 func main() { queue := queue{[]int{}} //{}是初始化一个结构体,[]int{}是传入的值 queue.push(1) queue.push(2) queue.push(3) fmt.Println(queue.pop()) fmt.Println(queue.pop()) fmt.Println(queue.pop()) } ","date":"2019-03-21","objectID":"/go%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/:5:0","tags":["golang"],"title":"go语言基本用法","uri":"/go%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/"},{"categories":["2019春节大礼包"],"content":"slice package main import \"fmt\" func main() { //relation of slice and array //slice is a reference of array //array := [5]int{1,2,3,4,5} //slice := array[:] //fmt.Println(array) //fmt.Println(slice) //declare way1 var slice1 []int //len = 0 and cap = 0 fmt.Println(slice1) //declare way2 slice2 := []int {1,2,3,4,5} //len = 5 and cap = 5 fmt.Println(slice2) //declare and create : make ; make will create slice and slice's relation array slice3 := make([]int, 10) //len = 10 and cap = 10 slice4 := make([]int, 10, 20) //len = 10 and cap = 20 fmt.Println(slice3) fmt.Println(slice4) //declare and create : new ; slice5 := new([100]int)[0:30] //\"new\" allocate memory of array and assignment array's slices to slice5 fmt.Println(slice5) //deferent between new and make : \"new\" allocate memory for type T and return the address of *T ; \"make\" create a object of type T and return it //slice use fmt.Println(slice2[0:3]) fmt.Println(slice2[3:]) fmt.Println(slice2[:3]) } ","date":"2019-03-21","objectID":"/go%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/:6:0","tags":["golang"],"title":"go语言基本用法","uri":"/go%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/"},{"categories":["2019春节大礼包"],"content":"stack package main import \"fmt\" //实现一个栈 type stack struct { val []interface{} } func (this *stack) push(val interface{}) { this.val = append([]interface{}{val}, this.val...) } func (this *stack) pop() interface{} { result := this.val[0] this.val = this.val[1:] return result } func (this *stack) peek() interface{} { return this.val[0] } func (this *stack) size() interface{} { return len(this.val) } func (this *stack) empty() bool { if (0 == len(this.val)) { return true } return false } //实现栈结束 func main() { var stack stack stack.push(1) stack.push(2) stack.push(3) fmt.Println(stack.pop()) fmt.Println(stack.pop()) fmt.Println(stack.pop()) } ","date":"2019-03-21","objectID":"/go%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/:7:0","tags":["golang"],"title":"go语言基本用法","uri":"/go%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/"},{"categories":["2019春节大礼包"],"content":"string package main import \"fmt\" import \"strings\" import \"strconv\" func main() { // string 是[]byte的别名 // byte是uint8的别名,用来表示ascii;一个英文字符对应一个byte,一个中文字符对应三个byte // rune是int32的别名,用来表示utf-8[一个中文占三个字节]/unicode[一个中文占两个字节];一个rune对应一个UTF-8字符 str := \"中文test string\" fmt.Println(\"str[0]:\", str[0]) // = string转[]byte,其实不转也是 strByte := []byte(str) fmt.Println(\"strByte[0]:\", strByte[0]) // = string转[]rune strRune := []rune(str) fmt.Println(\"strRune[0]:\", strRune[0]) // = string求长度 fmt.Println(\"strings.Count()-1:\", strings.Count(str, \"\")-1) // = string切割 fmt.Println(\"strings.Split\", strings.Split(str, \"\")) // = string截取 fmt.Println(\"str[:]\", str[6:]) // = string转int if strToNumber, err := strconv.Atoi(\"1\"); err == nil { fmt.Println(\"strconv.Atoi()\", strToNumber) } // = int转string fmt.Println(\"strconv.Itoa()\", strconv.Itoa(1)) } ","date":"2019-03-21","objectID":"/go%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/:8:0","tags":["golang"],"title":"go语言基本用法","uri":"/go%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/"},{"categories":["2019春节大礼包"],"content":"struct package main import \"fmt\" type man struct { name string age int weight int score []int } func main() { //创建结构体的方法1 var qiao man //qiao的类型是man qiao.name = \"qiao\" qiao.age = 25 qiao.weight = 140 qiao.score = append(qiao.score, 1) qiao.score = append(qiao.score, 2) fmt.Println(qiao) //创建结构体的方法2 yang := new(man) //yang的类型是指向man类型实例的指针 yang.name = \"yang\" fmt.Println(yang) //创建结构体的方法3 liu := man{} fmt.Println(liu) zhang := man{\"zhang\", 25, 140, []int{1,2,3,4,5}} fmt.Println(zhang) //创建结构体的方法4 li := \u0026man{} fmt.Println(liu) zhang := man{\"zhang\", 25, 140, []int{1,2,3,4,5}} fmt.Println(zhang) //创建结构体的方法4 li := \u0026man{} fmt.Println(li) } ","date":"2019-03-21","objectID":"/go%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/:9:0","tags":["golang"],"title":"go语言基本用法","uri":"/go%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/"},{"categories":["2019春节大礼包"],"content":"传值还是传指针 package main import \"fmt\" func main() { // int/float/bool/string/array 值类型 // slice/map 指针类型 i := 1; f := 1.1; b := true; s := \"a\" testBaseType(i, f, b , s) fmt.Println(i, f, b , s) arr := [...]int{1,1,1}; sli := []int{1,1,1}; m := map[int]int{1:1,2:2}; testSeniorType(arr, sli, m) fmt.Println(arr, sli, m) } func testBaseType(i int, f float64, b bool, s string) { i = 2 f = 2.2 b = false s = \"b\" } func testSeniorType(arr [3]int, sli []int, m map[int]int) { arr[0] = 2 sliCopy := make([]int, len(sli)) copy(sliCopy, sli) sliCopy[0] = 2 m[1] = 2 } ","date":"2019-03-21","objectID":"/go%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/:10:0","tags":["golang"],"title":"go语言基本用法","uri":"/go%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/"},{"categories":["乱七八糟"],"content":" git 忽略权限改变 git config core.filemode false 在vim编辑模式下快速输入===会杀掉连接 shell脚本的执行者可能没有初始化任何东西，包括PATH js数组赋值是传引用https://www.cnblogs.com/yuyifan/p/6204365.html js 强转为数字 Number(str) php 文件分隔符常量 DIRECTORY_SEPARATOR iview 动态验证，数字类型的必须增加type:number，否则会报错；因为它默认是string 使用响应式的col时，如果当前列有可能为空，增加一个空格占位符，避免col失效 英文或者数字的换行需要使用word-wrap:break-word; mysql in和join的区别 git修改权限 http://www.voidcn.com/article/p-zmzadkzt-bte.html php常量不能使用 . 做字符串拼接 crontab需要注意的问题（主要是环境变量和邮件）：https://blog.51cto.com/jiemian/1852092 yii2 indexBy可以指定返回值的key yii2 updateAll不会调用更新后置事件 explode不支持正则；split支持，但是5.3版本以后不建议使用split，要用preg_split yii2 httpclient 用法：https://blog.csdn.net/u012979009/article/details/52290584 ","date":"2019-03-21","objectID":"/%E4%B8%80%E6%9D%A1%E4%B8%80%E6%9D%A1/:0:0","tags":null,"title":"备忘","uri":"/%E4%B8%80%E6%9D%A1%E4%B8%80%E6%9D%A1/"},{"categories":["前端"],"content":"东西们 名称 分工 备注 nodejs js服务端运行环境 目前是v10 nvm node.js版本管理器 npm js包管理器 package.json/package-lock.json/node_modules npm脚本 用来定义一些快捷命令，在package.json中定义，如npm run .. webpack 静态模块打包器 把所有的js、图片、css等内容打包发布，供浏览器请求；但是webpack只解析import和export，所以需要babel等插件 babel js语法转换器 把js的最新语法转换为浏览器支持的语法 协议们 协议 导出 导入 应用场景 备注 CommonJS module.exports require nodejs(服务端) 运行时加载/传递值拷贝 AMD module.exports rquire 浏览器 运行时加载/传递值拷贝 ES6 export import 服务端/浏览器 传递值引用 webpack webpack 配置是标准的 Node.js CommonJS 模块 ","date":"2019-03-21","objectID":"/%E5%89%8D%E7%AB%AF%E6%8A%80%E6%9C%AF%E6%A0%88%E6%89%AB%E7%9B%B2/:0:0","tags":["前端"],"title":"前端技术栈扫盲","uri":"/%E5%89%8D%E7%AB%AF%E6%8A%80%E6%9C%AF%E6%A0%88%E6%89%AB%E7%9B%B2/"},{"categories":["前端"],"content":"入口 entry entry: './path/to/my/entry/file.js' ","date":"2019-03-21","objectID":"/%E5%89%8D%E7%AB%AF%E6%8A%80%E6%9C%AF%E6%A0%88%E6%89%AB%E7%9B%B2/:1:0","tags":["前端"],"title":"前端技术栈扫盲","uri":"/%E5%89%8D%E7%AB%AF%E6%8A%80%E6%9C%AF%E6%A0%88%E6%89%AB%E7%9B%B2/"},{"categories":["前端"],"content":"输出 output output: { path: path.resolve(__dirname, 'dist'), filename: 'my-first-webpack.bundle.js' } ","date":"2019-03-21","objectID":"/%E5%89%8D%E7%AB%AF%E6%8A%80%E6%9C%AF%E6%A0%88%E6%89%AB%E7%9B%B2/:2:0","tags":["前端"],"title":"前端技术栈扫盲","uri":"/%E5%89%8D%E7%AB%AF%E6%8A%80%E6%9C%AF%E6%A0%88%E6%89%AB%E7%9B%B2/"},{"categories":["前端"],"content":"loader webpack只处理js文件，所以其他类型文件需要对应的loader处理； 关键因素有：test(正则匹配对应的实验类型) use(使用哪个loader) module: { rules: [ { test: /\\.txt$/, use: 'raw-loader' } ] } ","date":"2019-03-21","objectID":"/%E5%89%8D%E7%AB%AF%E6%8A%80%E6%9C%AF%E6%A0%88%E6%89%AB%E7%9B%B2/:3:0","tags":["前端"],"title":"前端技术栈扫盲","uri":"/%E5%89%8D%E7%AB%AF%E6%8A%80%E6%9C%AF%E6%A0%88%E6%89%AB%E7%9B%B2/"},{"categories":["前端"],"content":"插件(plugins) 更大范围的特殊处理 需要require const HtmlWebpackPlugin = require('html-webpack-plugin'); // 通过 npm 安装 plugins: [ new HtmlWebpackPlugin({template: './src/index.html'}) ] ","date":"2019-03-21","objectID":"/%E5%89%8D%E7%AB%AF%E6%8A%80%E6%9C%AF%E6%A0%88%E6%89%AB%E7%9B%B2/:4:0","tags":["前端"],"title":"前端技术栈扫盲","uri":"/%E5%89%8D%E7%AB%AF%E6%8A%80%E6%9C%AF%E6%A0%88%E6%89%AB%E7%9B%B2/"},{"categories":["前端"],"content":"模式 mode: 'production' npm ","date":"2019-03-21","objectID":"/%E5%89%8D%E7%AB%AF%E6%8A%80%E6%9C%AF%E6%A0%88%E6%89%AB%E7%9B%B2/:5:0","tags":["前端"],"title":"前端技术栈扫盲","uri":"/%E5%89%8D%E7%AB%AF%E6%8A%80%E6%9C%AF%E6%A0%88%E6%89%AB%E7%9B%B2/"},{"categories":["前端"],"content":"常用命令 npm install moduleName@version npm uninstall moduleName npm search moduleName npm list # 查看当前项目已安装的模块 npm update moduleName ","date":"2019-03-21","objectID":"/%E5%89%8D%E7%AB%AF%E6%8A%80%E6%9C%AF%E6%A0%88%E6%89%AB%E7%9B%B2/:6:0","tags":["前端"],"title":"前端技术栈扫盲","uri":"/%E5%89%8D%E7%AB%AF%E6%8A%80%E6%9C%AF%E6%A0%88%E6%89%AB%E7%9B%B2/"},{"categories":["前端"],"content":"常用参数 -S, –save -D, –save-dev -g ","date":"2019-03-21","objectID":"/%E5%89%8D%E7%AB%AF%E6%8A%80%E6%9C%AF%E6%A0%88%E6%89%AB%E7%9B%B2/:7:0","tags":["前端"],"title":"前端技术栈扫盲","uri":"/%E5%89%8D%E7%AB%AF%E6%8A%80%E6%9C%AF%E6%A0%88%E6%89%AB%E7%9B%B2/"},{"categories":["前端"],"content":"配置项 dependencies devDependencies ","date":"2019-03-21","objectID":"/%E5%89%8D%E7%AB%AF%E6%8A%80%E6%9C%AF%E6%A0%88%E6%89%AB%E7%9B%B2/:8:0","tags":["前端"],"title":"前端技术栈扫盲","uri":"/%E5%89%8D%E7%AB%AF%E6%8A%80%E6%9C%AF%E6%A0%88%E6%89%AB%E7%9B%B2/"},{"categories":["2019春节大礼包"],"content":" package main import \"fmt\" func main() { fmt.Println(minimumTotal([][]int{ {2}, {3,4}, {6,5,7}, {4,1,8,3}, })) } func minimumTotal(triangle [][]int) int { max := len(triangle) - 1 result := triangle for i:=max; i\u003e=0; i-- { for j:=0; j\u003c=max; j++ { //init bottom if (i == len(triangle) - 1) { result[i][j] = triangle[i][j] } else { if result[i+1][j] \u003c result[i+1][j+1] { result[i][j] = result[i+1][j] + triangle[i][j] } else { result[i][j] = result[i+1][j+1] + triangle[i][j] } } } max = max - 1 } return result[0][0] } ","date":"2019-02-07","objectID":"/leetcode-triangle/:0:0","tags":["leetcode","算法"],"title":"LeetCode : triangle","uri":"/leetcode-triangle/"},{"categories":["2019春节大礼包"],"content":" package main import \"fmt\" var memory []int func main() { memory = make([]int, 4) fmt.Println(fibonacci3(3)) } //递归计算(会有很多重复计算) func fibonacci1(n int) int { if (n \u003c= 1) { return n } else { return fibonacci1(n-1) + fibonacci1(n-2) } } //带记忆的递归计算 func fibonacci2(n int) int { if (n \u003c= 1) { return n } else { if memory[n] == 0 { memory[n] = fibonacci2(n-1) + fibonacci2(n-2) } } return memory[n] } //自底向上的递推形式 f[n] = f[n-1] + f[n-2] func fibonacci3(n int) int { memory := make([]int, n+1) if (n \u003c= 1) { return n } memory[0] = 0 memory[1] = 1 for i:=2; i\u003c=n; i++ { memory[i] = memory[i-1] + memory[i-2] } return memory[n] } ","date":"2019-02-07","objectID":"/leetcode-fibonacci-number/:0:0","tags":["leetcode","算法"],"title":"LeetCode : fibonacci-number","uri":"/leetcode-fibonacci-number/"},{"categories":["2019春节大礼包"],"content":" package main import \"fmt\" func main() { fmt.Println(climbStairs(3)) } func climbStairs(n int) int { memory := make([]int, n+1) memory[0] = 1 memory[1] = 1 for i:=2; i\u003c=n; i++ { memory[i] = memory[i-1] + memory[i-2] //这里可以优化,memory不需要n的空间，只需要三个位置即可 } return memory[n] } ","date":"2019-02-07","objectID":"/leetcode-climbing-stairs/:0:0","tags":["leetcode","算法"],"title":"LeetCode : climbing-stairs","uri":"/leetcode-climbing-stairs/"},{"categories":["2019春节大礼包"],"content":" package main import \"fmt\" func main() { fmt.Println(countBits(10)) } func countBits(num int) []int { result := make([]int, num+1) for i:=1; i\u003c=num; i++ { result[i] = result[i\u0026(i-1)] + 1 } return result } ","date":"2019-02-07","objectID":"/leetcode-counting-bits/:0:0","tags":["leetcode","算法"],"title":"LeetCode : counting-bits","uri":"/leetcode-counting-bits/"},{"categories":["2019春节大礼包"],"content":" package main import \"fmt\" func main() { fmt.Println(isPowerOfTwo(10)) } func isPowerOfTwo(n int) bool { return n!= 0 \u0026\u0026 n \u0026 (n-1) == 0 } ","date":"2019-02-07","objectID":"/leetcode-power-of-two/:0:0","tags":["leetcode","算法"],"title":"LeetCode : power-of-two","uri":"/leetcode-power-of-two/"},{"categories":["2019春节大礼包"],"content":" package main import \"fmt\" func main() { fmt.Println(hammingWeight(10)) } func hammingWeight(num uint32) int { if (num == 0) { return 0 } count := 0 for num \u0026 (num-1) != 0 { count++ num = num \u0026 (num - 1) } count++ return count } ","date":"2019-02-07","objectID":"/leetcode-number-of-1-bits/:0:0","tags":["leetcode","算法"],"title":"LeetCode : number-of-1-bits","uri":"/leetcode-number-of-1-bits/"},{"categories":["2019春节大礼包"],"content":" package main import \"fmt\" var result []string func main() { /* board := [][]byte{ {'o','a','a','n'}, {'e','t','a','e'}, {'i','h','k','r'}, {'i','f','l','v'}, } */ board := [][]byte{ {'a', 'b'}, } words := []string{ \"ba\", } rs := findWords(board, words) fmt.Println(rs) } func findWords(board [][]byte, words []string) []string { result = []string{} for _,word := range words { dfs(board, word, 0, 0, 0) } //dictinct tempMap := map[string]int{} for _, item := range result { tempMap[item] = 0 } realResult := []string{} for index, _ := range tempMap { realResult = append(realResult, index) } return realResult } func dfs(board [][]byte, word string, pos, x, y int) bool { fmt.Println(\"find:\", string(word[pos]), \",x:\", x, \",y:\", y) //check if x or y out of range maxX := len(board) - 1 maxY := len(board[0]) - 1 if x \u003e maxX || y \u003e maxY { return false } //find strat point if (board[x][y] == word[pos]) { if pos == len(word) - 1 { // success result = append(result, word) return true } // go on recurision if (x \u003e 0) { if dfs(board, word, pos+1, x-1, y) { return true } } if (y \u003e 0) { if dfs(board, word, pos+1, x, y-1) { return true } } if x \u003c maxX { if dfs(board, word, pos+1, x+1, y) { return true } } if y \u003c maxY { if dfs(board, word, pos+1, x, y+1) { return true } } } else { // go on recurision if (x \u003e 0) { if dfs(board, word, pos, x-1, y) { return true } } if (y \u003e 0) { if dfs(board, word, pos, x, y-1) { return true } } if x \u003c maxX { if dfs(board, word, pos, x+1, y) { return true } } if y \u003c maxY { if dfs(board, word, pos, x, y+1) { return true } } } return false } ","date":"2019-02-06","objectID":"/leetcode-word-search-ii-1/:0:0","tags":["leetcode","算法"],"title":"LeetCode : word-search-ii-1","uri":"/leetcode-word-search-ii-1/"},{"categories":["2019春节大礼包"],"content":" package main import \"fmt\" func main() { fmt.Println(generateParenthesis(2)) } var list []string func generateParenthesis(n int) []string { list = []string{} gen(0, 0, n, \"\") return list } func gen(left, right,n int, result string) { if (left == n) \u0026\u0026 (right == n) { list = append(list, result) return } if left \u003c n { gen(left+1, right, n, result + \"(\") } if left \u003e right \u0026\u0026 right \u003c n { gen(left, right+1, n, result + \")\") } } ","date":"2019-02-06","objectID":"/leetcode-generate-parentheses/:0:0","tags":["leetcode","算法"],"title":"LeetCode : generate-parentheses","uri":"/leetcode-generate-parentheses/"},{"categories":["2019春节大礼包"],"content":" package main import \"fmt\" type TrieNode struct { children map[rune]*TrieNode isEnd bool } type Trie struct { root TrieNode } /** Initialize your data structure here. */ func Constructor() Trie { trie := Trie{TrieNode{make(map[rune]*TrieNode), false}} return trie } func main() { obj := Constructor(); obj.Insert(\"abc\"); rs := obj.Search(\"abc\") fmt.Println(rs) } /** Inserts a word into the trie. */ func (this *Trie) Insert(word string) { node := \u0026this.root var index int var char rune for index, char = range word { if _, ok := node.children[char]; (!ok) { node.children[char] = \u0026TrieNode{make(map[rune]*TrieNode), false} } if (index \u003c len(word) - 1) { node = node.children[char] } } node.isEnd = true } func (this *Trie) Search(word string) bool { node := \u0026this.root for index, char := range word { if _, ok := node.children[char]; (!ok) { return false } else { if (index \u003c len(word) - 1) { node = node.children[char] } } } return node.isEnd } func (this *Trie) StartsWith(prefix string) bool { node := \u0026this.root for _, char := range prefix { if _, ok := node.children[char]; (!ok) { return false } else { node = node.children[char] } } return true } ","date":"2019-02-06","objectID":"/leetcode-implement-trie-prefix-tree/:0:0","tags":["leetcode","算法"],"title":"LeetCode : implement-trie-prefix-tree","uri":"/leetcode-implement-trie-prefix-tree/"},{"categories":["2019春节大礼包"],"content":" package main import \"fmt\" func main() { fmt.Println(mySqrt(1)) } func mySqrt(x int) int { if (x == 1) { return 1 } return mySqrtHelp(0, x, x) } func mySqrtHelp(left,right,x int) int { if (right - left) \u003c= 1 { return left } mid := (left + right) / 2 if mid * mid == x { return mid } else if (mid * mid \u003e x) { return mySqrtHelp(left, mid, x) } else { return mySqrtHelp(mid, right, x) } } ","date":"2019-02-06","objectID":"/leetcode-sqrtx/:0:0","tags":["leetcode","算法"],"title":"LeetCode : sqrtx","uri":"/leetcode-sqrtx/"},{"categories":["2019春节大礼包"],"content":" package main import \"fmt\" var data []int var target int func main() { data = []int{0,1,2,3,4,5,6,7,8,9} target = 6 fmt.Println(binarySearch()) } func binarySearch() int { return binarySearchHelp(0, len(data)-1); } func binarySearchHelp(left int, right int) int { mid := (left + right) / 2 if (left \u003c 0) || (right \u003c 0) || (mid \u003c 0) { return -1 } if (data[mid] == target) { return mid } else if (data[mid] \u003c target) { return binarySearchHelp(mid+1, right) } else { return binarySearchHelp(left, mid-1) } } ","date":"2019-02-06","objectID":"/leetcode-binary-search/:0:0","tags":["leetcode","算法"],"title":"LeetCode : binary-search","uri":"/leetcode-binary-search/"},{"categories":["2019春节大礼包"],"content":" package main import \"fmt\" func main() { fmt.Println(solveNQueens(2)) } var result [][]int var cols, pie, na map[int]int func solveNQueens(n int) [][]string { cols = make(map[int]int) pie = make(map[int]int) na = make(map[int]int) dfs(n, 0, []int{}) stringReuslt := [][]string{} for _,cols := range result { //index stringReusltSub := []string{} for _,col := range cols { //row line := \"\" for i := 0; i \u003c n; i++ { if (i == col) { line += \"Q\" } else { line += \".\" } } stringReusltSub = append(stringReusltSub, line) } stringReuslt = append(stringReuslt, stringReusltSub) } return stringReuslt } func dfs(n int, row int, current []int) { //递归终止条件 if row \u003e= n { result = append(result, current) return } for col := 0; col \u003c n; col++ { //当前位置不能放置皇后 if cols[col] != 0 || pie[row+col] != 0 || na[row-col] != 0 { continue } //占领这个位置,加标志位 cols[col] = 1 pie[row+col] = 1 na[row-col] = 1 //占领了一个,向下探一行 dfs(n, row+1, append(current, col)) //回到这一层,删除标志 cols[col] = 0 pie[row+col] = 0 na[row-col] = 0 } } ","date":"2019-02-05","objectID":"/leetcode-n-queens/:0:0","tags":["leetcode","算法"],"title":"LeetCode : n-queens","uri":"/leetcode-n-queens/"},{"categories":["2019春节大礼包"],"content":" package main import \"fmt\" type TreeNode struct { Val int Left *TreeNode Right *TreeNode } func main() { /* 3 / \\ 9 20 / \\ 15 7 */ node15 := \u0026TreeNode{15, nil, nil} node7 := \u0026TreeNode{7, nil, nil} node9 := \u0026TreeNode{9, nil, nil} node20 := \u0026TreeNode{20, node15, node7} root := \u0026TreeNode{3, node9, node20} fmt.Println(minDepth(root)) } func minDepth(root *TreeNode) int { if root == nil { return 0 } return dfs(root, 0) } func dfs(root *TreeNode, level int) int { level++ leftLevel := 0 rightLevel := 0 if root.Left != nil { leftLevel = dfs(root.Left, level) } if root.Right != nil { rightLevel = dfs(root.Right, level) } if (leftLevel == 0) \u0026\u0026 (rightLevel == 0) { return level } else if (leftLevel != 0) \u0026\u0026 (rightLevel == 0) { //叶子节点 return leftLevel } else if (leftLevel == 0) \u0026\u0026 (rightLevel != 0) { return rightLevel } else if (leftLevel \u003c rightLevel) { return leftLevel } else { return rightLevel } } ","date":"2019-02-05","objectID":"/leetcode-minimum-depth-of-binary-tree/:0:0","tags":["leetcode","算法"],"title":"LeetCode : minimum-depth-of-binary-tree","uri":"/leetcode-minimum-depth-of-binary-tree/"},{"categories":["2019春节大礼包"],"content":" package main import \"fmt\" type TreeNode struct { Val int Left *TreeNode Right *TreeNode } func main() { /* 3 / \\ 9 20 / \\ 15 7 */ node15 := \u0026TreeNode{15, nil, nil} node7 := \u0026TreeNode{7, nil, nil} node9 := \u0026TreeNode{9, nil, nil} node20 := \u0026TreeNode{20, node15, node7} root := \u0026TreeNode{3, node9, node20} fmt.Println(maxDepth(root)) } func maxDepth(root *TreeNode) int { if root == nil { return 0 } return dfs(root, 0) } func dfs(root *TreeNode, level int) int { level++ leftLevel := 0 rightLevel := 0 if root.Left != nil { leftLevel = dfs(root.Left, level) } if root.Right != nil { rightLevel = dfs(root.Right, level) } if (leftLevel == 0) \u0026\u0026 (rightLevel == 0) { return level } else if (leftLevel \u003e rightLevel) { return leftLevel } else { return rightLevel } } ","date":"2019-02-05","objectID":"/leetcode-maximum-depth-of-binary-tree/:0:0","tags":["leetcode","算法"],"title":"LeetCode : maximum-depth-of-binary-tree","uri":"/leetcode-maximum-depth-of-binary-tree/"},{"categories":["2019春节大礼包"],"content":" package main import \"fmt\" type TreeNode struct { Val int Left *TreeNode Right *TreeNode } func main() { /* 3 / \\ 9 20 / \\ 15 7 */ node15 := \u0026TreeNode{15, nil, nil} node7 := \u0026TreeNode{7, nil, nil} node9 := \u0026TreeNode{9, nil, nil} node20 := \u0026TreeNode{20, node15, node7} root := \u0026TreeNode{3, node9, node20} fmt.Println(bfs(root)) } func bfs(root *TreeNode) []int{ result := []int{} queue := []*TreeNode{} queue = append(queue, root) for len(queue) != 0 { var item *TreeNode for index,value := range queue{ item = value queue = queue[index+1:len(queue)] break } result = append(result, item.Val) if (item.Left != nil) { queue = append(queue, item.Left) } if (item.Right != nil) { queue = append(queue, item.Right) } } return result } ","date":"2019-02-05","objectID":"/leetcode-bfs/:0:0","tags":["leetcode","算法"],"title":"LeetCode : bfs","uri":"/leetcode-bfs/"},{"categories":["2019春节大礼包"],"content":" package main import \"fmt\" type TreeNode struct { Val int Left *TreeNode Right *TreeNode } func main() { /* 3 / \\ 9 20 / \\ 15 7 */ node15 := \u0026TreeNode{15, nil, nil} node7 := \u0026TreeNode{7, nil, nil} node9 := \u0026TreeNode{9, nil, nil} node20 := \u0026TreeNode{20, node15, node7} root := \u0026TreeNode{3, node9, node20} dfs(root) } func dfs(root *TreeNode) { fmt.Println(root.Val) if root.Left != nil { dfs(root.Left) } if root.Right != nil { dfs(root.Right) } } ","date":"2019-02-05","objectID":"/leetcode-dfs/:0:0","tags":["leetcode","算法"],"title":"LeetCode : dfs","uri":"/leetcode-dfs/"},{"categories":["2019春节大礼包"],"content":" package main import \"fmt\" type TreeNode struct { Val int Left *TreeNode Right *TreeNode } func main() { node15 := \u0026TreeNode{15, nil, nil} node7 := \u0026TreeNode{7, nil, nil} node9 := \u0026TreeNode{9, nil, nil} node20 := \u0026TreeNode{20, node15, node7} root := \u0026TreeNode{3, node9, node20} fmt.Println(levelOrder(root)) } func levelOrder(root *TreeNode) [][]int { if (root == nil) { return [][]int{} } result := [][]int{} queue := []*TreeNode{} queue = append(queue, root) for len(queue) != 0 { levelSize := len(queue) levelElements := []int{} for i:=0; i \u003c levelSize; i++ { //每次都把当前队列取空,就是这一级的elements var item *TreeNode for index,value := range queue{ item = value queue = queue[index+1:len(queue)] break } levelElements = append(levelElements, item.Val) if (item.Left != nil) { queue = append(queue, item.Left) } if (item.Right != nil) { queue = append(queue, item.Right) } } result = append(result, levelElements) } return result } ","date":"2019-02-05","objectID":"/leetcode-binary-tree-level-order-traversal/:0:0","tags":["leetcode","算法"],"title":"LeetCode : binary-tree-level-order-traversal","uri":"/leetcode-binary-tree-level-order-traversal/"},{"categories":["2019春节大礼包"],"content":" package main import \"fmt\" func main(){ fmt.Println(maxProfit([]int{7,1,5,3,6,4})) } func maxProfit(prices []int) int { profit := 0 for index,price := range prices { if index \u003e 0 \u0026\u0026 price \u003e prices[index-1] { profit = profit + price - prices[index-1] } } return profit } ","date":"2019-02-05","objectID":"/leetcode-best-time-to-buy-and-sell-stock-ii/:0:0","tags":["leetcode","算法"],"title":"LeetCode : best-time-to-buy-and-sell-stock-ii","uri":"/leetcode-best-time-to-buy-and-sell-stock-ii/"},{"categories":["2019春节大礼包"],"content":" package main import \"fmt\" func main() { fmt.Println(majorityElement([]int{1,2,3,1,1,1,1,1,1})) } func majorityElement(nums []int) int { m := make(map[int]int) for _,num := range nums { m[num]++ } for num,count := range m { if (count \u003e len(nums)/2) { return num } } return 0 } ","date":"2019-02-05","objectID":"/leetcode-majority-element/:0:0","tags":["leetcode","算法"],"title":"LeetCode : majority-element","uri":"/leetcode-majority-element/"},{"categories":["2019春节大礼包"],"content":" package main import \"fmt\" func main() { fmt.Println(myPow(10, 5)) } func myPow(x float64, n int) float64 { if n == 0 { return 1 } if n \u003c 0 { return 1 / myPow(x, -n) } if n % 2 == 0 { return myPow(x*x, n/2) } else { return x * myPow(x*x, (n-1)/2) } } ","date":"2019-02-04","objectID":"/leetcode-powx-n/:0:0","tags":["leetcode","算法"],"title":"LeetCode : powx-n","uri":"/leetcode-powx-n/"},{"categories":["2019春节大礼包"],"content":" package main type TreeNode struct { Val int Left *ListNode Right *ListNode } func lowestCommonAncestor(root, p, q *TreeNode) *TreeNode { if root == nil || root.Val == p.Val || root.Val == q.Val { return root } left := lowestCommonAncestor(root.Left, p,q *TreeNode) right := lowestCommonAncestor(root.Right, p,q *TreeNode) if (left != nil) \u0026\u0026 (right == nil) { return left } if (left == nil) \u0026\u0026 (right != nil) { return left } return root } ","date":"2019-02-04","objectID":"/leetcode-lowest-common-ancestor-of-a-binary-tree/:0:0","tags":["leetcode","算法"],"title":"LeetCode : lowest-common-ancestor-of-a-binary-tree","uri":"/leetcode-lowest-common-ancestor-of-a-binary-tree/"},{"categories":["2019春节大礼包"],"content":" package main type TreeNode struct { Val int Left *TreeNode Right *TreeNode } func isValidBST(root *TreeNode) bool { if root == nil { return true } return helper(root, nil, nil) } func helper(root *TreeNode, low *int, high *int) bool { if ((low != nil \u0026\u0026 root.Val \u003c= *low) || (high != nil \u0026\u0026 root.Val \u003e= *high)) { return false } if root.Left != nil { if !helper(root.Left, low, \u0026root.Val) { return false } } if root.Right != nil { if !helper(root.Right, \u0026root.Val, high) { return false } } return true } ","date":"2019-02-04","objectID":"/leetcode-validate-binary-search-tree/:0:0","tags":["leetcode","算法"],"title":"LeetCode : validate-binary-search-tree","uri":"/leetcode-validate-binary-search-tree/"},{"categories":["2019春节大礼包"],"content":" package main import \"fmt\" import \"sort\" import \"strconv\" func main() { fmt.Println(threeSum([]int{-4,-2,-2,-2,0,1,2,2,2,3,3,4,4,6,6})) } func threeSum(nums []int) [][]int { result := [][]int{} set := make(map[int]int) used := make(map[string]int) for index,num := range nums { set[num] = index } for indexA,numA := range nums { for indexB,numB := range nums { numC := 0 - numA - numB indexC,ok := set[numC] if (indexA != indexB) \u0026\u0026 (indexA != indexC) \u0026\u0026 (indexB != indexC) \u0026\u0026 ok { resultItem := []int{numA, numB, numC} usedKey := \"\" sort.Ints(resultItem) for _,item := range resultItem { usedKey += strconv.Itoa(item) } _,ok := used[usedKey] if !ok { result = append(result, resultItem) used[usedKey] = 0 } } } } return result } ","date":"2019-02-03","objectID":"/leetcode-three-sum/:0:0","tags":["leetcode","算法"],"title":"LeetCode : three-sum","uri":"/leetcode-three-sum/"},{"categories":["2019春节大礼包"],"content":" package main import \"fmt\" func main() { fmt.Println(twoSum([]int{2,7,11,15}, 9)) } func twoSum(nums []int, target int) []int { set := make(map[int]int) for index,num := range nums { set[num] = index } for index,num := range nums { _, ok := set[target - num] if ok { if index != set[target - num] { return []int{index, set[target - num]} } } } return []int{} } ","date":"2019-02-03","objectID":"/leetcode-two-sum/:0:0","tags":["leetcode","算法"],"title":"LeetCode : two-sum","uri":"/leetcode-two-sum/"},{"categories":["2019春节大礼包"],"content":" package main import \"fmt\" import \"reflect\" func main() { fmt.Println(isAnagram(\"abc\", \"cbad\")) } func isAnagram(s string, t string) bool { ms := make(map[rune]int) mt := make(map[rune]int) for _,sitem := range s { ms[sitem]++ } for _,titem := range t { mt[titem]++ } eq := reflect.DeepEqual(ms, mt) if eq { return true } else { return false } } ","date":"2019-02-03","objectID":"/leetcode-valid-anagram/:0:0","tags":["leetcode","算法"],"title":"LeetCode : valid-anagram","uri":"/leetcode-valid-anagram/"},{"categories":["2019春节大礼包"],"content":" package main import \"fmt\" func main() { //fmt.Println(maxSlidingWindow([]int{1,3,-1,-3,5,3,6,7}, 3)) //fmt.Println(maxSlidingWindow([]int{1,-1}, 1)) fmt.Println(maxSlidingWindow([]int{9,10,9,-1,-4,-8,2,-6}, 5)) } func maxSlidingWindow(nums []int, k int) []int { if k == 0 || len(nums) == 0 { return []int{} } window := []int{} result := []int{} max := nums[0] maxIndex := 0 var windowIndex,windowNum int for index,num := range nums { if num \u003e= max { window = []int{num} max = num maxIndex = index } else { if len(window) \u003c k { window = append(window, num) } else { window = append(window[1:], num) if index - k \u003e= maxIndex { //select the new max max = num maxIndex = index for windowIndex,windowNum = range window { if windowNum \u003e max { max = windowNum maxIndex = index - (k - windowIndex) } } } } } if index \u003e= k-1 { result = append(result, max) } } return result } ","date":"2019-01-31","objectID":"/leetcode-sliding-window-maximum/:0:0","tags":["leetcode","算法"],"title":"LeetCode : sliding-window-maximum","uri":"/leetcode-sliding-window-maximum/"},{"categories":["2019春节大礼包"],"content":" package main import \"container/heap\" import \"fmt\" // heap type IntHeap []int func (h IntHeap) Len() int { return len(h) } func (h IntHeap) Less(i, j int) bool { return h[i] \u003c h[j] } func (h IntHeap) Swap(i, j int) { h[i], h[j] = h[j], h[i] } func (h *IntHeap) Pop() interface{} { old := *h n := len(old) x := old[n-1] *h = old[0 : n-1] return x } func (h *IntHeap) Push(x interface{}) { *h = append(*h, x.(int)) } type KthLargest struct { vals IntHeap size int } //heap end func Constructor(k int, nums []int) KthLargest { var right int if len(nums) \u003e k { right = k } else { right = len(nums) } vals := nums[0:right] obj := KthLargest{vals, k} //init vals as a heap heap.Init(\u0026obj.vals) //push other valus into obj for i := k; i \u003c len(nums); i++ { heap.Push(\u0026obj.vals, nums[i]) heap.Pop(\u0026obj.vals) } //return the obj return obj } func (this *KthLargest) Add(val int) int { heap.Push(\u0026this.vals, val) for this.vals.Len() \u003e this.size { heap.Pop(\u0026this.vals) } return this.vals[0] } /** * Your KthLargest object will be instantiated and called as such: * obj := Constructor(k, nums); * param_1 := obj.Add(val); */ func main() { obj := Constructor(3, []int{4,5,2,8}); fmt.Println(obj) fmt.Println(obj.Add(-6)) } ","date":"2019-01-31","objectID":"/leetcode-kth-largest-element-in-a-stream/:0:0","tags":["leetcode","算法"],"title":"LeetCode : kth-largest-element-in-a-stream","uri":"/leetcode-kth-largest-element-in-a-stream/"},{"categories":["2019春节大礼包"],"content":" package main import \"fmt\" //实现一个队列 type queue struct { val []int } func (this *queue) push(val int) { this.val = append(this.val, val) } func (this *queue) pop() int { result := this.val[0] this.val = this.val[1:] return result } func (this *queue) peek() int { return this.val[0] } func (this *queue) size() int { return len(this.val) } func (this *queue) empty() bool { if (0 == len(this.val)) { return true } return false } //实现队列结束 func main() { stack := Constructor() stack.Push(1) stack.Push(2) fmt.Println(stack.Top()) fmt.Println(stack.Top()) fmt.Println(stack.Top()) //fmt.Println(stack.Pop()) //fmt.Println(stack.Empty()) } type MyStack struct { queue1 queue queue2 queue } /** Initialize your data structure here. */ func Constructor() MyStack { var stack MyStack stack.queue1 = queue{[]int{}} stack.queue2 = queue{[]int{}} return stack } /** Push element x onto stack. */ func (this *MyStack) Push(x int) { //直接压入queue1 this.queue1.push(x) } /** Removes the element on top of the stack and returns that element. */ func (this *MyStack) Pop() int { //把queue1中除了最后一个压入queue2,pop出queue1中的最后一个 for (this.queue1.size() \u003e 1) { this.queue2.push(this.queue1.pop()) } result := this.queue1.pop() //把queue2中的元素放回queue1 for (!this.queue2.empty()) { this.queue1.push(this.queue2.pop()) } return result } /** Get the top element. */ func (this *MyStack) Top() int { //把queue1中除了最后一个压入queue2,pop出queue1中的最后一个 for (this.queue1.size() \u003e 1) { this.queue2.push(this.queue1.pop()) } result := this.queue1.peek() this.queue2.push(this.queue1.pop()) //把queue2中的元素放回queue1 for (!this.queue2.empty()) { this.queue1.push(this.queue2.pop()) } return result } /** Returns whether the stack is empty. */ func (this *MyStack) Empty() bool { return this.queue1.empty() } /** * Your MyStack object will be instantiated and called as such: * obj := Constructor(); * obj.Push(x); * param_2 := obj.Pop(); * param_3 := obj.Top(); * param_4 := obj.Empty(); */ ","date":"2019-01-29","objectID":"/leetcode-implement-stack-using-queues/:0:0","tags":["leetcode","算法"],"title":"LeetCode : implement-stack-using-queues","uri":"/leetcode-implement-stack-using-queues/"},{"categories":["2019春节大礼包"],"content":" package main import \"fmt\" //实现一个栈 type stack struct { val []int } func (this *stack) push(val int) { this.val = append([]int{val}, this.val...) } func (this *stack) pop() int { result := this.val[0] this.val = this.val[1:] return result } func (this *stack) peek() int { return this.val[0] } func (this *stack) size() int { return len(this.val) } func (this *stack) empty() bool { if (0 == len(this.val)) { return true } return false } //实现栈结束 func main() { queue := Constructor() queue.Push(1) queue.Push(2) queue.Push(3) fmt.Println(queue.Pop()) fmt.Println(queue.Pop()) fmt.Println(queue.Pop()) } type MyQueue struct { stack1 stack stack2 stack } /** Initialize your data structure here. */ func Constructor() MyQueue { var queue MyQueue queue.stack1 = stack{[]int{}} queue.stack2 = stack{[]int{}} return queue } /** Push element x to the back of queue. */ func (this *MyQueue) Push(x int) { this.stack1.push(x) } /** Removes the element from in front of queue and returns that element. */ func (this *MyQueue) Pop() int { if (!this.stack2.empty()) { //stack2不为空,直接取stack2中的元素 return this.stack2.pop() } else { if (!this.stack1.empty()) { //stack2为空,把stack1中所有元素pop到stack2中 for (!this.stack1.empty()) { this.stack2.push(this.stack1.pop()) } } //从stack2中pop元素 return this.stack2.pop() } } /** Get the front element. */ func (this *MyQueue) Peek() int { if (!this.stack2.empty()) { //stack2不为空,直接取stack2中的元素 return this.stack2.peek() } else { if (!this.stack1.empty()) { //stack2为空,把stack1中所有元素pop到stack2中 for (!this.stack1.empty()) { this.stack2.push(this.stack1.pop()) } } //从stack2中pop元素 return this.stack2.peek() } } /** Returns whether the queue is empty. */ func (this *MyQueue) Empty() bool { return this.stack1.empty() \u0026\u0026 this.stack2.empty() } /** * Your MyQueue object will be instantiated and called as such: * obj := Constructor(); * obj.Push(x); * param_2 := obj.Pop(); * param_3 := obj.Peek(); * param_4 := obj.Empty(); */ ","date":"2019-01-29","objectID":"/leetcode-implement-queue-using-stacks/:0:0","tags":["leetcode","算法"],"title":"LeetCode : implement-queue-using-stacks","uri":"/leetcode-implement-queue-using-stacks/"},{"categories":["2019春节大礼包"],"content":" package main import \"fmt\" import \"strings\" import \"container/list\" func main() { s := \"(\" result := isValid(s) fmt.Println(result) } func isValid(s string) bool { //切数组 items := strings.Split(s, \"\") //初始化栈 stack := list.New() for _, item := range items { //左括号,入栈 if (item == \"(\") || (item == \"[\") || (item == \"{\") { stack.PushBack(item) continue } //右括号,出栈 if stack.Len() == 0 { return false } if (item == \")\") { if stack.Back().Value == \"(\" { stack.Remove(stack.Back()) continue } else { return false } } if (item == \"]\") { if stack.Back().Value == \"[\" { stack.Remove(stack.Back()) continue } else { return false } } if (item == \"}\") { if stack.Back().Value == \"{\" { stack.Remove(stack.Back()) continue } else { return false } } return false } //如果已完全匹配,则栈内剩余数量为0 if (stack.Len() == 0) { return true } else { return false } } ","date":"2019-01-28","objectID":"/leetcode-valid-parentheses/:0:0","tags":["leetcode","算法"],"title":"LeetCode : valid-parentheses","uri":"/leetcode-valid-parentheses/"},{"categories":["2019春节大礼包"],"content":"reverse-nodes-in-k-group 题目链接：https://LeetCode.com/problems/reverse-nodes-in-k-group/ 代码 package main import \"fmt\" type ListNode struct { Val int Next *ListNode } func main() { node5 := ListNode {5, nil} node4 := ListNode {4, \u0026node5} node3 := ListNode {3, \u0026node4} node2 := ListNode {2, \u0026node3} node1 := ListNode {1, \u0026node2} head := ListNode {0, \u0026node1} result := reverseKGroup(\u0026head, 3) show(result) } func show(head *ListNode) { current := head for current != nil { fmt.Println(\"值:\", current.Val); current = current.Next } } /** * Definition for singly-linked list. * type ListNode struct { * Val int * Next *ListNode * } */ func reverseKGroup(head *ListNode, k int) *ListNode { if head == nil || head.Next == nil || k \u003c 2 { return head } // 以0-\u003e1-\u003e2-\u003e3-\u003e4-\u003e5的第一次循环为栗子 dummy := \u0026ListNode{-1, head} prev := dummy tail := dummy // 创建dummy // -1-\u003e0-\u003e1-\u003e2-\u003e3-\u003e4-\u003e5 // prev = -1 // tail = -1 // head = 0 for true { i := k // 把tail放到对应的位置 for i \u003e 0 \u0026\u0026 tail != nil { tail = tail.Next i-- } if (tail == nil) { break } // tail = 2 fmt.Println(\"tail值:\", tail.Val); // prev = -1 if prev != nil { fmt.Println(\"prev值:\", prev.Val); } // 这句是为下个循环打基础 本次循环完成后链表为 -1-\u003e2-\u003e1-\u003e0-\u003e3-\u003e4-\u003e5 下次的prev为0 tail为5 head为3(已不需要head，所以此处的head只是一个flag) head = prev.Next // head = 0 (本次循环完成后 0即为新一轮循环的prev) fmt.Println(\"--------\"); for prev.Next != tail { temp := prev.Next // temp = 1 当前链表为：-1-\u003e0-\u003e1-\u003e2-\u003e3-\u003e4-\u003e5 prev.Next = temp.Next //temp = 1 当前链表为：-1-\u003e1-\u003e2-\u003e3-\u003e4-\u003e5 temp.Next = tail.Next //temp = 1 当前链表为：-1-\u003e1-\u003e2-\u003e3-\u003e4-\u003e5 / 0-\u003e3 tail.Next = temp // temp = 1 当前链表为：-1-\u003e1-\u003e2-\u003e0-\u003e3-\u003e4-\u003e5 此时已完成0的位置转移 // 循环完成head到tail间所有元素的转移即可 if temp != nil { fmt.Println(\"temp值:\", temp.Val); } } fmt.Println(\"========\"); prev = head tail = head } return dummy.Next; } ","date":"2019-01-28","objectID":"/leetcode-reverse-nodes-in-k-group/:0:0","tags":["leetcode","算法"],"title":"Leetcode : reverse-nodes-in-k-group","uri":"/leetcode-reverse-nodes-in-k-group/"},{"categories":["2019春节大礼包"],"content":" package main import \"fmt\" type ListNode struct { Val int Next *ListNode } func main() { node5 := ListNode {5, nil} node4 := ListNode {4, \u0026node5} node3 := ListNode {3, \u0026node4} node2 := ListNode {2, \u0026node3} node1 := ListNode {1, \u0026node2} head := ListNode {0, \u0026node1} result := reverseKGroup(\u0026head, 3) show(result) } func show(head *ListNode) { current := head for current != nil { fmt.Println(\"值:\", current.Val); current = current.Next } } /** * Definition for singly-linked list. * type ListNode struct { * Val int * Next *ListNode * } */ func reverseKGroup(head *ListNode, k int) *ListNode { if head == nil || head.Next == nil || k \u003c 2 { return head } // 以0-\u003e1-\u003e2-\u003e3-\u003e4-\u003e5的第一次循环为栗子 dummy := \u0026ListNode{-1, head} prev := dummy tail := dummy // 创建dummy // -1-\u003e0-\u003e1-\u003e2-\u003e3-\u003e4-\u003e5 // prev = -1 // tail = -1 // head = 0 for true { i := k // 把tail放到对应的位置 for i \u003e 0 \u0026\u0026 tail != nil { tail = tail.Next i-- } if (tail == nil) { break } // tail = 2 fmt.Println(\"tail值:\", tail.Val); // prev = -1 if prev != nil { fmt.Println(\"prev值:\", prev.Val); } // 这句是为下个循环打基础 本次循环完成后链表为 -1-\u003e2-\u003e1-\u003e0-\u003e3-\u003e4-\u003e5 下次的prev为0 tail为5 head为3(已不需要head，所以此处的head只是一个flag) head = prev.Next // head = 0 (本次循环完成后 0即为新一轮循环的prev) fmt.Println(\"--------\"); for prev.Next != tail { temp := prev.Next // temp = 1 当前链表为：-1-\u003e0-\u003e1-\u003e2-\u003e3-\u003e4-\u003e5 prev.Next = temp.Next //temp = 1 当前链表为：-1-\u003e1-\u003e2-\u003e3-\u003e4-\u003e5 temp.Next = tail.Next //temp = 1 当前链表为：-1-\u003e1-\u003e2-\u003e3-\u003e4-\u003e5 / 0-\u003e3 tail.Next = temp // temp = 1 当前链表为：-1-\u003e1-\u003e2-\u003e0-\u003e3-\u003e4-\u003e5 此时已完成0的位置转移 // 循环完成head到tail间所有元素的转移即可 if temp != nil { fmt.Println(\"temp值:\", temp.Val); } } fmt.Println(\"========\"); prev = head tail = head } return dummy.Next; } ","date":"2019-01-18","objectID":"/leetcode-reverse-nodes-in-k-group-case-conflict/:0:0","tags":["leetcode","算法"],"title":"LeetCode : reverse-nodes-in-k-group","uri":"/leetcode-reverse-nodes-in-k-group-case-conflict/"},{"categories":["2019春节大礼包"],"content":" package main import \"fmt\" type ListNode struct { Val int Next *ListNode } func main() { node5 := ListNode {5, nil} node4 := ListNode {4, \u0026node5} node3 := ListNode {3, \u0026node4} node2 := ListNode {2, \u0026node3} node1 := ListNode {1, \u0026node2} head := ListNode {0, \u0026node1} node4.Next = \u0026node3 result := detectCycle(\u0026head) fmt.Println(\"值:\", result.Val); } func show(head *ListNode) { current := head for current != nil { fmt.Println(\"值:\", current.Val); current = current.Next } } /** * Definition for singly-linked list. * type ListNode struct { * Val int * Next *ListNode * } */ func detectCycle(head *ListNode) *ListNode { if head == nil { return nil } fast := head slow := head hasCycle := false for fast != nil \u0026\u0026 fast.Next != nil { slow = slow.Next fast = fast.Next.Next if slow == fast { hasCycle = true break } } if (hasCycle == false) { return nil } start := head for start != slow { start = start.Next slow = slow.Next } return start } ","date":"2019-01-18","objectID":"/leetcode-linked-list-cycle-ii/:0:0","tags":["leetcode","算法"],"title":"LeetCode : linked-list-cycle-ii","uri":"/leetcode-linked-list-cycle-ii/"},{"categories":["2019春节大礼包"],"content":" package main import \"fmt\" type ListNode struct { Val int Next *ListNode } func main() { node5 := ListNode {5, nil} node4 := ListNode {4, \u0026node5} node3 := ListNode {3, \u0026node4} node2 := ListNode {2, \u0026node3} node1 := ListNode {1, \u0026node2} head := ListNode {0, \u0026node1} node3.Next = \u0026node2 result := hasCycle(\u0026head) fmt.Println(\"值:\", result); } func show(head *ListNode) { current := head for current != nil { fmt.Println(\"值:\", current.Val); current = current.Next } } /** * Definition for singly-linked list. * type ListNode struct { * Val int * Next *ListNode * } */ func hasCycle(head *ListNode) bool { if head == nil { return false } fast := head slow := head for fast != nil \u0026\u0026 fast.Next != nil { slow = slow.Next fast = fast.Next.Next if slow == fast { return true } } return false } ","date":"2019-01-18","objectID":"/leetcode-linked-list-cycle/:0:0","tags":["leetcode","算法"],"title":"LeetCode : linked-list-cycle","uri":"/leetcode-linked-list-cycle/"},{"categories":["2019春节大礼包"],"content":" package main import \"fmt\" type ListNode struct { Val int Next *ListNode } func main() { node5 := ListNode {5, nil} node4 := ListNode {4, \u0026node5} node3 := ListNode {3, \u0026node4} node2 := ListNode {2, \u0026node3} node1 := ListNode {1, \u0026node2} head := ListNode {0, \u0026node1} reverseList(\u0026head) } func show(head *ListNode) { current := head for current != nil { fmt.Println(\"值:\", current.Val); current = current.Next } } /** * Definition for singly-linked list. * type ListNode struct { * Val int * Next *ListNode * } */ func reverseList(head *ListNode) *ListNode { if (head == nil) { return nil } var prev *ListNode prev = nil current := head next := head.Next for current != nil { if prev != nil { fmt.Println(\"prev:\", prev.Val); } else { fmt.Println(\"prev:nil\"); } if current != nil { fmt.Println(\"current:\", current.Val); } else { fmt.Println(\"current:nil\"); } if next != nil { fmt.Println(\"next:\", next.Val); } else { fmt.Println(\"next:nil\"); } fmt.Println(\"=========\"); current.Next = prev //真正把current的指针指向前序节点的操作 prev = current //维护prev current = next //维护current if (current != nil) { // 如果current已经为nil，则下一次不会再进入循环体；同时next.Next越界 next = next.Next //维护next } } show(prev) return prev } ","date":"2019-01-17","objectID":"/leetcode-reverse-linked-list/:0:0","tags":["leetcode","算法"],"title":"LeetCode : reverse-linked-list","uri":"/leetcode-reverse-linked-list/"},{"categories":["2019春节大礼包"],"content":" package main import \"fmt\" type ListNode struct { Val int Next *ListNode } func main() { node5 := ListNode {5, nil} node4 := ListNode {4, \u0026node5} node3 := ListNode {3, \u0026node4} node2 := ListNode {2, \u0026node3} node1 := ListNode {1, \u0026node2} head := ListNode {0, \u0026node1} result := swapPairs(\u0026head) show(result) } func show(head *ListNode) { current := head for current != nil { fmt.Println(\"值:\", current.Val); current = current.Next } } /** * Definition for singly-linked list. * type ListNode struct { * Val int * Next *ListNode * } */ func swapPairs(head *ListNode) *ListNode { // 边界条件 if head == nil || head.Next == nil { return head } // 初始化 var prev *ListNode prev = nil current1 := head current2 := head.Next next := head.Next.Next for current1 != nil \u0026\u0026 current2 != nil { if prev != nil { fmt.Println(\"prev:\", prev.Val); } else { fmt.Println(\"prev:nil\"); } if current1 != nil { fmt.Println(\"current1:\", current1.Val); } else { fmt.Println(\"current1:nil\"); } if current2 != nil { fmt.Println(\"current2:\", current2.Val); } else { fmt.Println(\"current2:nil\"); } if next != nil { fmt.Println(\"next:\", next.Val); } else { fmt.Println(\"next:nil\"); } fmt.Println(\"-----------\"); // 调整指向 current1.Next = next current2.Next = current1 if prev != nil { prev.Next = current2 } else { head = current2 } if current1.Next != nil { fmt.Println(\"current1.next:\", current1.Next.Val); } if current2.Next != nil { fmt.Println(\"current2.next:\", current2.Next.Val); } fmt.Println(\"============\"); // 维护临时变量 prev = current1 current1 = next if (next != nil) { current2 = next.Next if (next.Next != nil) { next = next.Next.Next } else { next = nil } } else { current2 = nil next = nil } } return head } ","date":"2019-01-17","objectID":"/leetcode-swap-nodes-in-pairs/:0:0","tags":["leetcode","算法"],"title":"LeetCode : swap-nodes-in-pairs","uri":"/leetcode-swap-nodes-in-pairs/"},{"categories":["算法学习笔记"],"content":"BF算法 暴力匹配 ","date":"2018-12-31","objectID":"/%E7%AE%97%E6%B3%95-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/:1:0","tags":["算法","学习笔记"],"title":"算法:字符串匹配","uri":"/%E7%AE%97%E6%B3%95-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/"},{"categories":["算法学习笔记"],"content":"代码实现 \u003c?php /** * 暴力匹配 * @param string $main 主串 * @param string $pattern 模式串 * @return mixed integer/boolean */ function bf($main, $pattern) { $main = str_split($main); $pattern = str_split($pattern); foreach ($main as $mk =\u003e $mv) { //匹配主串的mk~mk+pattern.size位置的内容 for ($pk = 0; $pk \u003c count($pattern); $pk++) { if ($main[$mk + $pk] == $pattern[$pk]) { if ($pk == (count($pattern) - 1)) { //匹配完成 return $mk; } //当前字符匹配 continue; } else { //不匹配 break; } } } return false; } //$result = bf('abcdefg', 'bcq'); //var_dump($result); ","date":"2018-12-31","objectID":"/%E7%AE%97%E6%B3%95-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/:1:1","tags":["算法","学习笔记"],"title":"算法:字符串匹配","uri":"/%E7%AE%97%E6%B3%95-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/"},{"categories":["算法学习笔记"],"content":"RK算法 通过哈希算法对主串中的 n-m+1 个子串分别求哈希值，然后然后逐个与模式串的哈希值比较大小。 为了提高哈希算法的效率，可能需要针对字符集设计相应的哈希算法，比如把每个字母都映射成数字等。 ","date":"2018-12-31","objectID":"/%E7%AE%97%E6%B3%95-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/:2:0","tags":["算法","学习笔记"],"title":"算法:字符串匹配","uri":"/%E7%AE%97%E6%B3%95-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/"},{"categories":["算法学习笔记"],"content":"代码实现 \u003c?php /** * 用hash的方式做匹配，免去逐个匹配模式串的字符 * 这里用的md5是随便选择的，md5实际上还是会考虑每个字符；一般实际应用场景会用如下两种hash函数来减少hash函数的复杂度 * 1.把字符集中的每个字符都映射成数字，hash函数是对这个映射结果求一个[字符集大小]进制的数值 * 2.如果字符集过大，那就不求真正的[字符集大小]进制的数值，而是直接用字面拼接值做为hash结果；这种情况会有hash冲突，所以hash匹配成功后还需要比较下原文是否一致 * @param string $main 主串 * @param string $pattern 模式串 * @return mixed integer/boolean */ function rk($main, $pattern) { $pHash = md5($pattern); $mainArray = str_split($main); foreach ($mainArray as $mk =\u003e $mv) { //截取主串中mk~mk+count($pattern)位置的内容 $mPart = substr($main, $mk, strlen($pattern)); //echo \"mPart : {$mPart}; $pattern\" . PHP_EOL; $mPartHash = md5($mPart); if ($pHash == $mPartHash) { return $mk; } } return false; } //$result = rk('abcdefg', 'bc'); //var_dump($result); ","date":"2018-12-31","objectID":"/%E7%AE%97%E6%B3%95-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/:2:1","tags":["算法","学习笔记"],"title":"算法:字符串匹配","uri":"/%E7%AE%97%E6%B3%95-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/"},{"categories":["算法学习笔记"],"content":"BM算法 模式串与主串匹配的过程，可以看成是模式串在主串下滑动的过程，上述两种算法都是每次滑动一位，所以效率较低。BM算法本质是寻找到一些能多滑动几位的规则，从而提高效率。 ","date":"2018-12-31","objectID":"/%E7%AE%97%E6%B3%95-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/:3:0","tags":["算法","学习笔记"],"title":"算法:字符串匹配","uri":"/%E7%AE%97%E6%B3%95-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/"},{"categories":["算法学习笔记"],"content":"坏字符规则 举个栗子 如下图，其中的c在模式串中压根不存在，所以不可能和模式串发生匹配，如果按照前面描述的算法，还是需要每次滑动一位 模式串中不存在坏字符的情况 这个栗子里我们可以直接把模式串移动到c的后面(这里的c就是坏字符) 模式串中存在坏字符的情况 如果模式串中存在坏字符，那我们就不能直接把模式串滑动到坏字符后面了，需要把坏字符和模式串中坏字符的位置对齐 当模式串中存在多个坏字符时，让坏字符和模式串中最后一个坏字符的位置对齐(避免错过匹配) 坏字符的问题 当主串是aaaaaaaaaaaaaaa，模式串是baaa时，坏字符将是a，因为模式串中的a都在b的后面，所以无法计算移动距离 实现tips 坏字符规则中最耗时的是在模式串中寻找坏字符的位置，我们可以先把模式串中每一个字符最后出现的位置准备到一个数组中，需要用的时候直接访问数组中的值即可。 ","date":"2018-12-31","objectID":"/%E7%AE%97%E6%B3%95-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/:3:1","tags":["算法","学习笔记"],"title":"算法:字符串匹配","uri":"/%E7%AE%97%E6%B3%95-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/"},{"categories":["算法学习笔记"],"content":"好后缀规则 举个栗子 好后缀在模式串中如果存在除了后缀以外的匹配，将两者对齐 当好后缀的后缀子串和模式串的前缀子串有重合时，将两者对齐 实现tips 好后缀规则计算最复杂的部分就是在模式串中寻找好后缀的匹配和好后缀的后缀子串和模式串的前缀子串的匹配，对于此，我们初始化两个数组 用suffix数组存储k长度的后缀，在模式串中对应匹配的起始下标 用prefix来记录模式串的后缀子串是否能匹配模式串的前缀子串 ","date":"2018-12-31","objectID":"/%E7%AE%97%E6%B3%95-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/:3:2","tags":["算法","学习笔记"],"title":"算法:字符串匹配","uri":"/%E7%AE%97%E6%B3%95-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/"},{"categories":["算法学习笔记"],"content":"何时使用哪个规则 我们分别计算两种规则的移动距离，选择其中最大的作为最终移动规则 ","date":"2018-12-31","objectID":"/%E7%AE%97%E6%B3%95-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/:3:3","tags":["算法","学习笔记"],"title":"算法:字符串匹配","uri":"/%E7%AE%97%E6%B3%95-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/"},{"categories":["算法学习笔记"],"content":"代码实现 \u003c?php function bm($main, $pattern) { //好后缀信息初始化 $suffix = []; $prefix = []; generateSuffixAndPrefix($pattern, $suffix, $prefix); $main = str_split($main); $pattern = str_split($pattern); //坏字符信息初始化 $patternCharLastPosition = []; //模式串中每个字符最后出现的位置(为了在模式串中寻找坏字符的时候更高效) foreach ($pattern as $pk =\u003e $pv) { $patternCharLastPosition[$pv] = $pk; } $patternPosition = 0; //模式串第一个字符和主串对应的位置 //主串中剩余的字符还足够给模式串匹配用，就继续循环 while ((count($main) - 1 - $patternPosition) \u003e= count($pattern)) { //打印当前状态 echo implode('', $main) . PHP_EOL; for ($i = 0; $i \u003c $patternPosition; $i++) { echo \" \"; } echo implode('', $pattern) . PHP_EOL; //从后往前匹配模式串 for ($pk = count($pattern) - 1; $pk \u003e= 0; $pk--) { //当前字符没有匹配成功;获取坏字符$pk if ($main[$patternPosition + $pk] != $pattern[$pk]) { echo \"bad char : {$main[$patternPosition + $pk]}\" . PHP_EOL; break; } } if ($pk \u003c 0) { //匹配成功 return $patternPosition; } //滑动模式串位置 //如果模式串中没有坏字符,则直接移到坏字符右边 if (!isset($patternCharLastPosition[$main[$patternPosition + $pk]])) { $patternCharLastPosition[$main[$patternPosition + $pk]] = -1; } $badCharMoveLength = $pk - $patternCharLastPosition[$main[$patternPosition + $pk]]; //如果有好后缀的话 这里有问题 if ($pk \u003c (count($pattern) - 1)) { $goodSuffixMoveLength = moveByGoodSuffix($pk, count($pattern), $suffix, $prefix); $moveLength = $badCharMoveLength \u003e $goodSuffixLength ? $badCharMoveLength : $goodSuffixLength; } else { $moveLength = $badCharMoveLength; } echo \"goodSuffixLength : {$goodSuffixLength}; badCharMoveLength : {$badCharMoveLength}; moveLength : {$moveLength}\" . PHP_EOL; $patternPosition = $patternPosition + $moveLength; echo PHP_EOL; } return false; } $result = bm('abcdefgafg', 'gafg'); var_dump($result); function moveByGoodSuffix($badCharPosition, $patternLength, $suffix, $prefix) { $goodSuffixLength = $patternLength - 1 - $badCharPosition; if (isset($suffix[$goodSuffixLength])) { return $badCharPosition - $suffix[$goodSuffixLength] + 1; } for ($r = $badCharPosition + 2; $r \u003c $patternLength - 1; $r++) { if ($prefix[$r]) { return $r; } } return $patternLength; } /** * 构造suffix和prefix * 左指针从0开始一直往右移动，一直和最后一个字符匹配，什么时候匹配到了，就基于这个左指针往左移，看有没有更长的匹配 * @param string $pattern * @param array $suffix * @param array $prefix * @return void */ function generateSuffixAndPrefix($pattern, \u0026$suffix, \u0026$prefix) { $pattern = str_split($pattern); $m = count($pattern); for ($pk = 0; $pk \u003c $m - 1; $pk++) { $left = $pk; $suffixLength = 0; $right = $m-1; echo \"left : {$left}; right : {$right}; suffixLength:{$suffixLength}\" . PHP_EOL; while (($left \u003e= 0) \u0026\u0026 ($pattern[$left] == $pattern[$m-1-$suffixLength])) { $right = $m-1-$suffixLength; echo \"left : {$left}; right : {$right}; suffixLength:{$suffixLength} success\" . PHP_EOL; $left--; // i-\u003e0 $suffixLength++; // 0-\u003ei $suffix[$suffixLength] = $left + 1; } if ($left == -1) { $prefix[$suffixLength] = true; } } } ","date":"2018-12-31","objectID":"/%E7%AE%97%E6%B3%95-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/:3:4","tags":["算法","学习笔记"],"title":"算法:字符串匹配","uri":"/%E7%AE%97%E6%B3%95-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/"},{"categories":["算法学习笔记"],"content":"KMP算法 ","date":"2018-12-31","objectID":"/%E7%AE%97%E6%B3%95-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/:4:0","tags":["算法","学习笔记"],"title":"算法:字符串匹配","uri":"/%E7%AE%97%E6%B3%95-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/"},{"categories":["算法学习笔记"],"content":"举个栗子 当遇到坏字符时，把模式串往后移，移多少取决于好前缀的后缀子串和模式串的前缀子串的最长匹配位置。 ","date":"2018-12-31","objectID":"/%E7%AE%97%E6%B3%95-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/:4:1","tags":["算法","学习笔记"],"title":"算法:字符串匹配","uri":"/%E7%AE%97%E6%B3%95-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/"},{"categories":["算法学习笔记"],"content":"实现tips 此时核心诉求就变成了，对于模式串的每一个长度的前缀子串的后缀子串，寻找对应的模式串的前缀子串。 因为这个寻找与主串无关，根据模式串就可以实现，所以只需要根据模式串初始化好这个数组就可以(预处理这里用动态规划) 这里真正难搞的是实现tips里的suffix、prefix和next数组，这些内容我也是勉强理解，等后面再回头看搞懂的时再回来补上 ","date":"2018-12-31","objectID":"/%E7%AE%97%E6%B3%95-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/:4:2","tags":["算法","学习笔记"],"title":"算法:字符串匹配","uri":"/%E7%AE%97%E6%B3%95-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/"},{"categories":["算法学习笔记"],"content":"Trie树 ","date":"2018-12-31","objectID":"/%E7%AE%97%E6%B3%95-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/:5:0","tags":["算法","学习笔记"],"title":"算法:字符串匹配","uri":"/%E7%AE%97%E6%B3%95-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/"},{"categories":["算法学习笔记"],"content":"定义 给个图，一看就懂噻 ","date":"2018-12-31","objectID":"/%E7%AE%97%E6%B3%95-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/:5:1","tags":["算法","学习笔记"],"title":"算法:字符串匹配","uri":"/%E7%AE%97%E6%B3%95-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/"},{"categories":["算法学习笔记"],"content":"Trie树很耗内存吗 如果用数组存储指针，那每个节点都需要存储完整的字符集，这种情况会比较消耗内存；但是如果牺牲一点性能，用散列表等结构存储，会有很大改善。 ","date":"2018-12-31","objectID":"/%E7%AE%97%E6%B3%95-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/:5:2","tags":["算法","学习笔记"],"title":"算法:字符串匹配","uri":"/%E7%AE%97%E6%B3%95-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/"},{"categories":["算法学习笔记"],"content":"Trie树的适用场景(局限性) 字符串的字符集不能太大 字符串的前缀重合较多 需要自己实现，复杂 用到了指针，不连续内存，对cpu缓存不友好 一般工程上更多使用红黑树或散列表，Trie树比较适合搜索引擎的模糊搜索词提醒等场景。 ","date":"2018-12-31","objectID":"/%E7%AE%97%E6%B3%95-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/:5:3","tags":["算法","学习笔记"],"title":"算法:字符串匹配","uri":"/%E7%AE%97%E6%B3%95-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/"},{"categories":["算法学习笔记"],"content":"AC自动机 AC自动机和Trie树的关系和KMP算法和BF算法的关系一样，都是在匹配失败后多跳几个节点以提高效率 字符串匹配这块理解得实在不好，后续再返回来更深理解一遍 ","date":"2018-12-31","objectID":"/%E7%AE%97%E6%B3%95-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/:6:0","tags":["算法","学习笔记"],"title":"算法:字符串匹配","uri":"/%E7%AE%97%E6%B3%95-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/"},{"categories":["算法学习笔记"],"content":"定义 大概长这样 存储 ","date":"2018-12-23","objectID":"/%E7%AE%97%E6%B3%95-%E5%9B%BE/:0:0","tags":["算法","学习笔记"],"title":"算法:图","uri":"/%E7%AE%97%E6%B3%95-%E5%9B%BE/"},{"categories":["算法学习笔记"],"content":"邻接矩阵 邻接矩阵存储是用一个二位数组存储图，如果i和j之间有边，则矩阵的[i][j]位置有值。 劣势是存储存在浪费情况 无向图一条边需要存储在两个位置 顶点多但是边少的情况存在大量的空间浪费 优势是获取两个顶点是否存在连接的效率很高O(1) ","date":"2018-12-23","objectID":"/%E7%AE%97%E6%B3%95-%E5%9B%BE/:1:0","tags":["算法","学习笔记"],"title":"算法:图","uri":"/%E7%AE%97%E6%B3%95-%E5%9B%BE/"},{"categories":["算法学习笔记"],"content":"邻接表 邻接表是用类似哈希表的方式存储表，数组中每个节点的链表中存储这个顶点关联的顶点 搜索 ","date":"2018-12-23","objectID":"/%E7%AE%97%E6%B3%95-%E5%9B%BE/:2:0","tags":["算法","学习笔记"],"title":"算法:图","uri":"/%E7%AE%97%E6%B3%95-%E5%9B%BE/"},{"categories":["算法学习笔记"],"content":"广度优先搜索 以起点的顶点为中心，搜索它周围所有的顶点； 再以它周围的每一个顶点，搜索它周围所有没被搜索过的顶点； 以此类推，直到找到目标顶点 ","date":"2018-12-23","objectID":"/%E7%AE%97%E6%B3%95-%E5%9B%BE/:3:0","tags":["算法","学习笔记"],"title":"算法:图","uri":"/%E7%AE%97%E6%B3%95-%E5%9B%BE/"},{"categories":["算法学习笔记"],"content":"深度优先搜索 从起点顶点出发，沿着一个方向一直前进(每次递归调用就是前进了一步)，如果找到了就直接返回； 否则就回退一步(递归函数执行完成，就会返回到调用栈的上一个函数中，即回退了一步)，换一个没有前进过的方向继续尝试； 直到找到目的顶点 ","date":"2018-12-23","objectID":"/%E7%AE%97%E6%B3%95-%E5%9B%BE/:4:0","tags":["算法","学习笔记"],"title":"算法:图","uri":"/%E7%AE%97%E6%B3%95-%E5%9B%BE/"},{"categories":["算法学习笔记"],"content":"代码 \u003c?php require_once('linked-list.php'); require_once('queue.php'); class Graph { //邻接表(链表数组) public $adjacencyList = []; /** * 增加一条边 (无向图,所以需要增加两个指向) * @param integer $start * @param integer $end * @return void */ public function addEdge($start, $end) { //其他语言可能需要指定邻接表的大小，并把邻接表都初始化为链表，这里选择动态创建 if (!isset($this-\u003eadjacencyList[$start])) { //没有拉链，创建 $this-\u003eadjacencyList[$start] = new LinkedList($end); } else { //已有拉链，在链尾增加元素 $this-\u003eadjacencyList[$start]-\u003eadd($end); } if (!isset($this-\u003eadjacencyList[$end])) { $this-\u003eadjacencyList[$end] = new LinkedList($start); } else { $this-\u003eadjacencyList[$end]-\u003eadd($start); } } /** * 广度优先搜索 * @param integer $start * @param integer $end * @return void */ public function bfs($start, $end) { if ($start == $end) { return ; } $visited = []; //记录已经被访问过的点 $queue = new Queue(); //用来存储已经被访问，但相连的顶点还没有被访问的点 $prev = []; //记录搜索路径 $prev[x] = y 表示遍历是从y来到x //初始化$start顶点在上述三个map中的状态 $visited[$start] = true; $queue-\u003ein($start); //遍历队列中所有需要处理的顶点 while (!$queue-\u003eisEmpty()) { $center = $queue-\u003eout(); //本次遍历的立足点 $handle = $this-\u003eadjacencyList[$center]-\u003ehead; //本次遍历的起点 //遍历 while ($handle != null) { if (!isset($visited[$handle-\u003edata])) { echo \"center : {$center}; handle : {$handle-\u003edata}\" . PHP_EOL; //prev $prev[$handle-\u003edata] = $center; //终止条件 if ($handle-\u003edata == $end) { $this-\u003eprint($prev, $start, $end); return ; } //visited $visited[$handle-\u003edata] = true; //queue $queue-\u003ein($handle-\u003edata); } $handle = $handle-\u003enext; } } } public $found = false; /** * 深度优先搜索:一条道走到黑,如果找到了就返回;否则回退几步换个没走过的方向继续尝试,直到找到目的地 * @param integer $start * @param integer $end * @return void */ public function dfs($start, $end) { $this-\u003efound = false; $visited = []; $prev = []; $this-\u003erecursionDfs($start, $end, $visited, $prev); $this-\u003eprint($prev, $start, $end); } /** * 深度优先搜索递归函数 * @param integer $center * @param integer $end * @param array $visited * @param array $prev */ public function recursionDfs($center, $end, \u0026$visited, \u0026$prev) { if ($this-\u003efound) { return ; } $visited[$center] = true; //终止条件 if ($center == $end) { $this-\u003efound = true; return ; } $handle = $this-\u003eadjacencyList[$center]-\u003ehead; while ($handle != null) { if (!isset($visited[$handle-\u003edata])) { echo \"center : {$center}; handle : {$handle-\u003edata}\" . PHP_EOL; $prev[$handle-\u003edata] = $center; //前进一步 $this-\u003erecursionDfs($handle-\u003edata, $end, $visited, $prev); } $handle = $handle-\u003enext; } //最终没有匹配成功,后退一步 } /** * 根据$prev打印路径 * @param array $prev * @param integer $start * @param integer $end * @return void */ public function print($prev, $start, $end) { if (($prev[$end]) \u0026\u0026 ($start != $end)) { $this-\u003eprint($prev, $s, $prev[$end]); } echo $end . ' '; } } $graph = new Graph(); $graph-\u003eaddEdge(0, 1); $graph-\u003eaddEdge(0, 3); $graph-\u003eaddEdge(1, 2); $graph-\u003eaddEdge(1, 4); $graph-\u003eaddEdge(2, 5); $graph-\u003eaddEdge(3, 4); $graph-\u003eaddEdge(4, 5); $graph-\u003eaddEdge(4, 6); $graph-\u003eaddEdge(5, 7); $graph-\u003ebfs(0, 7); $graph = new Graph(); $graph-\u003eaddEdge(1, 2); $graph-\u003eaddEdge(1, 4); $graph-\u003eaddEdge(2, 3); $graph-\u003eaddEdge(2, 5); $graph-\u003eaddEdge(3, 6); $graph-\u003eaddEdge(5, 7); $graph-\u003eaddEdge(5, 6); $graph-\u003eaddEdge(6, 8); $graph-\u003edfs(1, 7); ","date":"2018-12-23","objectID":"/%E7%AE%97%E6%B3%95-%E5%9B%BE/:5:0","tags":["算法","学习笔记"],"title":"算法:图","uri":"/%E7%AE%97%E6%B3%95-%E5%9B%BE/"},{"categories":["算法学习笔记"],"content":"运行结果 center : 0; handle : 1 center : 0; handle : 3 center : 1; handle : 2 center : 1; handle : 4 center : 2; handle : 5 center : 4; handle : 6 center : 5; handle : 7 1 2 5 7 center : 1; handle : 2 center : 2; handle : 3 center : 3; handle : 6 center : 6; handle : 5 center : 5; handle : 7 center : 6; handle : 8 center : 1; handle : 4 1 2 3 6 5 7 ","date":"2018-12-23","objectID":"/%E7%AE%97%E6%B3%95-%E5%9B%BE/:6:0","tags":["算法","学习笔记"],"title":"算法:图","uri":"/%E7%AE%97%E6%B3%95-%E5%9B%BE/"},{"categories":["算法学习笔记"],"content":"辅助类 ","date":"2018-12-23","objectID":"/%E7%AE%97%E6%B3%95-%E5%9B%BE/:7:0","tags":["算法","学习笔记"],"title":"算法:图","uri":"/%E7%AE%97%E6%B3%95-%E5%9B%BE/"},{"categories":["算法学习笔记"],"content":"LinkedList \u003c?php class Node { public function __construct($value) { $this-\u003edata = $value; } public $data = ''; public $next = null; } class LinkedList { public function __construct($value) { $this-\u003ehead = new Node($value); } public $head = null; public function printList() { $node = $this-\u003ehead; while ($node-\u003enext != null) { echo $node-\u003edata . ' '; $node = $node-\u003enext; } } public function add($value) { $tempNode = $this-\u003ehead; while ($tempNode-\u003enext != null) { $tempNode = $tempNode-\u003enext; } $tempNode-\u003enext = new Node($value); } } ","date":"2018-12-23","objectID":"/%E7%AE%97%E6%B3%95-%E5%9B%BE/:7:1","tags":["算法","学习笔记"],"title":"算法:图","uri":"/%E7%AE%97%E6%B3%95-%E5%9B%BE/"},{"categories":["算法学习笔记"],"content":"Queue \u003c?php class Queue { public $data = []; public function in($value) { $this-\u003edata[] = $value; } public function out() { return array_shift($this-\u003edata); } public function isEmpty() { return count($this-\u003edata) == 0; } } ","date":"2018-12-23","objectID":"/%E7%AE%97%E6%B3%95-%E5%9B%BE/:7:2","tags":["算法","学习笔记"],"title":"算法:图","uri":"/%E7%AE%97%E6%B3%95-%E5%9B%BE/"},{"categories":["算法学习笔记"],"content":"定义 堆是一个完全二叉树 堆中的每个节点的值都必须大于等于(或小于等于)其子树中每个节点的值 后续讨论默认为大顶堆 关键点 ","date":"2018-12-21","objectID":"/%E7%AE%97%E6%B3%95-%E5%A0%86/:0:0","tags":["算法","学习笔记"],"title":"算法:堆","uri":"/%E7%AE%97%E6%B3%95-%E5%A0%86/"},{"categories":["算法学习笔记"],"content":"存储 完全二叉树用数组存储最合适，见数据结构-二叉树/#存储方式 ","date":"2018-12-21","objectID":"/%E7%AE%97%E6%B3%95-%E5%A0%86/:1:0","tags":["算法","学习笔记"],"title":"算法:堆","uri":"/%E7%AE%97%E6%B3%95-%E5%A0%86/"},{"categories":["算法学习笔记"],"content":"插入 往堆的最后一个叶节点后插入一个元素 从该节点自底向上堆化 (即把不符合堆定义的树更新为符合堆定义的树) ","date":"2018-12-21","objectID":"/%E7%AE%97%E6%B3%95-%E5%A0%86/:2:0","tags":["算法","学习笔记"],"title":"算法:堆","uri":"/%E7%AE%97%E6%B3%95-%E5%A0%86/"},{"categories":["算法学习笔记"],"content":"删除堆顶元素 用最后一个叶节点替换堆顶元素 删除最后一个叶节点 从堆顶节点自顶向下堆化 ","date":"2018-12-21","objectID":"/%E7%AE%97%E6%B3%95-%E5%A0%86/:3:0","tags":["算法","学习笔记"],"title":"算法:堆","uri":"/%E7%AE%97%E6%B3%95-%E5%A0%86/"},{"categories":["算法学习笔记"],"content":"为什么不直接把堆顶元素置空，然后执行堆化呢？ 这样空节点有可能不落在最后一个叶节点，这样就不满足完全二叉树的要求了，所以直接把最后一个节点拎出来。 ","date":"2018-12-21","objectID":"/%E7%AE%97%E6%B3%95-%E5%A0%86/:3:1","tags":["算法","学习笔记"],"title":"算法:堆","uri":"/%E7%AE%97%E6%B3%95-%E5%A0%86/"},{"categories":["算法学习笔记"],"content":"堆化 ","date":"2018-12-21","objectID":"/%E7%AE%97%E6%B3%95-%E5%A0%86/:4:0","tags":["算法","学习笔记"],"title":"算法:堆","uri":"/%E7%AE%97%E6%B3%95-%E5%A0%86/"},{"categories":["算法学习笔记"],"content":"自底向上 当前节点和父节点做比较，如果当前节点比父节点大，则交换位置；递归到顶。 ","date":"2018-12-21","objectID":"/%E7%AE%97%E6%B3%95-%E5%A0%86/:4:1","tags":["算法","学习笔记"],"title":"算法:堆","uri":"/%E7%AE%97%E6%B3%95-%E5%A0%86/"},{"categories":["算法学习笔记"],"content":"自顶向下 当前节点和左右子树做比较，如果左右子树中有比当前节点小的，则把两个子树中最大的那一个和当前节点交换位置；递归到底。 ","date":"2018-12-21","objectID":"/%E7%AE%97%E6%B3%95-%E5%A0%86/:4:2","tags":["算法","学习笔记"],"title":"算法:堆","uri":"/%E7%AE%97%E6%B3%95-%E5%A0%86/"},{"categories":["算法学习笔记"],"content":"堆排序 堆排序分为两部分，首先是建堆，然后排序 ","date":"2018-12-21","objectID":"/%E7%AE%97%E6%B3%95-%E5%A0%86/:5:0","tags":["算法","学习笔记"],"title":"算法:堆","uri":"/%E7%AE%97%E6%B3%95-%E5%A0%86/"},{"categories":["算法学习笔记"],"content":"建堆 思路一：从前往后，自底向上 用往堆中逐项插入节点的形式建堆。 即最开始认为只有第一个元素是堆中的元素，插入第二个元素，自底向上堆化，依次类推，直至所有数据插入完成。 这个思路堆化的时间复杂度是O(nlogn)，即：需要插入n个元素，每次插入需要的堆化的logn次操作。 思路二：从后往前，自顶向下 从最后一个元素开始，逐项自底向上堆化，最终建立完整堆。 看起来思路二更复杂一些，因为自顶向下堆化比自底向上要复杂；但是自顶向下有个特性，就是叶子节点无需堆化，这样我们只遍历所有非叶子节点即可。 这个思路堆化的时间复杂度看起来是O(n/2*logn),但是不够精确,经过一系列复杂(我也不太会的)计算,最终的复杂度是O(logn) ","date":"2018-12-21","objectID":"/%E7%AE%97%E6%B3%95-%E5%A0%86/:5:1","tags":["算法","学习笔记"],"title":"算法:堆","uri":"/%E7%AE%97%E6%B3%95-%E5%A0%86/"},{"categories":["算法学习笔记"],"content":"排序 排序的思路类似插入，把堆顶元素(最大)和最后一个叶子节点(下标为n,是最大元素排序后应该在的位置)互换位置;然后把1~n-1堆化,递归后就得到了有序的数组。 ","date":"2018-12-21","objectID":"/%E7%AE%97%E6%B3%95-%E5%A0%86/:5:2","tags":["算法","学习笔记"],"title":"算法:堆","uri":"/%E7%AE%97%E6%B3%95-%E5%A0%86/"},{"categories":["算法学习笔记"],"content":"为什么快排比堆排序快？ 堆排序是稳定的O(nlogn)排序，看起来比快排还要优秀，但是实际上快排比堆排序要快。 堆排序数据访问的方式没有快速排序友好：快排是连续访问数组，堆排序主要是跳跃访问数据，对cpu缓存不友好 对于同样的数据，在排序过程中，堆排序的交换次数要多于快速排序；快速排序的交换次数等于逆序度，但是堆排序会打乱数据。 代码实现 \u003c?php //run(); function run() { $heap = new Heap([1, 2, 5, 10, 6, 90, 49]); $heap-\u003esort(); $heap-\u003einsert(66); $heap-\u003edeleteTop(); var_dump($heap-\u003edata); } //数组方式存储树,预设为大顶堆 class Heap { public $data = []; //建堆 public function __construct($data) { //第一种:从顶开始,逐项从尾部插入,自底向上堆化O(nlogn) /* $this-\u003edata[] = null; foreach ($data as $item) { $this-\u003einsert($item); } */ //第二种:从第一个不是叶节点的节点开始逐项往前,逐项自顶向下堆化 O(n)[因为叶子节点下面只有自己,所以不需要自顶向下堆化,省掉了所有叶子节点的堆化过程] //堆是完全二叉树,要找到叶子节点的起始位置,只需知道最后一个不是叶子节点的位置是最后一个叶节点的父节点(n/2),所以从1-n/2是非叶节点,n/2+1~n是叶节点 $this-\u003edata = array_merge([null], $data); for ($i = floor(count($this-\u003edata)/2); $i \u003e= 1; $i--) { $this-\u003eheapifyTopToBottom($i, count($this-\u003edata)); } } /** * 往堆里插入一个数据:把数据插入到最后一个叶节点的位置,然后自底向上堆化 * @param integer $value * @return void */ public function insert($value) { //把要插入的数据放到最后一个叶子节点 $this-\u003edata[] = $value; //自底向上堆化 $i = count($this-\u003edata) - 1; while (floor($i/2) \u003e 0 \u0026\u0026 $this-\u003edata[$i] \u003e $this-\u003edata[floor($i/2)]) { $this-\u003eswap($i, floor($i/2)); $i = floor($i/2); } } /** * 删除堆顶元素 * @return void */ public function deleteTop() { //把最后一个元素替换到堆顶 $lastLeafPosition = count($this-\u003edata) - 1; $this-\u003edata[1] = $this-\u003edata[$lastLeafPosition]; unset($this-\u003edata[$lastLeafPosition]); $this-\u003eheapifyTopToBottom(1, $lastLeafPosition); } /** * 堆排序:把堆顶元素(最大)和最后一个叶子节点(下标为n,是最大元素排序后应该在的位置)互换位置;然后把1~n-1堆化,递归后就得到了有序的数组 * @return void */ public function sort() { for ($i = (count($this-\u003edata) - 1); $i \u003e= 1; $i--) { //交换$i和1 $this-\u003eswap(1, $i); //堆化 $this-\u003eheapifyTopToBottom(1, $i); } } /** * 自顶向下堆化 * @param integer $i 起始点 * @param integer $size 要堆化内容的长度 */ public function heapifyTopToBottom($i, $size) { while (true) { $maxPosition = $i; if (($i*2 \u003c $size) \u0026\u0026 ($this-\u003edata[$i] \u003c $this-\u003edata[$i*2])) { //左子树大 $maxPosition = $i * 2; } if ((($i*2+1) \u003c $size) \u0026\u0026 ($this-\u003edata[$maxPosition] \u003c $this-\u003edata[$i*2+1])) { //右子树更大 $maxPosition = $i * 2 + 1; } //echo \"i=\u003e{$i}; v[i]=\u003e{$this-\u003edata[$i]}; v[i*2]=\u003e{$this-\u003edata[$i*2]}; v[i*2+1]=\u003e{$this-\u003edata[$i*2+1]}\" . PHP_EOL; if ($maxPosition != $i) { $this-\u003eswap($i, $maxPosition); $i = $maxPosition; } else { break; } } } /** * 交换$this-\u003edata中的两个数据 * @param integer $i * @param integer $j * @return void */ public function swap($i, $j) { $temp = $this-\u003edata[$i]; $this-\u003edata[$i] = $this-\u003edata[$j]; $this-\u003edata[$j] = $temp; } } 这篇博客是目前为止最耗时间的一篇，mark一下~ ","date":"2018-12-21","objectID":"/%E7%AE%97%E6%B3%95-%E5%A0%86/:5:3","tags":["算法","学习笔记"],"title":"算法:堆","uri":"/%E7%AE%97%E6%B3%95-%E5%A0%86/"},{"categories":["算法学习笔记"],"content":"定义 ","date":"2018-12-20","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%BA%A2%E9%BB%91%E6%A0%91/:0:0","tags":["算法","学习笔记"],"title":"数据结构:红黑树","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%BA%A2%E9%BB%91%E6%A0%91/"},{"categories":["算法学习笔记"],"content":"意义 红黑树是一种近似平衡的二叉查找树 树各种操作的时间复杂度基本都和树的高度成正比，所以我们期望我们的树能尽量平衡，这样才能让复杂度不退化，保持在O(logn)的级别。 一种完全平衡的二叉查找树实现是AVL树，但是树是动态数据结构，要在频繁的操作中维持树的完全平衡代价很大，所以红黑树应运而生。它满足了维持平衡代价低、且性能不至于退化严重两个需求。 ","date":"2018-12-20","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%BA%A2%E9%BB%91%E6%A0%91/:1:0","tags":["算法","学习笔记"],"title":"数据结构:红黑树","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%BA%A2%E9%BB%91%E6%A0%91/"},{"categories":["算法学习笔记"],"content":"要求 根节点是黑色的 每个叶子节点都是黑色的空节点 任何相邻的节点都不能同时为红色(这个相邻是指父子相邻) 每个节点，从该节点到达其可达叶子节点的所有路径，都包含相同数目的黑色节点 红黑树如何保证\"近似\"平衡(高度不至于太高) 如果将红色节点去掉，那只包含黑色节点的红黑树的高度是多少 如果从四叉树中取出某些节点，放到叶子节点位置，四叉树就变成了完全二叉树 由要求每个节点，从该节点到达其可达叶子节点的所有路径，都包含相同数目的黑色节点可以知道，如果从四叉树中取出某些节点，放到叶节点的位置，四叉树就变成了完全二叉树。所以仅包含黑色节点的四叉树的高度，比包含相同节点数目的完全二叉树的高度还要小，即小于logn。 如果把红色加回去，树的高度是多少 由要求任何相邻的节点都不能同时为红色可知，在竖直方向上有一个红色节点至少要有一个黑色节点，所以红色节点增加的高度不会比仅有黑色的四叉树高度更高，即小于2logn。 实现 红黑树的实现主要是保持树的平衡过程，主要有旋转和变色两种操作。 实现过程基本是针对不同的情况之下不同的流程，情况较多很复杂。所以呢，就不写了(因为我也不会 ","date":"2018-12-20","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%BA%A2%E9%BB%91%E6%A0%91/:2:0","tags":["算法","学习笔记"],"title":"数据结构:红黑树","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%BA%A2%E9%BB%91%E6%A0%91/"},{"categories":["算法学习笔记"],"content":"定义 ","date":"2018-12-18","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E4%BA%8C%E5%8F%89%E6%A0%91/:0:0","tags":["算法","学习笔记"],"title":"数据结构:二叉树","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"categories":["算法学习笔记"],"content":"树 摘自维基百科 树（英语：Tree）是一种无向图（undirected graph），其中任意两个顶点间存在唯一一条路径。或者说，只要没有回路的连通图就是树。 ","date":"2018-12-18","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E4%BA%8C%E5%8F%89%E6%A0%91/:1:0","tags":["算法","学习笔记"],"title":"数据结构:二叉树","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"categories":["算法学习笔记"],"content":"二叉树 每个节点最多有左右两个节点 ","date":"2018-12-18","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E4%BA%8C%E5%8F%89%E6%A0%91/:2:0","tags":["算法","学习笔记"],"title":"数据结构:二叉树","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"categories":["算法学习笔记"],"content":"完全二叉树 叶子节点都在最下两层 最后一层的叶子全靠左 除了最后一层，其他层的节点都要达到最大 ","date":"2018-12-18","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E4%BA%8C%E5%8F%89%E6%A0%91/:3:0","tags":["算法","学习笔记"],"title":"数据结构:二叉树","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"categories":["算法学习笔记"],"content":"满二叉树 除了叶子节点，每个节点都有左右两个子节点 存储方式 ","date":"2018-12-18","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E4%BA%8C%E5%8F%89%E6%A0%91/:4:0","tags":["算法","学习笔记"],"title":"数据结构:二叉树","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"categories":["算法学习笔记"],"content":"链式存储 用类似链表的形式存储，每个节点有左和右两个指针，分别指向左子树和右子树 ","date":"2018-12-18","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E4%BA%8C%E5%8F%89%E6%A0%91/:5:0","tags":["算法","学习笔记"],"title":"数据结构:二叉树","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"categories":["算法学习笔记"],"content":"顺序存储 把树的每个节点按照一定的规则存入数组中，存入规则如下 根节点在i=1的位置 根节点的左子节点在2*i的位置 根节点的右子节点在2*i+1的位置 依次类推 读取规则也一样，假设当前节点在i的位置，则 它的左子节点：2*i 它的右子节点：2*i+1 它的父节点：floor(i/2) 当二叉树是完全二叉树时，使用顺序存储只浪费了0这一个位置，但是如果二叉树本身不够完全，则会浪费较多空间。 二叉树的遍历 二叉树有前序、中序、后续三种遍历方式，本质都是递归，非常简单，实现如下 ","date":"2018-12-18","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E4%BA%8C%E5%8F%89%E6%A0%91/:6:0","tags":["算法","学习笔记"],"title":"数据结构:二叉树","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"categories":["算法学习笔记"],"content":"代码 \u003c?php class node { public $data; public $left; public $right; public function __construct($data) { $this-\u003edata = $data; } } // 先建立一棵树 $root = new node(1); $node2 = new node(2); $node3 = new node(3); $root-\u003eleft = $node2; $root-\u003eright = $node3; $node4 = new node(4); $node5 = new node(5); $node2-\u003eleft = $node4; $node2-\u003eright = $node5; $node6 = new node(6); $node7 = new node(7); $node3-\u003eleft = $node6; $node3-\u003eright = $node7; preTraversal($root); echo PHP_EOL; inTraversal($root); echo PHP_EOL; postTraversal($root); echo PHP_EOL; //前序遍历 function preTraversal($root) { if ($root == null) { return ; } echo $root-\u003edata . ' '; preTraversal($root-\u003eleft); preTraversal($root-\u003eright); } //中序遍历 function inTraversal($root) { if ($root == null) { return ; } inTraversal($root-\u003eleft); echo $root-\u003edata . ' '; inTraversal($root-\u003eright); } //后序遍历 function postTraversal($root) { if ($root == null) { return ; } postTraversal($root-\u003eleft); postTraversal($root-\u003eright); echo $root-\u003edata . ' '; } ","date":"2018-12-18","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E4%BA%8C%E5%8F%89%E6%A0%91/:7:0","tags":["算法","学习笔记"],"title":"数据结构:二叉树","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"categories":["算法学习笔记"],"content":"执行结果 1 2 4 5 3 6 7 4 2 5 1 6 3 7 4 5 2 6 7 3 1 二叉查找树 ","date":"2018-12-18","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E4%BA%8C%E5%8F%89%E6%A0%91/:8:0","tags":["算法","学习笔记"],"title":"数据结构:二叉树","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"categories":["算法学习笔记"],"content":"定义 任意一个节点的左子树中每个节点的值都要小于这个节点的值，右子树节点的值都大于这个节点的值。 它的主要意义在于：O(logn)级的增删改查，中序遍历可以直接输出有序结果(这一点散列表做不到) ","date":"2018-12-18","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E4%BA%8C%E5%8F%89%E6%A0%91/:9:0","tags":["算法","学习笔记"],"title":"数据结构:二叉树","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"categories":["算法学习笔记"],"content":"查找 如果要查找的值等于根节点，直接返回 如果要查找的值小于根节点，递归查找左子树 如果要查找的值大于根节点，递归查找右子树 ","date":"2018-12-18","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E4%BA%8C%E5%8F%89%E6%A0%91/:10:0","tags":["算法","学习笔记"],"title":"数据结构:二叉树","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"categories":["算法学习笔记"],"content":"插入 如果要查找的值大于根节点 根节点的右子树为空，则直接插入到根节点的右子树中 * 根节点的右子树不为空，则递归右子树找到插入位置 如果要查找的值小于根节点，处理方法同上 ","date":"2018-12-18","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E4%BA%8C%E5%8F%89%E6%A0%91/:11:0","tags":["算法","学习笔记"],"title":"数据结构:二叉树","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"categories":["算法学习笔记"],"content":"删除 如果要删除的节点没有子节点，直接把该节点的父节点中指向要删除节点的指针置为null 如果要删除的节点只有一个子节点，直接把该节点的父节点中指向要删除节点的指针指向它的子节点 如果要删除的节点有两个子节点，需要找到要删除节点的右子树中的最小节点，把它替换到要删除的节点上 ","date":"2018-12-18","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E4%BA%8C%E5%8F%89%E6%A0%91/:12:0","tags":["算法","学习笔记"],"title":"数据结构:二叉树","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"categories":["算法学习笔记"],"content":"散列表是什么 散列表是一种O(1)复杂度查找的数据结构，它是如何做到的呢 数组的随机访问为O(1) 把数据的key通过某种方式(hash函数)转化为数组的下标 于是当你要寻找某个key时，只需要通过hash函数把你的值转化为数组的下标，通过下标直接访问数组即可得到你要找的数据。 散列函数 散列函数是把key转化为数组下标的函数，理想的函数需要满足以下三个条件: 散列函数计算得到的散列值是一个非负整数（这个值是数组的下标） 如果key1 = key2，那 hash(key1) = hash(key2) 如果key1 ≠ key2，那 hash(key1) ≠ hash(key2) [这一条基本没有散列函数能做到，所以会产生散列冲突] 散列冲突 上述散列函数需要满足的条件中如果key1 ≠ key2，那 hash(key1) ≠ hash(key2)很难被满足，所以就会出现key1 ≠ key2，但是 hash(key1) = hash(key2)的情况，这种情况叫散列冲突。这里给出常见的散列冲突解决方法： ","date":"2018-12-17","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%95%A3%E5%88%97%E8%A1%A8/:0:0","tags":["算法","学习笔记"],"title":"数据结构:散列表","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%95%A3%E5%88%97%E8%A1%A8/"},{"categories":["算法学习笔记"],"content":"开放寻址法 ","date":"2018-12-17","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%95%A3%E5%88%97%E8%A1%A8/:1:0","tags":["算法","学习笔记"],"title":"数据结构:散列表","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%95%A3%E5%88%97%E8%A1%A8/"},{"categories":["算法学习笔记"],"content":"线性探测 插入：某个key做完hash后发现对应下标的位置已经有值，则查找下一个下标处是否有值，直到寻找到一个空的位置。 查找：先对key做hash，到它本该在的地方寻找，如果有则直接返回，否则依次查找下一个位置，直到找到(返回)或者找到空位(找不到) 删除：不能直接把目的位置清空，否则会影响查找操作；需要把删除的位置标记为deleted ","date":"2018-12-17","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%95%A3%E5%88%97%E8%A1%A8/:1:1","tags":["算法","学习笔记"],"title":"数据结构:散列表","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%95%A3%E5%88%97%E8%A1%A8/"},{"categories":["算法学习笔记"],"content":"二次探测 和线性探测一致，只是查找步长不一样；线性探测步长一致是1，二次探测步长为：1^2 2^2 … ","date":"2018-12-17","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%95%A3%E5%88%97%E8%A1%A8/:1:2","tags":["算法","学习笔记"],"title":"数据结构:散列表","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%95%A3%E5%88%97%E8%A1%A8/"},{"categories":["算法学习笔记"],"content":"双重散列 使用一堆散列函数，第一个找不到则用第二个，依次类推… ","date":"2018-12-17","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%95%A3%E5%88%97%E8%A1%A8/:1:3","tags":["算法","学习笔记"],"title":"数据结构:散列表","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%95%A3%E5%88%97%E8%A1%A8/"},{"categories":["算法学习笔记"],"content":"链表法 每个数组的位置都对应一个链表，插入时直接把数据附加到链表最后。这个是最简单也是最好用的办法 工业级的散列表 ","date":"2018-12-17","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%95%A3%E5%88%97%E8%A1%A8/:2:0","tags":["算法","学习笔记"],"title":"数据结构:散列表","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%95%A3%E5%88%97%E8%A1%A8/"},{"categories":["算法学习笔记"],"content":"要求 支持快速的查询、插入、删除操作 内存占用合理，不能浪费过多空间 性能稳定，在极端情况下，性能也不能退化到无法接受的情况 ","date":"2018-12-17","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%95%A3%E5%88%97%E8%A1%A8/:3:0","tags":["算法","学习笔记"],"title":"数据结构:散列表","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%95%A3%E5%88%97%E8%A1%A8/"},{"categories":["算法学习笔记"],"content":"需要考虑的点 ","date":"2018-12-17","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%95%A3%E5%88%97%E8%A1%A8/:4:0","tags":["算法","学习笔记"],"title":"数据结构:散列表","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%95%A3%E5%88%97%E8%A1%A8/"},{"categories":["算法学习笔记"],"content":"设计一个合适的散列函数 尽可能的随机、均匀，避免散列冲突 保持散列函数简单 常见方法：直接寻址法、平方取中法、折叠法、随机数法 ","date":"2018-12-17","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%95%A3%E5%88%97%E8%A1%A8/:4:1","tags":["算法","学习笔记"],"title":"数据结构:散列表","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%95%A3%E5%88%97%E8%A1%A8/"},{"categories":["算法学习笔记"],"content":"定义装载因子阈值，并设计动态扩容策略 如何设置装载因子阈值？ 该阈值主要用来控制扩容\u0026缩容，时间复杂度分析用摊还分析法 需要根据业务权衡时间复杂度和空间复杂度 如何避免低效扩容？ 分批扩容，和基本扩容方式相比，每次插入时顺带完成一次扩容中一条数据的迁移，避免达到阈值后一次需要O(n)的时间来完成整体扩容。 插入：将数据插入散列表，并从老的散列表中拿出一个数据放入新的散列表 查询：先查新散列表，再查老散列表 ","date":"2018-12-17","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%95%A3%E5%88%97%E8%A1%A8/:4:2","tags":["算法","学习笔记"],"title":"数据结构:散列表","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%95%A3%E5%88%97%E8%A1%A8/"},{"categories":["算法学习笔记"],"content":"选择合适的散列冲突解决方法 开放寻址法和链表法的优劣分析，考虑以下情况： 当要存储的数据较小，链表法因为需要存储指针，可能造成较大的空间浪费。 当装载因子较大时，开放寻址法的性能退化严重(扩容缩容耗时\u0026寻址耗时) 当数据规模较大，开放寻址法因为需要连续的内存空间，可能会导致内存无法利用 链表不需要连续的内存空间，对cpu缓存不友好 所以大部分情况下，链表法更加普适，当链表较大时可以改造为红黑树或跳表来避免性能恶化；而开放寻址法更适合小规模数据、装载因子不高的情况。 散列表和链表/跳表一起使用 数组有随机访问的优势，但有占据连续内存的优势的缺点。 链表具有可不连续存储的优势，但有访问查找需要线性级时间的缺点。 把数组(散列表)和链表(跳表)结合使用，可以结合两者的优势。 举例：散列表+双向链表的形式，prev和next用于指向真正链表的前序和后续；hnext用于组织散列表的拉链，这样插入、删除、查找的复杂度都降低到了O(1) ","date":"2018-12-17","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%95%A3%E5%88%97%E8%A1%A8/:4:3","tags":["算法","学习笔记"],"title":"数据结构:散列表","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%95%A3%E5%88%97%E8%A1%A8/"},{"categories":["算法学习笔记"],"content":"跳表是什么 二分查找的实现依赖数组的随机访问，跳表就是让链表也能实现二分查找。 把单链表的每两个结点提取一个结点到上级，这样查找的时候思路和二分查找基本一致。 跳表查询的时间复杂度 假设按照每两个结点抽出一个结点的话，会有log2n级索引；那么跳表查询的时间复杂度就是O(m*logn)，m是每层索引需要查询的数量，每层索引最多需要遍历3个节点(因为高层的两个结点之间只有三个低层节点) 所以总的查询复杂度就是O(logn)，和二分查找一致。 跳表的索引占用的空间 跳表的索引需要占用的空间量级是O(n) 实际应用中不需要太在意索引占用的额外空间，因为数据结构本身可能很大，而索引只需要存储关键数据，所以相对很小。 插入和删除的效率 链表的插入和删除本身效率都很高，是O(1)级别的，主要的时间花在查找的O(n)；跳表把查找的时间复杂度降到O(logn)，所以它插入和删除的时间复杂度也是O(logn) 索引的动态更新 当跳表不断有新元素插入，跳表的某两个索引之间的数据可能会增多导致跳表失去平衡，极端情况下会退化成单链表。 所以让我们插入数据时，需要考虑更新索引，更新的基本思路为：当我们往跳表中插入数据时，我们可以同时将这个数据插入到一个随机函数生成的指定层级的部分索引层中。 ","date":"2018-12-17","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E8%B7%B3%E8%A1%A8/:0:0","tags":["算法","学习笔记"],"title":"数据结构:跳表","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E8%B7%B3%E8%A1%A8/"},{"categories":["算法学习笔记"],"content":"基本思路 在已经升序排列且无重复数据的数组中，每次查找都取数组的中点值和目标值对比大小，如果目标值偏大，则目标值在中点右侧；如果目标值偏小，则目标值在中点左侧。 代码 \u003c?php $arr = [1, 2, 3, 5, 6, 8, 9, 10, 15, 20, 100]; $result = binarySearch(3, $arr); var_dump($result); $result = binarySearchRecursion(100, $arr, 0, 10); var_dump($result); /** * 二分查找 * @param integer $target * @param array $arr * @return integer 被查找值在数组中的位置 */ function binarySearch($target, $arr) { $l = 0; $h = count($arr) - 1; while($l \u003c= $h) { $m = intval(floor(($l+$h)/2)); //因为floor返回的是float类型(float范围比int大，所以floor只能返回float) echo \"low : {$l} ; high : {$h}; m : {$m}\" . PHP_EOL; if ($arr[$m] == $target) { return $m; } else if ($target \u003e $arr[$m]) { $l = $m + 1; } else { $h = $m - 1; } } return -1; } /** * 二分查找 * @param integer $target * @param array $arr * @param integer $l * @param integer $h * @return integer 被查找值在数组中的位置 */ function binarySearchRecursion($target, $arr, $l, $h) { /* 为啥不需要这段呢? 假设最小位置是0，最大位置是10 考虑如果要查找0位置的数字，使用floor取整数是可以的，但是如果要查找10位置的数字就找不到了？ 用ceil取整的话刚好相反，10位置的数字可以找到，但是0位置的找不到？ 解决问题的点在于递归调用时的$m+1和$m-1, 调用时会让$m前进或后退一步 如果是10位置的数值,则此时l=10 h=10,避免出现l=9 h=10 m=9(floor) 的尴尬局面;0位置同理 if ($target == $arr[$l]) { return $l; } if ($target == $arr[$h]) { return $h; } */ if ($l \u003e $h) { return -1; } $m = intval(floor(($l+$h)/2)); echo \"low : {$l} ; high : {$h}; m : {$m}\" . PHP_EOL; if ($target == $arr[$m]) { return $m; } if ($target \u003e $arr[$m]) { return binarySearchRecursion($target, $arr, $m + 1, $h); } else { return binarySearchRecursion($target, $arr, $l - 1, $m); } } 执行结果 low : 0 ; high : 10; m : 5 low : 0 ; high : 4; m : 2 int(2) low : 0 ; high : 10; m : 5 low : 6 ; high : 10; m : 8 low : 9 ; high : 10; m : 9 low : 10 ; high : 10; m : 10 int(10) 适用场景 二分查找的时间复杂度为O(logn)，效率非常高，所以你懂得，一定有它的局限性。 数据结构一定是顺序表结构(数组)，因为二分查找需要随机访问 原始数据要有序 数据量太小不适合，不如直接遍历 数据量太大不适合，因为它依赖数组，数组需要连续内存空间，比较难得 变体 各种变体的主要区别在于当$target = $arr[$m]时，不直接返回$m，而是根据需求更新对应的$l或$h 查找第一个值等于给定值的元素 查找最后一个值等于给定值的元素 查找第一个大于等于给定值的的元素 查找最后一个小于等于给定值的元素 ","date":"2018-12-16","objectID":"/%E7%AE%97%E6%B3%95-%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/:0:0","tags":["算法","学习笔记"],"title":"算法:二分查找","uri":"/%E7%AE%97%E6%B3%95-%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/"},{"categories":["架构学习笔记"],"content":"分类 负载均衡算法大致能分为以下几类： 任务平分类 负载均衡类 性能最优类 Hash类 算法 ","date":"2018-12-10","objectID":"/21-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/:0:0","tags":["架构","学习笔记"],"title":"21.高性能负载均衡：算法","uri":"/21-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/"},{"categories":["架构学习笔记"],"content":"轮询 ","date":"2018-12-10","objectID":"/21-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/:1:0","tags":["架构","学习笔记"],"title":"21.高性能负载均衡：算法","uri":"/21-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/"},{"categories":["架构学习笔记"],"content":"优点 简单 ","date":"2018-12-10","objectID":"/21-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/:1:1","tags":["架构","学习笔记"],"title":"21.高性能负载均衡：算法","uri":"/21-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/"},{"categories":["架构学习笔记"],"content":"缺点 无法感知到机器自身的状态和负载，只有机器宕机或失联才能感知 ","date":"2018-12-10","objectID":"/21-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/:1:2","tags":["架构","学习笔记"],"title":"21.高性能负载均衡：算法","uri":"/21-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/"},{"categories":["架构学习笔记"],"content":"加权轮询 ","date":"2018-12-10","objectID":"/21-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/:2:0","tags":["架构","学习笔记"],"title":"21.高性能负载均衡：算法","uri":"/21-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/"},{"categories":["架构学习笔记"],"content":"优点 能把服务器处理能力差异考虑到轮询算法中（配置） ","date":"2018-12-10","objectID":"/21-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/:2:1","tags":["架构","学习笔记"],"title":"21.高性能负载均衡：算法","uri":"/21-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/"},{"categories":["架构学习笔记"],"content":"缺点 依然无法把服务器的状态加入考虑 ","date":"2018-12-10","objectID":"/21-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/:2:2","tags":["架构","学习笔记"],"title":"21.高性能负载均衡：算法","uri":"/21-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/"},{"categories":["架构学习笔记"],"content":"负载最低优先 这里的负载根据业务场景不同，指标也不尽相同；可能是cpu负载、内存负载、连接数等等 ","date":"2018-12-10","objectID":"/21-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/:3:0","tags":["架构","学习笔记"],"title":"21.高性能负载均衡：算法","uri":"/21-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/"},{"categories":["架构学习笔记"],"content":"优点 解决了轮询算法中无法感知服务器状态的问题 ","date":"2018-12-10","objectID":"/21-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/:3:1","tags":["架构","学习笔记"],"title":"21.高性能负载均衡：算法","uri":"/21-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/"},{"categories":["架构学习笔记"],"content":"缺点 复杂度上升（因为需要感知服务器状态，就要求服务器上报状态） ","date":"2018-12-10","objectID":"/21-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/:3:2","tags":["架构","学习笔记"],"title":"21.高性能负载均衡：算法","uri":"/21-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/"},{"categories":["架构学习笔记"],"content":"性能最优 优先把请求分配给响应最快的服务器 ","date":"2018-12-10","objectID":"/21-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/:4:0","tags":["架构","学习笔记"],"title":"21.高性能负载均衡：算法","uri":"/21-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/"},{"categories":["架构学习笔记"],"content":"优点 同负载最低优先一样，也能感知服务器状态（只是通过响应时间来感知的） ","date":"2018-12-10","objectID":"/21-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/:4:1","tags":["架构","学习笔记"],"title":"21.高性能负载均衡：算法","uri":"/21-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/"},{"categories":["架构学习笔记"],"content":"缺点 复杂度上升（需要收集每个服务器每个任务的响应时间） 收集和统计本身比较耗费资源 * 为了减少统计上的消耗，可以不收集全部信息，通过抽样的方式来收集信息；这就涉及到采样率的选取，太低会导致结果不准确，太高会导致性能消耗较大。 * 需要选择合适的周期 ","date":"2018-12-10","objectID":"/21-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/:4:2","tags":["架构","学习笔记"],"title":"21.高性能负载均衡：算法","uri":"/21-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/"},{"categories":["架构学习笔记"],"content":"Hash Hash是指对请求的某个指标做Hash，然后对Hash值取模，根据取模结果把请求分配到某台机器上。 这种算法主要是为了满足某种特殊诉求，比如相同user_id的请求要打到同一台机器上，或者相同ip的请求打到同一台机器上。 ","date":"2018-12-10","objectID":"/21-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/:5:0","tags":["架构","学习笔记"],"title":"21.高性能负载均衡：算法","uri":"/21-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/"},{"categories":["架构学习笔记"],"content":"负载均衡分类 ","date":"2018-12-10","objectID":"/20-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%88%86%E7%B1%BB%E5%8F%8A%E6%9E%B6%E6%9E%84/:0:0","tags":["架构","学习笔记"],"title":"20.高性能负载均衡：分类及架构","uri":"/20-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%88%86%E7%B1%BB%E5%8F%8A%E6%9E%B6%E6%9E%84/"},{"categories":["架构学习笔记"],"content":"DNS负载均衡 ","date":"2018-12-10","objectID":"/20-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%88%86%E7%B1%BB%E5%8F%8A%E6%9E%B6%E6%9E%84/:1:0","tags":["架构","学习笔记"],"title":"20.高性能负载均衡：分类及架构","uri":"/20-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%88%86%E7%B1%BB%E5%8F%8A%E6%9E%B6%E6%9E%84/"},{"categories":["架构学习笔记"],"content":"优点 简单，成本低 就近访问，提升访问速度 ","date":"2018-12-10","objectID":"/20-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%88%86%E7%B1%BB%E5%8F%8A%E6%9E%B6%E6%9E%84/:1:1","tags":["架构","学习笔记"],"title":"20.高性能负载均衡：分类及架构","uri":"/20-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%88%86%E7%B1%BB%E5%8F%8A%E6%9E%B6%E6%9E%84/"},{"categories":["架构学习笔记"],"content":"缺点 更新不及时 扩展性差 分配策略简单 有些公司针对业务特点实现自己的DNS系统，优缺点与此刚好相反 ","date":"2018-12-10","objectID":"/20-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%88%86%E7%B1%BB%E5%8F%8A%E6%9E%B6%E6%9E%84/:1:2","tags":["架构","学习笔记"],"title":"20.高性能负载均衡：分类及架构","uri":"/20-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%88%86%E7%B1%BB%E5%8F%8A%E6%9E%B6%E6%9E%84/"},{"categories":["架构学习笔记"],"content":"硬件负载均衡 F5 A10 ","date":"2018-12-10","objectID":"/20-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%88%86%E7%B1%BB%E5%8F%8A%E6%9E%B6%E6%9E%84/:2:0","tags":["架构","学习笔记"],"title":"20.高性能负载均衡：分类及架构","uri":"/20-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%88%86%E7%B1%BB%E5%8F%8A%E6%9E%B6%E6%9E%84/"},{"categories":["架构学习笔记"],"content":"优点 功能强大：全面支持各层级的负载均衡，支持全面的负载均衡算法，支持全局负载均衡 性能强大：软件负载均衡最高支持约10万级并发，硬件可以支持100万以上的并发 稳定性高 支持安全防护：兼具防火墙、防DDoS攻击等安全功能 ","date":"2018-12-10","objectID":"/20-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%88%86%E7%B1%BB%E5%8F%8A%E6%9E%B6%E6%9E%84/:2:1","tags":["架构","学习笔记"],"title":"20.高性能负载均衡：分类及架构","uri":"/20-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%88%86%E7%B1%BB%E5%8F%8A%E6%9E%B6%E6%9E%84/"},{"categories":["架构学习笔记"],"content":"缺点 价格昂贵 扩展能力差 ","date":"2018-12-10","objectID":"/20-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%88%86%E7%B1%BB%E5%8F%8A%E6%9E%B6%E6%9E%84/:2:2","tags":["架构","学习笔记"],"title":"20.高性能负载均衡：分类及架构","uri":"/20-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%88%86%E7%B1%BB%E5%8F%8A%E6%9E%B6%E6%9E%84/"},{"categories":["架构学习笔记"],"content":"软件负载均衡 Nginx LVS ","date":"2018-12-10","objectID":"/20-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%88%86%E7%B1%BB%E5%8F%8A%E6%9E%B6%E6%9E%84/:3:0","tags":["架构","学习笔记"],"title":"20.高性能负载均衡：分类及架构","uri":"/20-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%88%86%E7%B1%BB%E5%8F%8A%E6%9E%B6%E6%9E%84/"},{"categories":["架构学习笔记"],"content":"优点 简单 便宜 灵活 ","date":"2018-12-10","objectID":"/20-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%88%86%E7%B1%BB%E5%8F%8A%E6%9E%B6%E6%9E%84/:3:1","tags":["架构","学习笔记"],"title":"20.高性能负载均衡：分类及架构","uri":"/20-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%88%86%E7%B1%BB%E5%8F%8A%E6%9E%B6%E6%9E%84/"},{"categories":["架构学习笔记"],"content":"缺点 性能一般：Nginx大约能支撑5万并发 功能不如硬件负载均衡那么强大 一般不具备防火墙等安全功能 负载均衡典型架构 DNS用于实现地理级别的负载均衡 硬件负载均衡用于实现集群级别的负载均衡 软件负载均衡用于实现机器级别的负载均衡 ","date":"2018-12-10","objectID":"/20-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%88%86%E7%B1%BB%E5%8F%8A%E6%9E%B6%E6%9E%84/:3:2","tags":["架构","学习笔记"],"title":"20.高性能负载均衡：分类及架构","uri":"/20-%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%88%86%E7%B1%BB%E5%8F%8A%E6%9E%B6%E6%9E%84/"},{"categories":["算法学习笔记"],"content":"线性排序即排序时间复杂度为线性O(n)的排序 桶排序 ","date":"2018-12-09","objectID":"/%E7%AE%97%E6%B3%95-%E7%BA%BF%E6%80%A7%E6%8E%92%E5%BA%8F/:0:0","tags":["算法","学习笔记"],"title":"算法:线性排序","uri":"/%E7%AE%97%E6%B3%95-%E7%BA%BF%E6%80%A7%E6%8E%92%E5%BA%8F/"},{"categories":["算法学习笔记"],"content":"数据要求 能够划分为m个有序的桶，且n个数据能够均匀地分配到m个桶中 ","date":"2018-12-09","objectID":"/%E7%AE%97%E6%B3%95-%E7%BA%BF%E6%80%A7%E6%8E%92%E5%BA%8F/:1:0","tags":["算法","学习笔记"],"title":"算法:线性排序","uri":"/%E7%AE%97%E6%B3%95-%E7%BA%BF%E6%80%A7%E6%8E%92%E5%BA%8F/"},{"categories":["算法学习笔记"],"content":"基本思路 N个数据均匀地分布到从小到大的M个桶里，桶与桶之间有序，每个桶内的数据有序。 ","date":"2018-12-09","objectID":"/%E7%AE%97%E6%B3%95-%E7%BA%BF%E6%80%A7%E6%8E%92%E5%BA%8F/:2:0","tags":["算法","学习笔记"],"title":"算法:线性排序","uri":"/%E7%AE%97%E6%B3%95-%E7%BA%BF%E6%80%A7%E6%8E%92%E5%BA%8F/"},{"categories":["算法学习笔记"],"content":"时间复杂度是O(n) 如果要排序的数据有 n 个，我们把它们均匀地划分到 m 个桶内，每个桶里就有 k=n/m 个元素。每个桶内部使用快速排序，时间复杂度为 O(klogk)。m 个桶排序的时间复杂度就是 O(mklogk)，因为 k=n/m，所以整个桶排序的时间复杂度就是 O(nlog(n/m))。当桶的个数 m 接近数据个数 n 时，log(n/m) 就是一个非常小的常量，这个时候桶排序的时间复杂度接近 O(n)。 ","date":"2018-12-09","objectID":"/%E7%AE%97%E6%B3%95-%E7%BA%BF%E6%80%A7%E6%8E%92%E5%BA%8F/:3:0","tags":["算法","学习笔记"],"title":"算法:线性排序","uri":"/%E7%AE%97%E6%B3%95-%E7%BA%BF%E6%80%A7%E6%8E%92%E5%BA%8F/"},{"categories":["算法学习笔记"],"content":"适合场景 桶排序适合外部排序，即数据量非常大，无法一次取到内存中的情况 记数排序 ","date":"2018-12-09","objectID":"/%E7%AE%97%E6%B3%95-%E7%BA%BF%E6%80%A7%E6%8E%92%E5%BA%8F/:4:0","tags":["算法","学习笔记"],"title":"算法:线性排序","uri":"/%E7%AE%97%E6%B3%95-%E7%BA%BF%E6%80%A7%E6%8E%92%E5%BA%8F/"},{"categories":["算法学习笔记"],"content":"数据要求 数据范围不大 ","date":"2018-12-09","objectID":"/%E7%AE%97%E6%B3%95-%E7%BA%BF%E6%80%A7%E6%8E%92%E5%BA%8F/:5:0","tags":["算法","学习笔记"],"title":"算法:线性排序","uri":"/%E7%AE%97%E6%B3%95-%E7%BA%BF%E6%80%A7%E6%8E%92%E5%BA%8F/"},{"categories":["算法学习笔记"],"content":"基本思路 计数排序其实是桶排序的一种特殊情况。当要排序的 n 个数据，所处的范围并不大的时候，比如最大值是 k，我们就可以把数据划分成 k 个桶。每个桶内存储对应值的数量，省掉了桶内排序的时间。 ","date":"2018-12-09","objectID":"/%E7%AE%97%E6%B3%95-%E7%BA%BF%E6%80%A7%E6%8E%92%E5%BA%8F/:6:0","tags":["算法","学习笔记"],"title":"算法:线性排序","uri":"/%E7%AE%97%E6%B3%95-%E7%BA%BF%E6%80%A7%E6%8E%92%E5%BA%8F/"},{"categories":["算法学习笔记"],"content":"优化思路 计数排序的桶C[k]里可以存储数值为k的数值个数，也存储小于等于k的值个数，这样在某些场景下会更加快速。 ","date":"2018-12-09","objectID":"/%E7%AE%97%E6%B3%95-%E7%BA%BF%E6%80%A7%E6%8E%92%E5%BA%8F/:7:0","tags":["算法","学习笔记"],"title":"算法:线性排序","uri":"/%E7%AE%97%E6%B3%95-%E7%BA%BF%E6%80%A7%E6%8E%92%E5%BA%8F/"},{"categories":["算法学习笔记"],"content":"适合场景 计数排序适合数据范围不大的情况，比如人的年龄，高考分数等 基数排序 ","date":"2018-12-09","objectID":"/%E7%AE%97%E6%B3%95-%E7%BA%BF%E6%80%A7%E6%8E%92%E5%BA%8F/:8:0","tags":["算法","学习笔记"],"title":"算法:线性排序","uri":"/%E7%AE%97%E6%B3%95-%E7%BA%BF%E6%80%A7%E6%8E%92%E5%BA%8F/"},{"categories":["算法学习笔记"],"content":"数据要求 需要可以分割出独立的“位”来比较，而且位之间有递进的关系，如果 a 数据的高位比 b 数据大，那剩下的低位就不用比较了。 每一位的数据范围不能太大，要可以用线性排序算法来排序，否则，基数排序的时间复杂度就无法做到 O(n) 了。 ","date":"2018-12-09","objectID":"/%E7%AE%97%E6%B3%95-%E7%BA%BF%E6%80%A7%E6%8E%92%E5%BA%8F/:9:0","tags":["算法","学习笔记"],"title":"算法:线性排序","uri":"/%E7%AE%97%E6%B3%95-%E7%BA%BF%E6%80%A7%E6%8E%92%E5%BA%8F/"},{"categories":["算法学习笔记"],"content":"基本思路 假设要比较两个手机号码 a，b 的大小，如果在前面几位中，a 手机号码已经比 b 手机号码大了，那后面的几位就不用看了。 先按照最后一位来排序手机号码，然后，再按照倒数第二位重新排序，以此类推，最后按照第一位重新排序。经过 11 次排序之后，手机号码就都有序了。 ","date":"2018-12-09","objectID":"/%E7%AE%97%E6%B3%95-%E7%BA%BF%E6%80%A7%E6%8E%92%E5%BA%8F/:10:0","tags":["算法","学习笔记"],"title":"算法:线性排序","uri":"/%E7%AE%97%E6%B3%95-%E7%BA%BF%E6%80%A7%E6%8E%92%E5%BA%8F/"},{"categories":["算法学习笔记"],"content":"优化思路 根据每一位来排序，我们可以用桶排序或者计数排序，它们的时间复杂度可以做到 O(n)。如果要排序的数据有 k 位，那我们就需要 k 次桶排序或者计数排序，总的时间复杂度是 O(k*n)。当 k 不大的时候，比如手机号码排序的例子，k 最大就是 11，所以基数排序的时间复杂度就近似于 O(n)。 ","date":"2018-12-09","objectID":"/%E7%AE%97%E6%B3%95-%E7%BA%BF%E6%80%A7%E6%8E%92%E5%BA%8F/:11:0","tags":["算法","学习笔记"],"title":"算法:线性排序","uri":"/%E7%AE%97%E6%B3%95-%E7%BA%BF%E6%80%A7%E6%8E%92%E5%BA%8F/"},{"categories":["算法学习笔记"],"content":"适合场景 可以分割出独立的“位”来比较，而且位之间有递进的关系 ","date":"2018-12-09","objectID":"/%E7%AE%97%E6%B3%95-%E7%BA%BF%E6%80%A7%E6%8E%92%E5%BA%8F/:12:0","tags":["算法","学习笔记"],"title":"算法:线性排序","uri":"/%E7%AE%97%E6%B3%95-%E7%BA%BF%E6%80%A7%E6%8E%92%E5%BA%8F/"},{"categories":["乱七八糟"],"content":"元字符 代码 说明 . 匹配除换行符以外的任意字符 \\w 匹配字母或数字或下划线或汉字 \\s 匹配任意的空白符 \\b 匹配数字 ^ 匹配字符串的开始 $ 匹配字符串的结束 转义 当需要匹配元字符本身时,需要转义，即： \\元字符 重复 代码 说明 * 重复零次或更多次 + 重复一次或更多次 ? 重复零次或一次 {m} 重复n次 {m,} 重复n次或更多次 {m,n} 重复n到m次 字符类 代码 说明 [aeiou] 匹配任何一个英文元音字母 [0-9] 匹配一位数字 [a-z0-9A-Z_] 匹配一个大小写字母或数字 分支条件 | 表示或 例如：0\\d{2}-\\d{8}|0\\d{3}-\\d{7}能匹配两种电话号码 需要注意顺序，左侧匹配命中后就不会再继续向右进行 分组 ()表示分组 (\\d{1,3}\\.){3}\\d{1,3}是一个简单的IP地址匹配表达式 反义 元字符的反义和具体字符的反义 代码 说明 \\W 匹配任意不是字母，数字，下划线，汉字的字符 \\S 匹配任意不是空白符的字符 \\D 匹配任意非数字的字符 \\B 匹配不是单词开头或结束的位置 [^x] 匹配除了x以外的任意字符 [^aeiou] 匹配除了aeiou这几个字母以外的任意字符 后向引用（变量） \\b(\\w+)\\b\\s+\\1\\b可以用来匹配重复的单词，像go go, 或者kitty kitty 组名：使用\u003cxxx\u003e可以给分组命名 \\b(?\u003cWord\u003e\\w+)\\b\\s+\\k\u003cWord\u003e\\b ","date":"2018-12-09","objectID":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%A4%87%E5%BF%98/:0:0","tags":null,"title":"正则表达式备忘","uri":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%A4%87%E5%BF%98/"},{"categories":["乱七八糟"],"content":"分组常用的语法 代码 说明 (exp) 匹配exp,并捕获文本到自动命名的组里 (?\u003cname\u003eexp) 匹配exp,并捕获文本到名称为name的组里，也可以写成(?'name'exp) (?:exp) 匹配exp,不捕获匹配的文本，也不给此分组分配组号 零宽断言 ","date":"2018-12-09","objectID":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%A4%87%E5%BF%98/:1:0","tags":null,"title":"正则表达式备忘","uri":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%A4%87%E5%BF%98/"},{"categories":["乱七八糟"],"content":"零宽度正预测先行断言 ","date":"2018-12-09","objectID":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%A4%87%E5%BF%98/:2:0","tags":null,"title":"正则表达式备忘","uri":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%A4%87%E5%BF%98/"},{"categories":["乱七八糟"],"content":"简单说 (?=exp) 位置匹配：表达式自身位置后面能匹配exp 它断言自身出现的位置的后面能匹配表达式exp ","date":"2018-12-09","objectID":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%A4%87%E5%BF%98/:2:1","tags":null,"title":"正则表达式备忘","uri":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%A4%87%E5%BF%98/"},{"categories":["乱七八糟"],"content":"举个栗子 比如\\b\\w+(?=ing\\b)，匹配以ing结尾的单词的前面部分(除了ing以外的部分)，如查找I’m singing while you’re dancing.时，它会匹配sing和danc。 ","date":"2018-12-09","objectID":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%A4%87%E5%BF%98/:2:2","tags":null,"title":"正则表达式备忘","uri":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%A4%87%E5%BF%98/"},{"categories":["乱七八糟"],"content":"零宽度正回顾后发断言 ","date":"2018-12-09","objectID":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%A4%87%E5%BF%98/:3:0","tags":null,"title":"正则表达式备忘","uri":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%A4%87%E5%BF%98/"},{"categories":["乱七八糟"],"content":"简单说 (?\u003c=exp) 位置匹配：表达式自身出现的位置前面能匹配exp 它断言自身出现的位置的前面能匹配表达式exp ","date":"2018-12-09","objectID":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%A4%87%E5%BF%98/:3:1","tags":null,"title":"正则表达式备忘","uri":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%A4%87%E5%BF%98/"},{"categories":["乱七八糟"],"content":"举个栗子 比如(?\u003c=\\bre)\\w+\\b会匹配以re开头的单词的后半部分(除了re以外的部分)，例如在查找reading a book时，它匹配ading。 负向零宽断言 ","date":"2018-12-09","objectID":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%A4%87%E5%BF%98/:3:2","tags":null,"title":"正则表达式备忘","uri":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%A4%87%E5%BF%98/"},{"categories":["乱七八糟"],"content":"零宽度负预测先行断言 ","date":"2018-12-09","objectID":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%A4%87%E5%BF%98/:4:0","tags":null,"title":"正则表达式备忘","uri":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%A4%87%E5%BF%98/"},{"categories":["乱七八糟"],"content":"简单说 (?!exp) 位置匹配：表达式自身位置后面不能匹配exp 它断言此位置的后面不能匹配表达式exp ","date":"2018-12-09","objectID":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%A4%87%E5%BF%98/:4:1","tags":null,"title":"正则表达式备忘","uri":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%A4%87%E5%BF%98/"},{"categories":["乱七八糟"],"content":"举个栗子 \\d{3}(?!\\d)匹配三位数字，而且这三位数字的后面不能是数字；\\b((?!abc)\\w)+\\b匹配不包含连续字符串abc的单词。 ","date":"2018-12-09","objectID":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%A4%87%E5%BF%98/:4:2","tags":null,"title":"正则表达式备忘","uri":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%A4%87%E5%BF%98/"},{"categories":["乱七八糟"],"content":"零宽度负回顾后发断言 ","date":"2018-12-09","objectID":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%A4%87%E5%BF%98/:5:0","tags":null,"title":"正则表达式备忘","uri":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%A4%87%E5%BF%98/"},{"categories":["乱七八糟"],"content":"简单说 (?\u003c!exp) 位置匹配：表达式自身位置前面不能匹配exp 它断言此位置的前面不能匹配表达式exp ","date":"2018-12-09","objectID":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%A4%87%E5%BF%98/:5:1","tags":null,"title":"正则表达式备忘","uri":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%A4%87%E5%BF%98/"},{"categories":["乱七八糟"],"content":"举个栗子 (?\u003c![a-z])\\d{7}匹配前面不是小写字母的七位数字。 零宽断言总结 代码 说明 (?=exp) 匹配exp前面的位置 (?\u003c=exp) 匹配exp后面的位置 (?!exp) 匹配后面跟的不是exp的位置 (?\u003c!exp) 匹配前面不是exp的位置 注释 小括号的另一种用途是通过语法(?#comment)来包含注释。例如：2[0-4]\\d(?#200-249)|25[0-5](?#250-255)|[01]?\\d\\d?(?#0-199)。 贪婪与懒惰 ","date":"2018-12-09","objectID":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%A4%87%E5%BF%98/:5:2","tags":null,"title":"正则表达式备忘","uri":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%A4%87%E5%BF%98/"},{"categories":["乱七八糟"],"content":"贪婪匹配： a.*b aabab =\u003e aabab ","date":"2018-12-09","objectID":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%A4%87%E5%BF%98/:6:0","tags":null,"title":"正则表达式备忘","uri":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%A4%87%E5%BF%98/"},{"categories":["乱七八糟"],"content":"懒惰匹配： a.*?b aabab =\u003e aab / ab 所有表示数量的元字符后加问号都可以起到这种效果 处理选项 可以配置，忽略大小写，多行模式，单行模式，忽略空白，显示捕获等 递归匹配 可以像词法分析一样使用堆栈，比较复杂😂 参考链接：正则表达式30分钟入门 ","date":"2018-12-09","objectID":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%A4%87%E5%BF%98/:7:0","tags":null,"title":"正则表达式备忘","uri":"/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%A4%87%E5%BF%98/"},{"categories":["算法学习笔记"],"content":"基本原理 快排的基本思想也是分治，它的基本思路是从数组中选择一个值作为分割点,小于这个分割点的值都放在分割点左侧;递归执行,直到分割点的左侧和右侧都只有一个元素,数组有序。 主要难点 我写这段代码的时候思路没从归并排序中跳出来踩了个坑：选择分割点的时候我沿着归并排序的思路就把分割点选为数组的中点,并且让分区函数返回这个中点,结果就是这个中点并不是分割好了的数组中的新位置,导致不能遍历完全,排序不完全。 其实快排要处理的是分区后的数组,真正有价值的是分区后分割点的位置尽量居中,所以分区前应该选择大小适中的分割点,选择中点完全没意义。 代码 \u003c?php $arr = [8, 10, 2, 3, 6, 1, 5]; main($arr); function main($arr) { quick_sort($arr, 0, count($arr) - 1); } /** * 快速排序 * @param array $arr * @param integer $l * @param integer $h * @return void */ function quick_sort(\u0026$arr, $l, $h) { if ($l \u003e= $h) { return ; } $m = partition($arr, $l, $h); //执行分区,拿到新的数组中分割点数的位置 echo \"{$l}~{$h} 处理完成; 新的分割点为{$m}\" . PHP_EOL; quick_sort($arr, $l, $m - 1); quick_sort($arr, $m + 1, $h); } /** * 分区函数:取$arr[$h]的值为分割点,把大于它的放到它左侧,小于它的放到它右侧,返回这个分割点的新位置 * @param array $arr * @param integer $l * @param integer $h * @return integer $privot */ function partition(\u0026$arr, $l, $h) { echo \"开始处理{$l}~{$h}\" . PHP_EOL; //选取$h为分区点 $left = []; $right = []; for ($i = $l; $i \u003c $h; $i++) { if ($arr[$i] \u003c $arr[$h]) { //左侧 $left[] = $arr[$i]; } else { //右侧 $right[] = $arr[$i]; } } //回灌到$arr $i = $l; for ($j = 0; $j \u003c count($left); $j++) { $arr[$i] = $left[$j]; $i++; } $arr[$i] = $arr[$h]; $privot = $i; $i++; for ($j = 0; $j \u003c count($right); $j++) { $arr[$i] = $right[$j]; $i++; } echo \"分割点的值:{$arr[$privot]}\" . PHP_EOL; echo \"left: \" . json_encode($left) . PHP_EOL; echo \"right: \" . json_encode($right) . PHP_EOL; echo \"arr: \" . json_encode($arr) . PHP_EOL; //注意:要返回的是分割点的值在新数组中的下标 return $privot; } 执行结果 开始处理0~6 分割点的值:5 left: [2,3,1] right: [8,10,6] arr: [2,3,1,5,8,10,6] 0~6 处理完成; 新的分割点为3 开始处理0~2 分割点的值:1 left: [] right: [2,3] arr: [1,2,3,5,8,10,6] 0~2 处理完成; 新的分割点为0 开始处理1~2 分割点的值:3 left: [2] right: [] arr: [1,2,3,5,8,10,6] 1~2 处理完成; 新的分割点为2 开始处理4~6 分割点的值:6 left: [] right: [8,10] arr: [1,2,3,5,6,8,10] 4~6 处理完成; 新的分割点为4 开始处理5~6 分割点的值:10 left: [8] right: [] arr: [1,2,3,5,6,8,10] 5~6 处理完成; 新的分割点为6 优化思路 用临时数组实现的分区函数不是原地排序的空间复杂度是O(n) 有一个很巧妙的办法能实现原地的分区函数 它的思路是用$i作为一个分区点,$i左侧的内容为已处理区间,右侧为未处理区间,每次都从未处理区间取出一个值,如果它小于分割点,则把它交换到已处理区间尾部,即$arr[$i],这样遍历之后即完成了原地分区,$i位置就是分割点 /** * 原地分区函数:功能同partition,但不需要n级别的额外的空间 * @param array $arr * @param integer $l * @param integer $h * @return integer $privot */ function partitionAutochthonous(\u0026$arr, $l, $h) { $pivot = $arr[$h]; $i = $l; for ($j = $l; $j \u003c $h; $j++) { if ($arr[$j] \u003c $pivot) { swap($arr, $i, $j); $i++; } } swap($arr, $i, $h); return $i; } /** * 交换操作,把数组中下标为$i和$j的数据换位置 * @param array $arr * @param integer $i * @param integer $j */ function swap(\u0026$arr, $i, $j) { $temp = $arr[$i]; $arr[$i] = $arr[$j]; $arr[$j] = $temp; } 性能分析 ","date":"2018-12-09","objectID":"/%E7%AE%97%E6%B3%95-%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/:0:0","tags":["算法","学习笔记"],"title":"算法:快速排序","uri":"/%E7%AE%97%E6%B3%95-%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/"},{"categories":["算法学习笔记"],"content":"空间复杂度 如果使用原地的分区函数,那么快速排序就是一个原地排序,它的空间复杂度为O(1);如果不使用原地分区函数,那么它的空间复杂度为O(n) ","date":"2018-12-09","objectID":"/%E7%AE%97%E6%B3%95-%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/:1:0","tags":["算法","学习笔记"],"title":"算法:快速排序","uri":"/%E7%AE%97%E6%B3%95-%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/"},{"categories":["算法学习笔记"],"content":"时间复杂度 快速排序的时间复杂度取决于分区操作的次数,分区操作的时间复杂度为O(n); 如果能每次都恰好选择大小适中的分割点,那么分区次数就是完全二叉树的高度logn,那么快速排序的时间复杂度和归并排序相同,都是O(nlogn); 如果每次都选择最差的分割点,即所有数字都在分割点左侧,那就需要n次分区操作,基本退化为选择排序,此时的时间复杂度为O(n^2); 如果随机选取分割点,快速排序的平均时间复杂度为O(nlogn) 快速排序和归并排序的区别 ","date":"2018-12-09","objectID":"/%E7%AE%97%E6%B3%95-%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/:2:0","tags":["算法","学习笔记"],"title":"算法:快速排序","uri":"/%E7%AE%97%E6%B3%95-%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/"},{"categories":["算法学习笔记"],"content":"思路:快速排序自顶向下;归并排序自底向上 快速排序是先分区,然后再处理子问题; 归并排序是先处理子问题,然后再合并 ","date":"2018-12-09","objectID":"/%E7%AE%97%E6%B3%95-%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/:3:0","tags":["算法","学习笔记"],"title":"算法:快速排序","uri":"/%E7%AE%97%E6%B3%95-%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/"},{"categories":["算法学习笔记"],"content":"性能:快速排序空间占优;归并排序时间稳定 归并排序的时间复杂度很稳定,但是空间复杂度也稳定较高,因为合并操作无法原地完成; 快速排序虽然时间不够稳定,但是整体可接受,且空间复杂度很有优势,所以快排应用更加广泛 ","date":"2018-12-09","objectID":"/%E7%AE%97%E6%B3%95-%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/:4:0","tags":["算法","学习笔记"],"title":"算法:快速排序","uri":"/%E7%AE%97%E6%B3%95-%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/"},{"categories":["算法学习笔记"],"content":"基本原理 要排序一个数组，只需要把它的左半部分和右半部分分别排序，再把两个部分按排序合并，即完成了排序。 而当两部分划分到最小，即左部分和右部分都只有一个元素时，直接合并即可。 归并排序的思想是分治，先分(分两部分,分别排序)后治(把两部分合并) 主要难点(个人感觉) merge函数的边界条件需要仔细斟酌,不然容易越界或死循环 性能分析 时间复杂度是O(nlogn):归并排序的主要内容是分X治；其中logn是分叉过程中二叉树的最大高度，n是治(merge函数)的耗时 空间复杂度是O(n):因为merge函数在同一时刻需要最大为n的临时空间 代码 ","date":"2018-12-07","objectID":"/%E7%AE%97%E6%B3%95-%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/:0:0","tags":["算法","学习笔记"],"title":"算法:归并排序","uri":"/%E7%AE%97%E6%B3%95-%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/"},{"categories":["算法学习笔记"],"content":"递归实现 \u003c?php $arr = [11, 8, 3, 9, 7, 1, 2, 5]; main($arr); /** * 入口函数 * @param array $arr * @rturn array $arr(有序) */ function main(\u0026$arr) { merge_sort($arr, 0, count($arr) - 1); return $arr; } /** * 把数组$arr的$l-$h排序 * @param array $arr * @param integer $l * @param integer $h * @return void */ function merge_sort(\u0026$arr, $l, $h) { echo \"当前在执行{$l} ~ {$h}的排序\\n\"; if ($l \u003e= $h) { echo \"当前到达一个叶节点 {$l}\\n\"; return ; } $m = floor(($h+$l)/2); merge_sort($arr, $l, $m); //左侧有序 merge_sort($arr, $m+1, $h); //右侧有序 //左侧和右侧都有序,怎么递归是它的事,但是已经有序了,合并即可 merge($arr, $l, $m, $h); } /** * 数组$arr的$l-$m,$m-$h两部分有序,把有序的两部分合并为一部分,依然保持有序 * @param array $arr * @param integer $l * @param integer $m * @param integer $h * @return void */ function merge(\u0026$arr, $l, $m, $h) { $arrResult = []; $i = $l; $j = $m + 1; echo \"开始合并{$l}~{$m}和{$j}~{$h}\\n\"; while (($i \u003c= $m) || ($j \u003c= $h)) { //echo \"合并中:i=\u003e{$i};j=\u003e{$j}\\n\"; // 有一个数组已经遍历完成的情况 if ($i \u003e $m) { $arrResult[] = $arr[$j]; $j++; continue; } if ($j \u003e $h) { $arrResult[] = $arr[$i]; $i++; continue; } if ($arr[$j] \u003c $arr[$i]) { //当$j位置的数据小的时才让$j在前面,保证排序稳定性 $arrResult[] = $arr[$j]; $j++; } else { $arrResult[] = $arr[$i]; $i++; } } echo \"合并结果\" . json_encode($arrResult) . \"\\n\"; //把arrResult写回原数组 $i = $l; foreach ($arrResult as $v) { $arr[$i] = $v; $i++; } } ","date":"2018-12-07","objectID":"/%E7%AE%97%E6%B3%95-%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/:1:0","tags":["算法","学习笔记"],"title":"算法:归并排序","uri":"/%E7%AE%97%E6%B3%95-%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/"},{"categories":["算法学习笔记"],"content":"执行结果 当前在执行0 ~ 7的排序 当前在执行0 ~ 3的排序 当前在执行0 ~ 1的排序 当前在执行0 ~ 0的排序 当前到达一个叶节点 0 当前在执行1 ~ 1的排序 当前到达一个叶节点 1 开始合并0~0和1~1 合并结果[8,11] 当前在执行2 ~ 3的排序 当前在执行2 ~ 2的排序 当前到达一个叶节点 2 当前在执行3 ~ 3的排序 当前到达一个叶节点 3 开始合并2~2和3~3 合并结果[3,9] 开始合并0~1和2~3 合并结果[3,8,9,11] 当前在执行4 ~ 7的排序 当前在执行4 ~ 5的排序 当前在执行4 ~ 4的排序 当前到达一个叶节点 4 当前在执行5 ~ 5的排序 当前到达一个叶节点 5 开始合并4~4和5~5 合并结果[1,7] 当前在执行6 ~ 7的排序 当前在执行6 ~ 6的排序 当前到达一个叶节点 6 当前在执行7 ~ 7的排序 当前到达一个叶节点 7 开始合并6~6和7~7 合并结果[2,5] 开始合并4~5和6~7 合并结果[1,2,5,7] 开始合并0~3和4~7 合并结果[1,2,3,5,7,8,9,11] ","date":"2018-12-07","objectID":"/%E7%AE%97%E6%B3%95-%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/:2:0","tags":["算法","学习笔记"],"title":"算法:归并排序","uri":"/%E7%AE%97%E6%B3%95-%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/"},{"categories":["算法学习笔记"],"content":"是否原地排序? 三个排序算法都只需要开辟常数级的内存空间用于存储一些临时变量,所以三者都是原地排序算法 是否稳定排序？ 什么是稳定排序？排序前后大小相同的两个值的先后顺序不变 除了选择排序的特性决定了它不是稳定排序，因为它有序序列右侧的元素会被从未排序区间里选出的最小值交换，所以无法保证稳定 效率 三者的最坏和平均时间复杂度都是O(n^2) 最好情况时间复杂度冒泡和插入排序均为O(n)，因为它们在整个数组有序的情况下会提前终止循环 选择排序的最好时间复杂度也是O(n^2),因为它没有提前终止排序的条件，任何情况下都会执行完整的排序算法 哪个更受欢迎? ","date":"2018-12-02","objectID":"/%E7%AE%97%E6%B3%95-%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F-%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F-%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F%E5%AF%B9%E6%AF%94/:0:0","tags":["算法","学习笔记"],"title":"算法:冒泡排序/插入排序/选择排序对比","uri":"/%E7%AE%97%E6%B3%95-%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F-%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F-%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F%E5%AF%B9%E6%AF%94/"},{"categories":["算法学习笔记"],"content":"原地排序\u0026效率 因为选择排序不是原地排序，最好情况时间复杂度也偏高，所以先放弃它。 冒泡排序和插入排序孰优孰劣呢？因为冒泡排序的交换操作需要三次赋值，而插入排序的交换操作只需要一次，所以插入排序更受欢迎。 ","date":"2018-12-02","objectID":"/%E7%AE%97%E6%B3%95-%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F-%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F-%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F%E5%AF%B9%E6%AF%94/:1:0","tags":["算法","学习笔记"],"title":"算法:冒泡排序/插入排序/选择排序对比","uri":"/%E7%AE%97%E6%B3%95-%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F-%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F-%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F%E5%AF%B9%E6%AF%94/"},{"categories":["算法学习笔记"],"content":"基本原理 把数组分为已排序序列和未排序序列,每次选择都从未排序序列中选出最小的,放到已排序序列尾部,直至整个 数组都成为已排序序列。 代码 \u003c?php $arr = [1, 4, 6, 2, 6, 3]; print_r(selectSort($arr)); /** * 选择排序:把数组分为已排序序列和未排序序列,每次选择都从未排序序列中选出最小的,放到已排序序列尾部,直至整个数组都成为已排序序列 * @param array $arr * @return array $arr 有序序列 */ function selectSort($arr) { $i = 0; //$i左侧的是已排序的区间 for ($i = 0; $i \u003c count($arr); $i++) { $min = $i; echo \"当前{$i}位置左侧的序列有序,准备选择一个值和{$i}:{$arr[$i]}交换\" . PHP_EOL; for ($j = $i; $j \u003c count($arr); $j++) { echo \"选择中... 当前最小值为{$min}:{$arr[$min]}; 正在对比{$j}:{$arr[$j]}\" . PHP_EOL; if ($arr[$min] \u003e $arr[$j]) { $min = $j; } } echo \"选择无序序列中的$min:{$arr[$min]}为最小值,与{$i}位置交换\\n\"; //交换min和$i,即把min移到了已排序队列右侧 swap($arr, $i, $min); } return $arr; } /** * 交换操作,把数组中下标为$i和$j的数据换位置 * @param array $arr * @param integer $i * @param integer $j */ function swap(\u0026$arr, $i, $j) { $temp = $arr[$i]; $arr[$i] = $arr[$j]; $arr[$j] = $temp; } 执行结果 当前0位置左侧的序列有序,准备选择一个值和0:1交换 选择中... 当前最小值为0:1; 正在对比0:1 选择中... 当前最小值为0:1; 正在对比1:4 选择中... 当前最小值为0:1; 正在对比2:6 选择中... 当前最小值为0:1; 正在对比3:2 选择中... 当前最小值为0:1; 正在对比4:6 选择中... 当前最小值为0:1; 正在对比5:3 选择无序序列中的0:1为最小值,与0位置交换 当前1位置左侧的序列有序,准备选择一个值和1:4交换 选择中... 当前最小值为1:4; 正在对比1:4 选择中... 当前最小值为1:4; 正在对比2:6 选择中... 当前最小值为1:4; 正在对比3:2 选择中... 当前最小值为3:2; 正在对比4:6 选择中... 当前最小值为3:2; 正在对比5:3 选择无序序列中的3:2为最小值,与1位置交换 当前2位置左侧的序列有序,准备选择一个值和2:6交换 选择中... 当前最小值为2:6; 正在对比2:6 选择中... 当前最小值为2:6; 正在对比3:4 选择中... 当前最小值为3:4; 正在对比4:6 选择中... 当前最小值为3:4; 正在对比5:3 选择无序序列中的5:3为最小值,与2位置交换 当前3位置左侧的序列有序,准备选择一个值和3:4交换 选择中... 当前最小值为3:4; 正在对比3:4 选择中... 当前最小值为3:4; 正在对比4:6 选择中... 当前最小值为3:4; 正在对比5:6 选择无序序列中的3:4为最小值,与3位置交换 当前4位置左侧的序列有序,准备选择一个值和4:6交换 选择中... 当前最小值为4:6; 正在对比4:6 选择中... 当前最小值为4:6; 正在对比5:6 选择无序序列中的4:6为最小值,与4位置交换 当前5位置左侧的序列有序,准备选择一个值和5:6交换 选择中... 当前最小值为5:6; 正在对比5:6 选择无序序列中的5:6为最小值,与5位置交换 ","date":"2018-12-02","objectID":"/%E7%AE%97%E6%B3%95-%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F/:0:0","tags":["算法","学习笔记"],"title":"算法:选择排序","uri":"/%E7%AE%97%E6%B3%95-%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F/"},{"categories":["Yii2"],"content":"增 $customer = new Customer(); $customer-\u003ename = 'Qiang'; $customer-\u003esave(); 删 $customer = Customer::findOne(123); $customer-\u003edelete(); Customer::deleteAll(['status' =\u003e Customer::STATUS_INACTIVE]); 改 $customer = Customer::findOne(123); $customer-\u003eemail = 'james@newexample.com'; $customer-\u003esave(); Customer::updateAll(['status' =\u003e Customer::STATUS_ACTIVE], ['like', 'email', '@example.com']); 查 $customer = Customer::find() -\u003ewhere(['like', 'remark', 'test']) -\u003eone(); $customers = Customer::find() -\u003ewhere(['status' =\u003e Customer::STATUS_ACTIVE]) -\u003eorderBy('id') -\u003eall(); $customer = Customer::findOne(123); $customers = Customer::findAll([100, 101, 123, 124]); ","date":"2018-11-26","objectID":"/yii2-%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5/:0:0","tags":["Yii2","学习笔记","PHP"],"title":"YII2 增删改查","uri":"/yii2-%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5/"},{"categories":["Yii2"],"content":"查询指定列的数组 User::find()-\u003eselect('name,id')-\u003ecolumn(); //column()会返回第一个列的数组,这行代码将会返回由每一行的列组成的数组['bob', 'lily'] ","date":"2018-11-26","objectID":"/yii2-%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5/:1:0","tags":["Yii2","学习笔记","PHP"],"title":"YII2 增删改查","uri":"/yii2-%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5/"},{"categories":["算法学习笔记"],"content":"基本原理 把数据分成两个区间,已排序区间和未排序区间,每次遍历从未排序区间取出一个元素,插入到左侧已排序区间中的合适位置,遍历n次后数据有序 主要难点 如果对于插入排序的原理理解不透彻，循环的时候比较难处理 代码 \u003c?php $arr = [4, 5, 6, 1, 3, 2]; $arr = insertSort($arr); print_r($arr); /** * 插入排序 * 把数据分成两个区间,已排序区间和未排序区间,每次遍历从未排序区间取出一个元素,插入到左侧已排序区间中的合适位置,遍历n次,数据有序 * @param array $arr * @return array $arr */ function insertSort($arr) { $n = count($arr); for ($i = 0; $i \u003c $n - 1; $i++) { //$i表示已排序区间的最后一个元素的下标,该元素的右侧为未排序区间 //$arr[$i+1]待插入,在0~i中选择一个位置插入到该位置之前 for ($j = 0; $j \u003c= $i; $j++) { if ($arr[$i+1] \u003c $arr[$j]) { //i+1插入到j之前 insert($arr, $j, $i+1); break; } } } return $arr; } /** * 把数组中j位置的数据插入到i位置之前 * @param array $arr * @param integer $i * @param integer $j * @rertun void */ function insert(\u0026$arr, $i, $j) { echo 'insert:' . $j . '=\u003e' . $i . PHP_EOL; $temp = $arr[$j]; for ($k = $j; $k \u003e $i; $k--) { $arr[$k] = $arr[$k-1]; } $arr[$i] = $temp; } 执行结果 insert:3=\u003e0 insert:4=\u003e1 insert:5=\u003e1 Array ( [0] =\u003e 4 [1] =\u003e 5 [2] =\u003e 6 [3] =\u003e 1 [4] =\u003e 3 [5] =\u003e 2 ) 优化思路 当前代码选择插入位置时，j是从0移动到i的，这样找到插入位置以后，还需要把插入位置到i的元素依次后移，代码比较复杂。 一个解决办法就是j从i移动到0，如果arr[i+1]比arr[j]大，则直接后移。 这样优化以后，每次选择插入位置并插入的遍历数量会少一些。 优化后代码 \u003c?php $arr = [4, 5, 6, 1, 3, 2]; $arr = insertSort($arr); print_r($arr); /** * 插入排序 * 把数据分成两个区间,已排序区间和未排序区间,每次遍历从未排序区间取出一个元素,插入到左侧已排序区间中的合适位置,遍历n次,数据有序 * @param array $arr * @return array $arr */ function insertSort($arr) { $n = count($arr); for ($i = 0; $i \u003c $n - 1; $i++) { //$i的取值范围是0~n-2;因为当0~n-1都有序时,0~n-2也一定是有序的,且$i=n-1时无$i+1可比 //$i表示已排序区间的最后一个元素的下标,该元素的右侧为未排序区间 //$arr[$i+1]为目标元素,待插入,需在0~i中选择一个位置插入 $target = $arr[$i+1]; for ($j = $i; $j \u003e= 0; $j--) { echo \"j=\u003e{$j}\" . PHP_EOL; if ($target \u003c $arr[$j]) { //当前元素比目标元素大,需要右移为目标元素让出位置 $arr[$j+1] = $arr[$j]; } else { //当前元素不比目标元素大,不需要继续右移了 break; } } //把目标元素放入正确的位置 $arr[$j+1] = $target; } return $arr; } ","date":"2018-11-23","objectID":"/%E7%AE%97%E6%B3%95-%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F/:0:0","tags":["算法","学习笔记"],"title":"算法:插入排序","uri":"/%E7%AE%97%E6%B3%95-%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F/"},{"categories":["算法学习笔记"],"content":"基本原理 一次冒泡的定义：从左往右遍历一次数组，比较每个元素和它后面元素的大小，如果后面的元素较小则交换两者。 每次冒泡会把一个元素移动到它应该在的位置(例:第一次冒泡会让最大的数据冒泡到最后)，冒泡排序最多执行n次冒泡,能使得所有元素有序 优化过程 ","date":"2018-11-23","objectID":"/%E7%AE%97%E6%B3%95-%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F/:0:0","tags":["算法","学习笔记"],"title":"算法:冒泡排序","uri":"/%E7%AE%97%E6%B3%95-%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F/"},{"categories":["算法学习笔记"],"content":"冒泡遍历元素数量 原：每次冒泡都会遍历所有元素 新：从第二次冒泡开始,遍历的元素逐渐减少(每次冒泡减少一个)；因为每次遍历都会让一个数据到达它应该在的位置,即它的位置在后续的冒泡中不会再发生变化，所以后续的冒泡可以不遍历该元素。 ","date":"2018-11-23","objectID":"/%E7%AE%97%E6%B3%95-%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F/:0:1","tags":["算法","学习笔记"],"title":"算法:冒泡排序","uri":"/%E7%AE%97%E6%B3%95-%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F/"},{"categories":["算法学习笔记"],"content":"数据本身不是完全逆序,可能不需要完成所有的冒泡 增加标志位$flag，如果上一次冒泡没有发生交换，则表名数据已经有序,不再进行冒泡，直接返回。 代码 \u003c?php $arr = [4, 5, 6, 3, 2, 1]; puppleSort($arr); /** * 冒泡排序 * 一次冒泡的定义:从左往右遍历一次数组,比较每个元素和它后面元素的大小,如果后面的元素较小,则交换两者 * 每次冒泡会把一个元素移动到它应该在的位置,最多执行n次冒泡,所有元素有序 * @param array $arr * @return array $arr 有序数组 */ function puppleSort($arr) { $n = count($arr); $flag = true; for ($i = $n - 1; $i \u003e 0; $i--) { //每次需要比较的元素都在变少,每次冒泡需要遍历从0到$i,比较每个元素与后者的大小 $flag = false; for ($j = 0; $j \u003c $i; $j++) { //遍历从0到$i,看相邻的两个元素是否需要交换 if ($arr[$j] \u003e $arr[$j+1]) { $flag = true; swap($arr, $j, $j+1); } } if (!$flag) { break; } echo '本次冒泡使得下标' . $i . '位的数据准确:'; echo implode(',', $arr) . PHP_EOL; } return $arr; } /** * 交换操作,把数组中下标为$i和$j的数据换位置 * @param array $arr * @param integer $i * @param integer $j */ function swap(\u0026$arr, $i, $j) { $temp = $arr[$i]; $arr[$i] = $arr[$j]; $arr[$j] = $temp; } 执行结果 本次冒泡使得下标5位的数据正确:4,5,3,2,1,6 本次冒泡使得下标4位的数据正确:4,3,2,1,5,6 本次冒泡使得下标3位的数据正确:3,2,1,4,5,6 本次冒泡使得下标2位的数据正确:2,1,3,4,5,6 本次冒泡使得下标1位的数据正确:1,2,3,4,5,6 ","date":"2018-11-23","objectID":"/%E7%AE%97%E6%B3%95-%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F/:0:2","tags":["算法","学习笔记"],"title":"算法:冒泡排序","uri":"/%E7%AE%97%E6%B3%95-%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F/"},{"categories":null,"content":"如何优雅地把数组输出为可运行的php数组声明1 print_r输出的声明代码太老了，是php5.6以前的样子(array关键字) 那么如何把数组优雅地输出成可运行的数组声明代码呐，看下面 把数组转成json，然后把json中的{ } : 分别替换成 [ ] =\u003e 只要数组中没有{}:这样的字符，就能顺利替换成php数组的声明代码啦 str_replace(['{', '}', ':', '\"'], ['[', ']', '=\u003e', '\\''], json_encode($data, JSON_PRETTY_PRINT)) 最后吐个槽，php官方能不能把print_r加个参数，像json_decode一样支持最新的数组声明方式~ 批量更新数据表内容 最近在用yii2做开发,所以执行sql的命令是yii2的，主要参考sql语句。下述代码的内容是删除废弃的时间戳字段，增加新的 \u003c?php //获取所有表 $tables = Yii::$app-\u003edb-\u003ecreateCommand(\"select table_name from information_schema.tables where table_schema='sample_platform_new' and table_type='base table'\")-\u003equeryAll(); foreach ($tables as $table) { //获取表中的所有字段 $columns = Yii::$app-\u003edb-\u003ecreateCommand(\"select COLUMN_NAME from information_schema.COLUMNS where table_name = '{$table['table_name']}'\")-\u003equeryAll(); foreach ($columns as $column) { if (in_array($column['COLUMN_NAME'], ['updatetime', 'createtime', 'update_time', 'create_time', 'created_at', 'updated_at'])) { //如果有updatetime/createtime update_time/create_time 删除 Yii::$app-\u003edb-\u003ecreateCommand(\"alter table {$table['table_name']} drop column {$column['COLUMN_NAME']}\")-\u003eexecute(); } } //增加created_at / updated_at字段 Yii::$app-\u003edb-\u003ecreateCommand(\"alter table {$table['table_name']} add created_at int default 0\")-\u003eexecute(); Yii::$app-\u003edb-\u003ecreateCommand(\"alter table {$table['table_name']} modify column created_at int comment '创建时间'\")-\u003eexecute(); Yii::$app-\u003edb-\u003ecreateCommand(\"alter table {$table['table_name']} add updated_at int default 0\")-\u003eexecute(); Yii::$app-\u003edb-\u003ecreateCommand(\"alter table {$table['table_name']} modify column updated_at int comment '更新时间'\")-\u003eexecute(); } 打印调用栈 \u003c?php $stack = debug_backtrace(); unset($stack[0]); $html = ''; foreach($stack as $row) { $html .=$row['file'].':'.$row['line'].'行,调用方法:'.$row['function'].\"\u003cp\u003e\"; } echo $html; 按照自己想要的格式打印mysql表的列 SELECT GROUP_CONCAT(COLUMN_NAME SEPARATOR \",\") FROM information_schema.COLUMNS WHERE TABLE_SCHEMA = 'db_name' AND TABLE_NAME = 'table_name' 显示所有错误信息 error_reporting(E_ALL); ini_set('display_errors', 'On'); apache和nginx 区别 getallheaders只在apache下才支持 nginx需要用此方式规避 if (!function_exists('getallheaders')) { function getallheaders() { $headers = array(); foreach ($_SERVER as $name =\u003e $value) { if (substr($name, 0, 5) == 'HTTP_') { $headers[str_replace(' ', '-', ucwords(strtolower(str_replace('_', ' ', substr($name, 5)))))] = $value; } } return $headers; } } ","date":"2018-11-14","objectID":"/php%E5%B0%8F%E8%81%AA%E6%98%8E/:0:0","tags":["PHP"],"title":"PHP小聪明","uri":"/php%E5%B0%8F%E8%81%AA%E6%98%8E/"},{"categories":["Laravel"],"content":"本文记录一些文档中描述可能不够清晰，但是开发过程中需要用到的内容 ","date":"2018-11-08","objectID":"/laravel%E5%A4%87%E6%B3%A8/:0:0","tags":["Laravel","PHP"],"title":"Laravel备注","uri":"/laravel%E5%A4%87%E6%B3%A8/"},{"categories":["Laravel"],"content":"resource方法 Route::resource('users', 'UsersController'); 上述代码将等同于：（当需要生成url时，可参考下述name） Route::get('/users', 'UsersController@index')-\u003ename('users.index'); Route::get('/users/{user}', 'UsersController@show')-\u003ename('users.show'); Route::get('/users/create', 'UsersController@create')-\u003ename('users.create'); Route::post('/users', 'UsersController@store')-\u003ename('users.store'); Route::get('/users/{user}/edit', 'UsersController@edit')-\u003ename('users.edit'); Route::patch('/users/{user}', 'UsersController@update')-\u003ename('users.update'); Route::delete('/users/{user}', 'UsersController@destroy')-\u003ename('users.destroy'); ","date":"2018-11-08","objectID":"/laravel%E5%A4%87%E6%B3%A8/:1:0","tags":["Laravel","PHP"],"title":"Laravel备注","uri":"/laravel%E5%A4%87%E6%B3%A8/"},{"categories":["Laravel"],"content":"修改$request参数 $request-\u003emerge(['foo' =\u003e 'bar', ....]); $request-\u003ereplace([..])// 替换所有输入 $request['foo'] = 'bar'; unset($request['foo']) // 移除某参数 $request-\u003eoffsetSet(key,value); $request-\u003eattritube-\u003eset($key, $value) 上述操作方式对于普通内容都有效，但是对于file类型的参数无效 ","date":"2018-11-08","objectID":"/laravel%E5%A4%87%E6%B3%A8/:2:0","tags":["Laravel","PHP"],"title":"Laravel备注","uri":"/laravel%E5%A4%87%E6%B3%A8/"},{"categories":["Laravel"],"content":"本文记录Laravel开发过程中遇到的问题以及最佳实践方法和参考来源，不定期更新 ","date":"2018-11-06","objectID":"/laravel%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/:0:0","tags":["Laravel","PHP"],"title":"Laravel最佳实践","uri":"/laravel%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/"},{"categories":["Laravel"],"content":"配置书写方式 存储在 .env 和 config/app.php 文件中，然后使用 config() 函数来读取。 .env CDN_DOMAIN=cdndomain.com config/app.php ‘cdn_domain’ =\u003e env(‘CDN_DOMAIN’, null), 程序读取方式 config(‘app.cdn_domain’) 参考：https://laravel-china.org/docs/laravel-specification/5.5/configuration-information-and-environment-variables/514 ","date":"2018-11-06","objectID":"/laravel%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/:0:1","tags":["Laravel","PHP"],"title":"Laravel最佳实践","uri":"/laravel%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/"},{"categories":["Laravel"],"content":"一次请求的基本流程 index.php 加载composer生成的自动加载配置 * 从bootstrap/app.php脚本中检索Laravel应用实例 HTTP/Console内核 初始化：配置错误处理、日志、检测环境 * 定义中间件 * 注册ServiceProvider * 请求调度：把请求传递给路由，由路由或路由中定义的控制器处理请求 如上所述，laravel通过ServiceProvider把独立插件注册到核心架构上，供后续服务调用。 Contracts, ServiceContainer, ServiceProvider, Facades Contracts：接口，定义一些规则，每个实现此接口的都要实现里面的方法 ServiceContainer：Contracts具体的逻辑实现 ServiceProvider：ServiceContainer的服务提供者，返回ServiceContainer的实例化供其他地方使用。上文中提到的注册ServiceProvider就是调用方式。 Facades：简化ServiceProvider的调用方式，而且可以静态调用ServiceContainer中的方法 ","date":"2018-11-06","objectID":"/laravel%E6%A0%B8%E5%BF%83%E6%9E%B6%E6%9E%84%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5%E7%90%86%E8%A7%A3/:0:0","tags":["Laravel","PHP"],"title":"Laravel核心架构相关概念理解","uri":"/laravel%E6%A0%B8%E5%BF%83%E6%9E%B6%E6%9E%84%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5%E7%90%86%E8%A7%A3/"},{"categories":["Laravel"],"content":"Contracts 定义接口 namespace App\\Contracts; interface MyFooContracts { public function add($a, $b) } ","date":"2018-11-06","objectID":"/laravel%E6%A0%B8%E5%BF%83%E6%9E%B6%E6%9E%84%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5%E7%90%86%E8%A7%A3/:1:0","tags":["Laravel","PHP"],"title":"Laravel核心架构相关概念理解","uri":"/laravel%E6%A0%B8%E5%BF%83%E6%9E%B6%E6%9E%84%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5%E7%90%86%E8%A7%A3/"},{"categories":["Laravel"],"content":"ServiceContainer ServiceContainer是一个Contracts的实现，提供真正的服务 use App\\Helper\\Contracts\\MyFooContracts; namespace App\\Helper; class MyFoo implements MyFoo{ public function add($a, $b) { return $a+$b; } } ","date":"2018-11-06","objectID":"/laravel%E6%A0%B8%E5%BF%83%E6%9E%B6%E6%9E%84%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5%E7%90%86%E8%A7%A3/:2:0","tags":["Laravel","PHP"],"title":"Laravel核心架构相关概念理解","uri":"/laravel%E6%A0%B8%E5%BF%83%E6%9E%B6%E6%9E%84%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5%E7%90%86%E8%A7%A3/"},{"categories":["Laravel"],"content":"ServiceProvider 定义一个ServiceProvider供其他地方使用ServiceContainer 本质是把ServiceContainer的服务包装起来，并提供一些接口如register()，供调用者无差别的调用不同的ServiceContainer \u003c?php namespace App\\Providers; use App\\Helper\\MyFoo; //要服务的Container use Illuminate\\Support\\ServiceProvider; use App; class MyFooServiceProvider extends ServiceProvider { public function boot(){} //注册到容器中 public function register() { //可以这么绑定,这需要use App; App::bind(\"myfoo\",function(){ return new MyFoo(); }); //也可以这么绑定 $this-\u003eapp-\u003ebind(\"myfoo\", function(){ return new MyFoo(); }); } } 如果要让laravel调用这个Service，需要在app/config.php中的providers数组中加入ServiceProvider,让系统自动注册 App\\Providers\\MyFooServiceProvider::class, ","date":"2018-11-06","objectID":"/laravel%E6%A0%B8%E5%BF%83%E6%9E%B6%E6%9E%84%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5%E7%90%86%E8%A7%A3/:3:0","tags":["Laravel","PHP"],"title":"Laravel核心架构相关概念理解","uri":"/laravel%E6%A0%B8%E5%BF%83%E6%9E%B6%E6%9E%84%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5%E7%90%86%E8%A7%A3/"},{"categories":["Laravel"],"content":"在Controller中调用 public function two($id=null) { //从系统容器中获取实例化对象 $myfoo = App::make(\"myfoo\"); echo $myfoo-\u003eadd(1,2); } ","date":"2018-11-06","objectID":"/laravel%E6%A0%B8%E5%BF%83%E6%9E%B6%E6%9E%84%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5%E7%90%86%E8%A7%A3/:3:1","tags":["Laravel","PHP"],"title":"Laravel核心架构相关概念理解","uri":"/laravel%E6%A0%B8%E5%BF%83%E6%9E%B6%E6%9E%84%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5%E7%90%86%E8%A7%A3/"},{"categories":["Laravel"],"content":"Facades 上述调用方法太麻烦，需要make来获取对象，为了简便，定义Facades namespace App\\Facades; use Illuminate\\Support\\Facades\\Facade; class MyFooFacade extends Facade { protected static function getFacadeAccessor() { //这里返回的是ServiceProvider中注册时,定义的字符串 return 'myfoo'; } } ","date":"2018-11-06","objectID":"/laravel%E6%A0%B8%E5%BF%83%E6%9E%B6%E6%9E%84%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5%E7%90%86%E8%A7%A3/:4:0","tags":["Laravel","PHP"],"title":"Laravel核心架构相关概念理解","uri":"/laravel%E6%A0%B8%E5%BF%83%E6%9E%B6%E6%9E%84%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5%E7%90%86%E8%A7%A3/"},{"categories":["Laravel"],"content":"使用Facades调用 use App\\Facades\\MyFooFacade; public function two($id=null) { //从系统容器中获取实例化对象 $myfoo = App::make(\"myfoo\"); echo $myfoo-\u003eadd(1,2); //使用门面 echo MyFooFacade::add(4,5); } 综上：Contracts, ServiceContainer, ServiceProvider, Facades中，真正有用的只有ServiceContainer；Contracts是为了低耦合定义的接口；ServiceProvider是为了方便其他位置无差别的注册不同的ServiceContainer；Facades是为了更方便的调用ServiceContainer 参考\u0026感谢：https://www.cnblogs.com/hanyouchun/p/5341264.html ","date":"2018-11-06","objectID":"/laravel%E6%A0%B8%E5%BF%83%E6%9E%B6%E6%9E%84%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5%E7%90%86%E8%A7%A3/:4:1","tags":["Laravel","PHP"],"title":"Laravel核心架构相关概念理解","uri":"/laravel%E6%A0%B8%E5%BF%83%E6%9E%B6%E6%9E%84%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5%E7%90%86%E8%A7%A3/"},{"categories":["架构学习笔记"],"content":" 本节并不太理解，暂放;后续如果有机会学习nginx原理时再详细了解 Reactor ","date":"2018-11-05","objectID":"/19-%E5%8D%95%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E6%80%A7%E8%83%BD%E6%A8%A1%E5%BC%8Freactor%E4%B8%8Eproactor/:0:0","tags":["架构","学习笔记"],"title":"19.单服务器高性能模式：Reactor与Proactor","uri":"/19-%E5%8D%95%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E6%80%A7%E8%83%BD%E6%A8%A1%E5%BC%8Freactor%E4%B8%8Eproactor/"},{"categories":["架构学习笔记"],"content":"资源复用 PPC和TPC和核心问题是每个连接都要创建进程/线程，连接结束后就销毁了，这样很浪费资源。为了解决这个问题，一个自然而然的想法就是资源复用，创建一个进程池，一个进程可以处理多个连接。 ","date":"2018-11-05","objectID":"/19-%E5%8D%95%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E6%80%A7%E8%83%BD%E6%A8%A1%E5%BC%8Freactor%E4%B8%8Eproactor/:1:0","tags":["架构","学习笔记"],"title":"19.单服务器高性能模式：Reactor与Proactor","uri":"/19-%E5%8D%95%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E6%80%A7%E8%83%BD%E6%A8%A1%E5%BC%8Freactor%E4%B8%8Eproactor/"},{"categories":["架构学习笔记"],"content":"如何高效处理多个连接 常规的read-\u003e业务处理-\u003ewrite ：进程阻塞在read上，无法处理多个请求 read非常阻塞，进程轮询连接：轮询不优雅，消耗cpu I/O多路复用，只有当连接上有数据的时候进程才去处理 ","date":"2018-11-05","objectID":"/19-%E5%8D%95%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E6%80%A7%E8%83%BD%E6%A8%A1%E5%BC%8Freactor%E4%B8%8Eproactor/:2:0","tags":["架构","学习笔记"],"title":"19.单服务器高性能模式：Reactor与Proactor","uri":"/19-%E5%8D%95%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E6%80%A7%E8%83%BD%E6%A8%A1%E5%BC%8Freactor%E4%B8%8Eproactor/"},{"categories":["架构学习笔记"],"content":"I/O多路复用两个关键点 当多条连接共用一个阻塞对象后，进程只需要在一个阻塞对象上等待，无须再轮询所有连接 当某条连接有新的数据可以处理时，操作系统会通知进程，进程从阻塞状态返回，开始进行业务处理 ","date":"2018-11-05","objectID":"/19-%E5%8D%95%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E6%80%A7%E8%83%BD%E6%A8%A1%E5%BC%8Freactor%E4%B8%8Eproactor/:3:0","tags":["架构","学习笔记"],"title":"19.单服务器高性能模式：Reactor与Proactor","uri":"/19-%E5%8D%95%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E6%80%A7%E8%83%BD%E6%A8%A1%E5%BC%8Freactor%E4%B8%8Eproactor/"},{"categories":["架构学习笔记"],"content":"Reactor/Dispatcher模式 Reactor监听和分配事件 处理资源池负责处理事件 ","date":"2018-11-05","objectID":"/19-%E5%8D%95%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E6%80%A7%E8%83%BD%E6%A8%A1%E5%BC%8Freactor%E4%B8%8Eproactor/:4:0","tags":["架构","学习笔记"],"title":"19.单服务器高性能模式：Reactor与Proactor","uri":"/19-%E5%8D%95%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E6%80%A7%E8%83%BD%E6%A8%A1%E5%BC%8Freactor%E4%B8%8Eproactor/"},{"categories":["架构学习笔记"],"content":"复杂度可能的来源 Reactor的数量可变：单个、多个 资源池的数量可变：单进程、多进程 上述情况排列组合后会有四中选择，但是由多Reactor单进程很鸡肋，所以只有如下三种典型方案 ","date":"2018-11-05","objectID":"/19-%E5%8D%95%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E6%80%A7%E8%83%BD%E6%A8%A1%E5%BC%8Freactor%E4%B8%8Eproactor/:5:0","tags":["架构","学习笔记"],"title":"19.单服务器高性能模式：Reactor与Proactor","uri":"/19-%E5%8D%95%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E6%80%A7%E8%83%BD%E6%A8%A1%E5%BC%8Freactor%E4%B8%8Eproactor/"},{"categories":["架构学习笔记"],"content":"Reactor的可选方案 单Reactor 单进程/线程 单Reactor 多线程 多Reactor 多进程/线程 Proactor 异步I/O ","date":"2018-11-05","objectID":"/19-%E5%8D%95%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E6%80%A7%E8%83%BD%E6%A8%A1%E5%BC%8Freactor%E4%B8%8Eproactor/:6:0","tags":["架构","学习笔记"],"title":"19.单服务器高性能模式：Reactor与Proactor","uri":"/19-%E5%8D%95%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E6%80%A7%E8%83%BD%E6%A8%A1%E5%BC%8Freactor%E4%B8%8Eproactor/"},{"categories":["架构学习笔记"],"content":"服务器高性能的关键之一就是服务器采取的并发模型，并发模型有如下两个关键设计点： 服务器如何管理连接 服务器如何处理请求 以上两个设计点最终都和操作系统的I/O模型及进程模型相关： I/O模型：阻塞、非阻塞、同步、异步 进程模型：单进程、多进程、多线程 PPC:Process Per Connection 每次有新的链接就新建一个进程去专门处理这个连接的请求。 ","date":"2018-11-05","objectID":"/18-%E5%8D%95%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E6%80%A7%E8%83%BD%E6%A8%A1%E5%BC%8Fppc%E4%B8%8Etpc/:0:0","tags":["架构","学习笔记"],"title":"18.单服务器高性能模式：PPC与TPC","uri":"/18-%E5%8D%95%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E6%80%A7%E8%83%BD%E6%A8%A1%E5%BC%8Fppc%E4%B8%8Etpc/"},{"categories":["架构学习笔记"],"content":"优势 实现简单 ","date":"2018-11-05","objectID":"/18-%E5%8D%95%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E6%80%A7%E8%83%BD%E6%A8%A1%E5%BC%8Fppc%E4%B8%8Etpc/:1:0","tags":["架构","学习笔记"],"title":"18.单服务器高性能模式：PPC与TPC","uri":"/18-%E5%8D%95%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E6%80%A7%E8%83%BD%E6%A8%A1%E5%BC%8Fppc%E4%B8%8Etpc/"},{"categories":["架构学习笔记"],"content":"问题 fork代价高 父子进程通信复杂 支持的并发连接数量有限 ","date":"2018-11-05","objectID":"/18-%E5%8D%95%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E6%80%A7%E8%83%BD%E6%A8%A1%E5%BC%8Fppc%E4%B8%8Etpc/:2:0","tags":["架构","学习笔记"],"title":"18.单服务器高性能模式：PPC与TPC","uri":"/18-%E5%8D%95%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E6%80%A7%E8%83%BD%E6%A8%A1%E5%BC%8Fppc%E4%B8%8Etpc/"},{"categories":["架构学习笔记"],"content":"prefork 提前创建进程 TPC:Thread Per Connection 每次有新的连接就新建一个专门的线程去专门处理这个连接的请求。 ","date":"2018-11-05","objectID":"/18-%E5%8D%95%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E6%80%A7%E8%83%BD%E6%A8%A1%E5%BC%8Fppc%E4%B8%8Etpc/:3:0","tags":["架构","学习笔记"],"title":"18.单服务器高性能模式：PPC与TPC","uri":"/18-%E5%8D%95%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E6%80%A7%E8%83%BD%E6%A8%A1%E5%BC%8Fppc%E4%B8%8Etpc/"},{"categories":["架构学习笔记"],"content":"优势 解决了fork代价高和进程通信复杂的问题 ","date":"2018-11-05","objectID":"/18-%E5%8D%95%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E6%80%A7%E8%83%BD%E6%A8%A1%E5%BC%8Fppc%E4%B8%8Etpc/:4:0","tags":["架构","学习笔记"],"title":"18.单服务器高性能模式：PPC与TPC","uri":"/18-%E5%8D%95%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E6%80%A7%E8%83%BD%E6%A8%A1%E5%BC%8Fppc%E4%B8%8Etpc/"},{"categories":["架构学习笔记"],"content":"问题 创建线程依然有代价，高并发时还是有性能问题 无需进程间通信，但是线程间的互斥和共享又引入了复杂度 多线程会互相影响，某个线程出现异常时，可能导致整个进程退出 除了引入新的问题，TPC还存在CPU线程调度和切换代价的问题，因此，TPC本质上和PPC类似，在并发几百的场景下，反而更多地是采用PPC方案，因为PPC方案不会有死锁的风险，也不会有多进程互相影响，稳定性更高。 ","date":"2018-11-05","objectID":"/18-%E5%8D%95%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E6%80%A7%E8%83%BD%E6%A8%A1%E5%BC%8Fppc%E4%B8%8Etpc/:5:0","tags":["架构","学习笔记"],"title":"18.单服务器高性能模式：PPC与TPC","uri":"/18-%E5%8D%95%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E6%80%A7%E8%83%BD%E6%A8%A1%E5%BC%8Fppc%E4%B8%8Etpc/"},{"categories":["架构学习笔记"],"content":"prethread 提前创建线程 ","date":"2018-11-05","objectID":"/18-%E5%8D%95%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E6%80%A7%E8%83%BD%E6%A8%A1%E5%BC%8Fppc%E4%B8%8Etpc/:6:0","tags":["架构","学习笔记"],"title":"18.单服务器高性能模式：PPC与TPC","uri":"/18-%E5%8D%95%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E6%80%A7%E8%83%BD%E6%A8%A1%E5%BC%8Fppc%E4%B8%8Etpc/"},{"categories":["架构学习笔记"],"content":"某些场景下，单纯依靠存储性能的提升不能解决问题 这些场景下高性能存储也无能为力，这就需要用到缓存系统 需要经过复杂的运算后得出的数据 读多写少的数据 缓存的架构设计要点 ","date":"2018-11-05","objectID":"/17-%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%93%E5%AD%98%E6%9E%B6%E6%9E%84/:0:0","tags":["架构","学习笔记"],"title":"17.高性能缓存架构","uri":"/17-%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%93%E5%AD%98%E6%9E%B6%E6%9E%84/"},{"categories":["架构学习笔记"],"content":"缓存穿透 ","date":"2018-11-05","objectID":"/17-%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%93%E5%AD%98%E6%9E%B6%E6%9E%84/:1:0","tags":["架构","学习笔记"],"title":"17.高性能缓存架构","uri":"/17-%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%93%E5%AD%98%E6%9E%B6%E6%9E%84/"},{"categories":["架构学习笔记"],"content":"存储数据不存在 可能被黑客利用做攻击，解决办法是当读不存在值的时，设置一个默认值到缓存中。 ","date":"2018-11-05","objectID":"/17-%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%93%E5%AD%98%E6%9E%B6%E6%9E%84/:1:1","tags":["架构","学习笔记"],"title":"17.高性能缓存架构","uri":"/17-%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%93%E5%AD%98%E6%9E%B6%E6%9E%84/"},{"categories":["架构学习笔记"],"content":"缓存数据生成耗费大量时间或资源 比如分页缓存，前10页失效的可能性不大，因为用户会一直有大量读取请求；但是后面也没的内容可能失效，日常请求也足够用，但是当爬虫循环请求所有页面时，数据库会被拖慢。 没有太好的解决办法，如果禁止爬虫会影响SEO和推广；做好监控，发现问题后及时处理。 ","date":"2018-11-05","objectID":"/17-%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%93%E5%AD%98%E6%9E%B6%E6%9E%84/:1:2","tags":["架构","学习笔记"],"title":"17.高性能缓存架构","uri":"/17-%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%93%E5%AD%98%E6%9E%B6%E6%9E%84/"},{"categories":["架构学习笔记"],"content":"缓存雪崩 缓存雪崩是指当缓存失效后引起系统性能急剧下降的情况，当多个请求到达时，会请求多次数据库。 ","date":"2018-11-05","objectID":"/17-%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%93%E5%AD%98%E6%9E%B6%E6%9E%84/:2:0","tags":["架构","学习笔记"],"title":"17.高性能缓存架构","uri":"/17-%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%93%E5%AD%98%E6%9E%B6%E6%9E%84/"},{"categories":["架构学习笔记"],"content":"更新锁 对缓存更新操作进行加锁保护，保证只有一个现成能够进行缓存更新。 ","date":"2018-11-05","objectID":"/17-%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%93%E5%AD%98%E6%9E%B6%E6%9E%84/:2:1","tags":["架构","学习笔记"],"title":"17.高性能缓存架构","uri":"/17-%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%93%E5%AD%98%E6%9E%B6%E6%9E%84/"},{"categories":["架构学习笔记"],"content":"后台更新 由后台现成来更新缓存，缓存本身的有效期设置为永久，后台线程定时更新。 特殊场景：当内存不够时，会删除一些数据，这些数据就返回空了 后台频繁读缓存，如果发现数据被删除，就立即更新缓存 业务线程发现缓存失效后，通过消息队列发送一条消息给后台线程更新缓存 √ ","date":"2018-11-05","objectID":"/17-%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%93%E5%AD%98%E6%9E%B6%E6%9E%84/:2:2","tags":["架构","学习笔记"],"title":"17.高性能缓存架构","uri":"/17-%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%93%E5%AD%98%E6%9E%B6%E6%9E%84/"},{"categories":["架构学习笔记"],"content":"缓存热点 设置多副本解决；需要注意，不同的缓存副本不要设置统一的过期时间，否则会引起缓存雪崩 ","date":"2018-11-05","objectID":"/17-%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%93%E5%AD%98%E6%9E%B6%E6%9E%84/:3:0","tags":["架构","学习笔记"],"title":"17.高性能缓存架构","uri":"/17-%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%93%E5%AD%98%E6%9E%B6%E6%9E%84/"},{"categories":["架构学习笔记"],"content":"实现方式 程序代码实现 中间件实现 ","date":"2018-11-05","objectID":"/17-%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%93%E5%AD%98%E6%9E%B6%E6%9E%84/:4:0","tags":["架构","学习笔记"],"title":"17.高性能缓存架构","uri":"/17-%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%93%E5%AD%98%E6%9E%B6%E6%9E%84/"},{"categories":["架构学习笔记"],"content":"关系型数据库的缺点 存储的是行记录，无法存储数据结构 schema扩展很不方便：修改数据库的列很麻烦 在大数据场景下I/O偏高：即使只针对某一列计算，关系型数据库也会把整行数据读入内存 全文搜索功能较弱：like只能进行整表扫描，效率低 常见的NoSQL k-v存储：解决无法存储数据结构的问题，如Redis 文档数据库：解决强schema约束的问题，如MongoDB 列式数据库：解决大数据下I/O高的问题，如HBase 全文搜索引擎：解决全文搜索性能的问题，如Elasticsearch ","date":"2018-11-01","objectID":"/16-%E9%AB%98%E6%80%A7%E8%83%BDnosql/:0:0","tags":["架构","学习笔记"],"title":"16.高性能NoSQL","uri":"/16-%E9%AB%98%E6%80%A7%E8%83%BDnosql/"},{"categories":["架构学习笔记"],"content":"k-v数据库 支持数据结构存储：string、hash、list、set、sroted set、bitmap和hyperloglog 原生支持典型操作 LPOP key 左pop出元素 LINDEX key index 通过索引列表获取一个元素 LLEN key 获取队列长度 RPOP key 从队列的右边出一个元素 问题：事务只能保证隔离性和一致性，无法保证原子性和持久性 ","date":"2018-11-01","objectID":"/16-%E9%AB%98%E6%80%A7%E8%83%BDnosql/:1:0","tags":["架构","学习笔记"],"title":"16.高性能NoSQL","uri":"/16-%E9%AB%98%E6%80%A7%E8%83%BDnosql/"},{"categories":["架构学习笔记"],"content":"文档数据库 新增字段简单：无需修改表结构 历史数据不会出错：新增字段后对原有数据无影响 可以很容易存储复杂数据：通过json存储 问题：不支持事务、无法join ","date":"2018-11-01","objectID":"/16-%E9%AB%98%E6%80%A7%E8%83%BDnosql/:2:0","tags":["架构","学习笔记"],"title":"16.高性能NoSQL","uri":"/16-%E9%AB%98%E6%80%A7%E8%83%BDnosql/"},{"categories":["架构学习笔记"],"content":"列式数据库 同时读取多个列时效率高 能够一次完成对一行中多个列的写操作 ","date":"2018-11-01","objectID":"/16-%E9%AB%98%E6%80%A7%E8%83%BDnosql/:3:0","tags":["架构","学习笔记"],"title":"16.高性能NoSQL","uri":"/16-%E9%AB%98%E6%80%A7%E8%83%BDnosql/"},{"categories":["架构学习笔记"],"content":"全文搜索引擎 原理：倒排索引，建立单词到文档的索引 ","date":"2018-11-01","objectID":"/16-%E9%AB%98%E6%80%A7%E8%83%BDnosql/:4:0","tags":["架构","学习笔记"],"title":"16.高性能NoSQL","uri":"/16-%E9%AB%98%E6%80%A7%E8%83%BDnosql/"},{"categories":["架构学习笔记"],"content":"业务分库 将不同业务的数据分到不同数据库中 ","date":"2018-11-01","objectID":"/15-%E9%AB%98%E6%80%A7%E8%83%BD%E6%95%B0%E6%8D%AE%E5%BA%93%E9%9B%86%E7%BE%A4%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/:0:0","tags":["架构","学习笔记"],"title":"15.高性能数据库集群：分库分表","uri":"/15-%E9%AB%98%E6%80%A7%E8%83%BD%E6%95%B0%E6%8D%AE%E5%BA%93%E9%9B%86%E7%BE%A4%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"},{"categories":["架构学习笔记"],"content":"问题 join操作 事务问题 成本问题 分表 垂直分表 常用和不常用的字段分开 问题：表操作的数量要增加 水平分表 一般五千万开始分表 ","date":"2018-11-01","objectID":"/15-%E9%AB%98%E6%80%A7%E8%83%BD%E6%95%B0%E6%8D%AE%E5%BA%93%E9%9B%86%E7%BE%A4%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/:1:0","tags":["架构","学习笔记"],"title":"15.高性能数据库集群：分库分表","uri":"/15-%E9%AB%98%E6%80%A7%E8%83%BD%E6%95%B0%E6%8D%AE%E5%BA%93%E9%9B%86%E7%BE%A4%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"},{"categories":["架构学习笔记"],"content":"读写分离原理 主从架构，主机读写，从机读取，主机通过复制将数据同步到从机。 复制延迟的解决方案 写操作后的读操作发送给主机：耦合代码 读从机失败后再读一次主机：增加主机压力 关键业务读写主机，非关键业务读从机 分配机制 代码封装 引入中间件 ","date":"2018-11-01","objectID":"/14-%E9%AB%98%E6%80%A7%E8%83%BD%E6%95%B0%E6%8D%AE%E5%BA%93%E9%9B%86%E7%BE%A4%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB/:0:0","tags":["架构","学习笔记"],"title":"14.高性能数据库集群：读写分离","uri":"/14-%E9%AB%98%E6%80%A7%E8%83%BD%E6%95%B0%E6%8D%AE%E5%BA%93%E9%9B%86%E7%BE%A4%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB/"},{"categories":["架构学习笔记"],"content":"识别复杂度 复杂度主要来源于高性能、高可用、扩扩展几个方面，但是大多数场景下，系统只需要其中一个特性。 所以识别业务的复杂度，针对性的解决问题很关键，不要想着满足所有需求。 设计备选方案 设计多个备选方案，以写出与主方案的差异点的方式表明 评估备选方案 360度环评：列出我们需要关注的质量属性点，然后分别从这些质量属性的维度去评估每个方案，再选择最优方案。 详细方案设计 完善技术细节，比如Nginx的负载均衡策略是选择轮询、加权、ip_has还是fair？ ","date":"2018-11-01","objectID":"/10-11-12-13-%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E6%B5%81%E7%A8%8B%E8%AF%86%E5%88%AB%E5%A4%8D%E6%9D%82%E5%BA%A6%E8%AE%BE%E8%AE%A1%E5%A4%87%E9%80%89%E6%96%B9%E6%A1%88%E8%AF%84%E4%BC%B0%E5%92%8C%E9%80%89%E6%8B%A9%E5%A4%87%E9%80%89%E6%96%B9%E6%A1%88%E8%AF%A6%E7%BB%86%E6%96%B9%E6%A1%88%E8%AE%BE%E8%AE%A1/:0:0","tags":["架构","学习笔记"],"title":"10.11.12.13.架构设计流程：识别复杂度、设计备选方案、评估和选择备选方案、详细方案设计","uri":"/10-11-12-13-%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E6%B5%81%E7%A8%8B%E8%AF%86%E5%88%AB%E5%A4%8D%E6%9D%82%E5%BA%A6%E8%AE%BE%E8%AE%A1%E5%A4%87%E9%80%89%E6%96%B9%E6%A1%88%E8%AF%84%E4%BC%B0%E5%92%8C%E9%80%89%E6%8B%A9%E5%A4%87%E9%80%89%E6%96%B9%E6%A1%88%E8%AF%A6%E7%BB%86%E6%96%B9%E6%A1%88%E8%AE%BE%E8%AE%A1/"},{"categories":["架构学习笔记"],"content":"合适原则 根据业务场景选择最合适的，不要追求无必要的东西，也不要从头到尾一把梭 简单原则 在满足需求的前提下保持简单，降低结构复杂性和逻辑复杂性 演化原则 演化优于一步到位 ","date":"2018-11-01","objectID":"/8-9-%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E4%B8%89%E5%8E%9F%E5%88%99/:0:0","tags":["架构","学习笔记"],"title":"8.9.架构设计三原则","uri":"/8-9-%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E4%B8%89%E5%8E%9F%E5%88%99/"},{"categories":["架构学习笔记"],"content":"低成本 一般引入新技术或者创造新技术才可能显著降低成本 安全 功能安全(防小偷) 架构安全(防强盗) DDoS没有太好的办法，用云服务商的流量清洗能力 规模 功能增加，因为各个功能间有关联，会导致系统复杂度指数增长 数据增加，会导致系统的复杂度发生质变(数据量大到一定程度，原有的解决方案基本都不再有效) ","date":"2018-10-31","objectID":"/7-%E5%A4%8D%E6%9D%82%E5%BA%A6%E7%9A%84%E6%9D%A5%E6%BA%90%E4%BD%8E%E6%88%90%E6%9C%AC%E5%AE%89%E5%85%A8%E8%A7%84%E6%A8%A1-1/:0:0","tags":["架构","学习笔记"],"title":"7.复杂度的来源：低成本、安全、规模","uri":"/7-%E5%A4%8D%E6%9D%82%E5%BA%A6%E7%9A%84%E6%9D%A5%E6%BA%90%E4%BD%8E%E6%88%90%E6%9C%AC%E5%AE%89%E5%85%A8%E8%A7%84%E6%A8%A1-1/"},{"categories":["架构学习笔记"],"content":"预测变化 软件系统中，唯一的不变就是一直在变。 预测变化 预测就意味着可能预测错误 但是又不能完全不预测 又不能每个点都考虑变化 根据业务需求，考虑哪些可能变化，哪些不会变化 应对变化 拆分稳定层和变化层 设计稳定层和变化层的接口 ","date":"2018-10-31","objectID":"/6-%E5%A4%8D%E6%9D%82%E5%BA%A6%E6%9D%A5%E6%BA%90%E5%8F%AF%E6%89%A9%E5%B1%95%E6%80%A7/:0:0","tags":["架构","学习笔记"],"title":"6.复杂度来源：可扩展性","uri":"/6-%E5%A4%8D%E6%9D%82%E5%BA%A6%E6%9D%A5%E6%BA%90%E5%8F%AF%E6%89%A9%E5%B1%95%E6%80%A7/"},{"categories":["架构学习笔记"],"content":"计算高可用 无论在哪台机器上进行计算，同样的算法和输入数据，产出的结果都是一样的；所以将计算从一台机器迁移到另外一台机器，对业务没有影响。 ","date":"2018-10-31","objectID":"/5-%E5%A4%8D%E6%9D%82%E5%BA%A6%E6%9D%A5%E6%BA%90%E9%AB%98%E5%8F%AF%E7%94%A8/:0:0","tags":["架构","学习笔记"],"title":"5.复杂度来源：高可用","uri":"/5-%E5%A4%8D%E6%9D%82%E5%BA%A6%E6%9D%A5%E6%BA%90%E9%AB%98%E5%8F%AF%E7%94%A8/"},{"categories":["架构学习笔记"],"content":"复杂度来源(同04中集群复杂度的来源) 需要增加一个任务分配器 分配器和业务服务器之间需要连接和交互(连接方式、异常处理等) 分配算法(轮询、按权重、按负载) 存储高可用(难点) 和计算相比，存储有一个本质上的区别：将数据从一台机器搬到另一台机器是有延迟的；导致“数据+逻辑=业务”中的数据不一致。 CAP定理证明了一个系统最多能满足一致性、可用性、分区容错性中的两个。 高可用状态决策 独裁式(有一个专门的决策者)：当决策者自身故障时，系统瘫痪 协商式(主备商量)：当主备连接异常时，如何处理？可能会出现双主、双备、多连接状态不一致问题 民主式(选举主机 ZooKeeper)：可能出现脑裂问题，通过系统节点数超过半数才选举主节点可以解决，但是当系统真的只剩下低于半数的节点可用时，系统瘫痪。 ","date":"2018-10-31","objectID":"/5-%E5%A4%8D%E6%9D%82%E5%BA%A6%E6%9D%A5%E6%BA%90%E9%AB%98%E5%8F%AF%E7%94%A8/:1:0","tags":["架构","学习笔记"],"title":"5.复杂度来源：高可用","uri":"/5-%E5%A4%8D%E6%9D%82%E5%BA%A6%E6%9D%A5%E6%BA%90%E9%AB%98%E5%8F%AF%E7%94%A8/"},{"categories":["架构学习笔记"],"content":"单机复杂度 ","date":"2018-10-31","objectID":"/4-%E5%A4%8D%E6%9D%82%E5%BA%A6%E6%9D%A5%E6%BA%90%E9%AB%98%E6%80%A7%E8%83%BD/:0:0","tags":["架构","学习笔记"],"title":"4.复杂度来源：高性能","uri":"/4-%E5%A4%8D%E6%9D%82%E5%BA%A6%E6%9D%A5%E6%BA%90%E9%AB%98%E6%80%A7%E8%83%BD/"},{"categories":["架构学习笔记"],"content":"进程和线程的前世今生 手工操作：系统大多数时间都在等待人的输入 批处理：计算机一次只能执行一个任务，如果某个任务需要从I/O读取大量数据，在这个过程中，CPU是空闲的 多进程(分时利用CPU)：单个进程内部只能串行处理，且进程间通信比较复杂 多进程多线程 线程是计算机是计算机调度的最小单位 进程是计算机资源的最小分配单元 ","date":"2018-10-31","objectID":"/4-%E5%A4%8D%E6%9D%82%E5%BA%A6%E6%9D%A5%E6%BA%90%E9%AB%98%E6%80%A7%E8%83%BD/:1:0","tags":["架构","学习笔记"],"title":"4.复杂度来源：高性能","uri":"/4-%E5%A4%8D%E6%9D%82%E5%BA%A6%E6%9D%A5%E6%BA%90%E9%AB%98%E6%80%A7%E8%83%BD/"},{"categories":["架构学习笔记"],"content":"架构设计的复杂度 考虑多进程、多线程、进程间通信、多线程并发等技术点，在架构设计时需要根据业务选型 集群的复杂度 ","date":"2018-10-31","objectID":"/4-%E5%A4%8D%E6%9D%82%E5%BA%A6%E6%9D%A5%E6%BA%90%E9%AB%98%E6%80%A7%E8%83%BD/:2:0","tags":["架构","学习笔记"],"title":"4.复杂度来源：高性能","uri":"/4-%E5%A4%8D%E6%9D%82%E5%BA%A6%E6%9D%A5%E6%BA%90%E9%AB%98%E6%80%A7%E8%83%BD/"},{"categories":["架构学习笔记"],"content":"任务分配 需要增加一个任务分配器 分配器和业务服务器之间需要连接和交互(连接方式、异常处理等) 分配算法(轮询、按权重、按负载) ","date":"2018-10-31","objectID":"/4-%E5%A4%8D%E6%9D%82%E5%BA%A6%E6%9D%A5%E6%BA%90%E9%AB%98%E6%80%A7%E8%83%BD/:3:0","tags":["架构","学习笔记"],"title":"4.复杂度来源：高性能","uri":"/4-%E5%A4%8D%E6%9D%82%E5%BA%A6%E6%9D%A5%E6%BA%90%E9%AB%98%E6%80%A7%E8%83%BD/"},{"categories":["架构学习笔记"],"content":"任务分解 任务越复杂，单台集群处理器性能越低，只通过增加集群来扩展性能，收益会越来越低。 把业务横向拆解成多个子业务可以解决此问题，主要因为 简单的系统容易做到高性能 可以针对单个任务进行扩展 ","date":"2018-10-31","objectID":"/4-%E5%A4%8D%E6%9D%82%E5%BA%A6%E6%9D%A5%E6%BA%90%E9%AB%98%E6%80%A7%E8%83%BD/:4:0","tags":["架构","学习笔记"],"title":"4.复杂度来源：高性能","uri":"/4-%E5%A4%8D%E6%9D%82%E5%BA%A6%E6%9D%A5%E6%BA%90%E9%AB%98%E6%80%A7%E8%83%BD/"},{"categories":["架构学习笔记"],"content":"架构设计的主要目的是为了解决软件系统复杂度带来的问题 ","date":"2018-10-31","objectID":"/3-%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E7%9A%84%E7%9B%AE%E7%9A%84/:0:0","tags":["架构","学习笔记"],"title":"3.架构设计的目的","uri":"/3-%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E7%9A%84%E7%9B%AE%E7%9A%84/"},{"categories":["架构学习笔记"],"content":"编程语言的发展史 机器语言 汇编语言 高级语言 第一次软件危机与结构化程序设计：通过自顶向下、逐步细化、模块化的指导思想，将软件的逻辑复杂度控制在一定范围内 第二次软件危机与面向对象：软件扩展异常困难，通过面向对象解决 架构的诞生 随着软件系统规模的增加，计算相关的算法和数据结构不再构成主要的设计问题；当系统由许多部分组成时，整个系统的组织，也就是软件架构，导致了一系列新的设计问题。 主要体现在如下几个方面 开发效率低 扩展困难 出问题难排查 ","date":"2018-10-31","objectID":"/2-%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E7%9A%84%E5%8E%86%E5%8F%B2%E8%83%8C%E6%99%AF/:0:0","tags":["架构","学习笔记"],"title":"2.架构设计的历史背景","uri":"/2-%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E7%9A%84%E5%8E%86%E5%8F%B2%E8%83%8C%E6%99%AF/"},{"categories":["架构学习笔记"],"content":"梳理常见概念 ","date":"2018-10-31","objectID":"/1-%E6%9E%B6%E6%9E%84%E5%88%B0%E5%BA%95%E6%98%AF%E4%BB%80%E4%B9%88/:0:0","tags":["架构","学习笔记"],"title":"1.架构到底是什么","uri":"/1-%E6%9E%B6%E6%9E%84%E5%88%B0%E5%BA%95%E6%98%AF%E4%BB%80%E4%B9%88/"},{"categories":["架构学习笔记"],"content":"系统与子系统 系统是一群有关连的个体按照既定的规则组成，并且产生了新的能力，关键是产生了新的能力 子系统也是系统，只是与系统之间有大和小的关系 ","date":"2018-10-31","objectID":"/1-%E6%9E%B6%E6%9E%84%E5%88%B0%E5%BA%95%E6%98%AF%E4%BB%80%E4%B9%88/:1:0","tags":["架构","学习笔记"],"title":"1.架构到底是什么","uri":"/1-%E6%9E%B6%E6%9E%84%E5%88%B0%E5%BA%95%E6%98%AF%E4%BB%80%E4%B9%88/"},{"categories":["架构学习笔记"],"content":"模块与组件 模块和组件，系统的组成部分，只是从不同的角度差分系统 从逻辑的角度拆分系统后得到的单元就是模块 从物理的角度拆分系统后得到的单元就是组件 划分模块的主要目的是职责分离；划分组件的主要目的是单元复用 component也可以翻译为“零件”，这就更好理解了 ","date":"2018-10-31","objectID":"/1-%E6%9E%B6%E6%9E%84%E5%88%B0%E5%BA%95%E6%98%AF%E4%BB%80%E4%B9%88/:2:0","tags":["架构","学习笔记"],"title":"1.架构到底是什么","uri":"/1-%E6%9E%B6%E6%9E%84%E5%88%B0%E5%BA%95%E6%98%AF%E4%BB%80%E4%B9%88/"},{"categories":["架构学习笔记"],"content":"框架与架构 框架是组件规范，框架是提供基础功能的产品 架构是指软件系统的基础结构 框架关注的是规范；架构关注的是结构 总结 架构是顶层设计；框架是面向编程和配置的半成品；组件是从技术维度上的复用；模块是从业务维度上职责的划分；系统是相互协同可运行的实体 ","date":"2018-10-31","objectID":"/1-%E6%9E%B6%E6%9E%84%E5%88%B0%E5%BA%95%E6%98%AF%E4%BB%80%E4%B9%88/:3:0","tags":["架构","学习笔记"],"title":"1.架构到底是什么","uri":"/1-%E6%9E%B6%E6%9E%84%E5%88%B0%E5%BA%95%E6%98%AF%E4%BB%80%E4%B9%88/"},{"categories":null,"content":" 典型普通程序员 我的备忘录 只有假期才刷题 很片面 email:qiaomaoshuang@foxmail.com ","date":"0001-01-01","objectID":"/about/:0:0","tags":null,"title":"关于","uri":"/about/"}]